{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad362e02",
   "metadata": {},
   "source": [
    "# GMO Forecasting\n",
    "\n",
    "*Case: Grantham, Mayo, and Van Otterloo, 2012: Estimating the Equity Risk Premium\n",
    "[9-211-051].*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 READING: GMO\n",
    "\n",
    "This section is not graded, and you do not need to submit your answers. But you are expected to consider these issues and be ready to discuss them.\n",
    "\n",
    "1. **GMO’s approach.**\n",
    "   - Why does GMO believe they can more easily predict **long‑run** than **short‑run** asset‑class performance?\n",
    "\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      GMO believes that there exists a long-run 'steady state' level to which asset's returns should converge over long time horizons. This belief is founded in a belief in the economics underlying the markets, in which the markets operate in a more efficient manner. In the short run, GMO is aware of the noise that clouds markets and market participants. GMO believes that although things will eventually revert towards the 'steady state', the biases, career considerations, and shocks cause significant noise that make it difficult to predict short-run performance.\n",
    "\n",
    "      </span>\n",
    "\n",
    "   - What predicting variables does the case mention are used by GMO? Does this fit with the goal of long‑run forecasts?\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      GMO uses the dividend yield, the P/E multiple expansion/contraction, the change in the profit margin, and sales growth as its predicting variables. Specifically, it believes that the profit margin and the P/E multiple have long-term steady values, and that in the long-term returns are driven by sales growth and the required dividend yield. This does seem to fit with the goal of long-run forecasts, which are meant to focus on the fundamental drivers of assets, not the market noise.\n",
    "\n",
    "      </span>\n",
    "\n",
    "   - How has this approach led to **contrarian** positions?\n",
    "\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      GMO typically expects the P/E and profit margin to revert to their long-run mean, and adjusts its expectations for dividend yield and sales growth according to their belief in the future of the business cycle. As such, when markets have elevated multiples or profit margins, GMO expects them to contract and thus takes an underweight position.\n",
    "\n",
    "      </span>\n",
    "\n",
    "   - How does this approach raise **business risk** and **managerial career risk**?\n",
    "\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      The first risk, business risk, is a result of a fund needing to secure capital long enough to see its thesis become realized. As a contrarian with a long term perspective, GMO is likely to suffer from severe underperformance while it waits for its thesis to play out. Many investors are not patient enough and may withrdraw their money, leaving GMO with no ability to function at all. Secondly, there is career risk. The risk here is that many investment professionals are driven by their concern for their position, which is largely determined by short(er) term performance. One may be reluctant to stand out if the risk of them, and them alone, being wrong leads to them being fired.\n",
    "\n",
    "      </span>\n",
    "\n",
    "2. **The market environment.**\n",
    "   - We often estimate the market risk premium by looking at a large sample of historic data. What reasons does the case give to be skeptical that the market risk premium will be as high **in the future** as it has been **over the past 50 years**?\n",
    "      \n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "      \n",
    "      Firstly, we have developed significant infrastructure, theory, and general understanding over the past 50 years. As the process of searching and transacting changes, it is likely that the costs (as reflected in returns) will change as well. In addition, our development of risk-theory is likely to alter the premiums of different assets. From a more foundational perspective, one can not even be sure that the underlying economics functions similarly as it has before. New technology, whether it be the internet or blockchain have proven their ability to alter the intersection of economics and markets (or at least our perspective of such as market participants). Consider GMO's use of profit margins, for example, and how fundamentally different the business models of tech is from prior businesses.\n",
    "\n",
    "      </span>\n",
    "\n",
    "   - In 2007, GMO forecasts **real excess equity returns** will be negative. What are the biggest drivers of their **pessimistic conditional** forecast relative to the **unconditional** forecast? (See Exhibit 9.)\n",
    "\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "      \n",
    "      As of 2007, the market's P/E sat at 19.5 and it's profit margin at 7.9%. These were both above GMO's steady-state levels. Also, GMO forecasted a 2.4% growth in sales as opposed to its 3.2% steady-state level, which seems to indicate that GMO anticipated an economic contraction.\n",
    "\n",
    "      </span>\n",
    "\n",
    "   - In the 2011 forecast, what components has GMO revised most relative to 2007? Now how does their conditional forecast compare to the unconditional? (See Exhibit 10.)\n",
    "\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "      \n",
    "      GMO expects both sales growth and dividend yield to increase from 2011 levels, and expects profit margins to decrease. It has also revised its steady state P/E from 16 down to 15.\n",
    "\n",
    "      </span>\n",
    "\n",
    "3. **Consider the asset‑class forecasts in Exhibit 1.**\n",
    "   - Which asset class did GMO estimate to have a **negative 10‑year return** over 2002–2011?\n",
    "      \n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "      \n",
    "      GMO expected US equities to have a negative return.\n",
    "\n",
    "      </span>\n",
    "\n",
    "   - Which asset classes substantially **outperformed** GMO’s estimate over that time period?\n",
    "      \n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      Foreign government bonds substantially outperformed GMO's forecast.\n",
    "\n",
    "      </span>\n",
    "\n",
    "\n",
    "   - Which asset classes substantially **underperformed** GMO’s estimate over that time period?\n",
    "      \n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      US Treasuries and US REITS.\n",
    "\n",
    "      </span>\n",
    "\n",
    "4. **Fund performance.**\n",
    "   - In which asset class was **GMWAX** most heavily allocated throughout the majority of 1997–2011?\n",
    "\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      GMWAX was most heavily positioned in US Fixed Income.\n",
    "\n",
    "      </span>\n",
    "\n",
    "   - Comment on the performance of GMWAX versus its benchmark. (No calculation needed; simply comment on the comparison in the exhibits.)\n",
    "\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "      \n",
    "      GMWAX seems to have performed fairly well in comparison. Most notably, it seemed to have less tail risk on the downside.\n",
    "\n",
    "      </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Analyzing GMO\n",
    "\n",
    "_This section utilizes data in the file `gmo_data.xlsx`._ Convert total returns to **excess returns** using the risk‑free rate.\n",
    "\n",
    "1. **Performance (GMWAX).** Compute **mean**, **volatility**, and **Sharpe ratio** for **GMWAX** over three samples:\n",
    "   - inception → 2011\n",
    "   - 2012 → present\n",
    "   - inception → present  \n",
    "   Has the mean, vol, and Sharpe changed much since the case?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440494d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 SPY     GMWAX     GMGEX\n",
      "date                                    \n",
      "1996-12-31 -0.075002 -0.073804 -0.064710\n",
      "1997-01-31  0.010316 -0.036735 -0.017022\n",
      "1997-02-28 -0.042635 -0.029935 -0.039467\n",
      "1997-03-31 -0.098941 -0.068372 -0.069661\n",
      "1997-04-30  0.012038 -0.059061 -0.052330\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the Excel file\n",
    "total_returns = pd.read_excel('gmo_analysis_data.xlsx', sheet_name=\"total returns\", index_col=0)\n",
    "risk_free_rate = pd.read_excel('gmo_analysis_data.xlsx', sheet_name=\"risk-free rate\", index_col=0)\n",
    "\n",
    "# Date to datetime\n",
    "total_returns.index = pd.to_datetime(total_returns.index)\n",
    "risk_free_rate.index = pd.to_datetime(risk_free_rate.index)\n",
    "\n",
    "\n",
    "# Calculate excess returns by subtracting risk-free rate from each column\n",
    "excess_returns = total_returns.sub(risk_free_rate['TBill 3M'], axis=0)\n",
    "\n",
    "print(excess_returns.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37f344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMWAX data range: 1996-12-31 to 2025-10-31\n",
      "\n",
      "================================================================================\n",
      "GMWAX Performance Statistics\n",
      "================================================================================\n",
      "             Period  Mean (annualized)  Volatility (annualized)  Sharpe Ratio (annualized)  N observations\n",
      "   inception → 2011          -0.265291                 0.131867                  -2.011809             181\n",
      "     2012 → present          -0.123303                 0.109588                  -1.125154             166\n",
      "inception → present          -0.197366                 0.123263                  -1.601179             347\n",
      "\n",
      "================================================================================\n",
      "Comparison: Has performance changed since the case?\n",
      "================================================================================\n",
      "\n",
      "Mean Return (annualized):\n",
      "  Inception → 2011: -0.2653 (-26.53%)\n",
      "  2012 → present:   -0.1233 (-12.33%)\n",
      "  Change:           +0.1420 (+14.20%)\n",
      "\n",
      "Volatility (annualized):\n",
      "  Inception → 2011: 0.1319 (13.19%)\n",
      "  2012 → present:   0.1096 (10.96%)\n",
      "  Change:           -0.0223 (-2.23%)\n",
      "\n",
      "Sharpe Ratio (annualized):\n",
      "  Inception → 2011: -2.0118\n",
      "  2012 → present:   -1.1252\n",
      "  Change:           +0.8867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 1. Performance (GMWAX): Compute mean, volatility, and Sharpe ratio\n",
    "# ============================================================================\n",
    "\n",
    "# Extract GMWAX excess returns\n",
    "gmwax_excess = excess_returns['GMWAX'].dropna()\n",
    "\n",
    "# Define time periods\n",
    "inception_date = gmwax_excess.index.min()\n",
    "end_2011 = pd.Timestamp('2011-12-31')\n",
    "start_2012 = pd.Timestamp('2012-01-01')\n",
    "present_date = gmwax_excess.index.max()\n",
    "\n",
    "print(f\"GMWAX data range: {inception_date.date()} to {present_date.date()}\\n\")\n",
    "\n",
    "# Function to calculate statistics\n",
    "def calculate_stats(returns, period_name):\n",
    "    \"\"\"Calculate mean, volatility, and Sharpe ratio for a return series.\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Monthly statistics\n",
    "    mean_monthly = returns.mean()\n",
    "    vol_monthly = returns.std()\n",
    "    sharpe_monthly = mean_monthly / vol_monthly if vol_monthly > 0 else np.nan\n",
    "    \n",
    "    # Annualize (assuming monthly data)\n",
    "    mean_annual = mean_monthly * 12\n",
    "    vol_annual = vol_monthly * np.sqrt(12)\n",
    "    sharpe_annual = mean_annual / vol_annual if vol_annual > 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'Period': period_name,\n",
    "        'Mean (annualized)': mean_annual,\n",
    "        'Volatility (annualized)': vol_annual,\n",
    "        'Sharpe Ratio (annualized)': sharpe_annual,\n",
    "        'N observations': len(returns)\n",
    "    }\n",
    "\n",
    "# Calculate statistics for three periods\n",
    "# Period 1: inception → 2011\n",
    "period1 = gmwax_excess[gmwax_excess.index <= end_2011]\n",
    "stats1 = calculate_stats(period1, 'inception → 2011')\n",
    "\n",
    "# Period 2: 2012 → present\n",
    "period2 = gmwax_excess[gmwax_excess.index >= start_2012]\n",
    "stats2 = calculate_stats(period2, '2012 → present')\n",
    "\n",
    "# Period 3: inception → present\n",
    "period3 = gmwax_excess\n",
    "stats3 = calculate_stats(period3, 'inception → present')\n",
    "\n",
    "# Create results DataFrame\n",
    "results = pd.DataFrame([stats1, stats2, stats3])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GMWAX Performance Statistics\")\n",
    "print(\"=\"*80)\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# Display comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Comparison: Has performance changed since the case?\")\n",
    "print(\"=\"*80)\n",
    "if stats1 and stats2:\n",
    "    print(f\"\\nMean Return (annualized):\")\n",
    "    print(f\"  Inception → 2011: {stats1['Mean (annualized)']:.4f} ({stats1['Mean (annualized)']*100:.2f}%)\")\n",
    "    print(f\"  2012 → present:   {stats2['Mean (annualized)']:.4f} ({stats2['Mean (annualized)']*100:.2f}%)\")\n",
    "    mean_change = stats2['Mean (annualized)'] - stats1['Mean (annualized)']\n",
    "    print(f\"  Change:           {mean_change:+.4f} ({mean_change*100:+.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nVolatility (annualized):\")\n",
    "    print(f\"  Inception → 2011: {stats1['Volatility (annualized)']:.4f} ({stats1['Volatility (annualized)']*100:.2f}%)\")\n",
    "    print(f\"  2012 → present:   {stats2['Volatility (annualized)']:.4f} ({stats2['Volatility (annualized)']*100:.2f}%)\")\n",
    "    vol_change = stats2['Volatility (annualized)'] - stats1['Volatility (annualized)']\n",
    "    print(f\"  Change:           {vol_change:+.4f} ({vol_change*100:+.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nSharpe Ratio (annualized):\")\n",
    "    print(f\"  Inception → 2011: {stats1['Sharpe Ratio (annualized)']:.4f}\")\n",
    "    print(f\"  2012 → present:   {stats2['Sharpe Ratio (annualized)']:.4f}\")\n",
    "    sharpe_change = stats2['Sharpe Ratio (annualized)'] - stats1['Sharpe Ratio (annualized)']\n",
    "    print(f\"  Change:           {sharpe_change:+.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd12638",
   "metadata": {},
   "source": [
    "\n",
    "<span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "Performance improved since 2011, but remains negative.\n",
    "\n",
    "Mean return: Improved from -26.53% to -12.33% (14.20 percentage points)\n",
    "\n",
    "Volatility: Decreased from 13.19% to 10.96%\n",
    "\n",
    "Sharpe ratio: Improved from -2.01 to -1.13\n",
    "\n",
    "Interpretation: Risk-adjusted returns are less negative, indicating a more stable profile\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e5d2b",
   "metadata": {},
   "source": [
    "\n",
    "2. **Tail risk (GMWAX).** For all three samples, analyze extreme scenarios:\n",
    "   - minimum return\n",
    "   - 5th percentile (VaR‑5th)\n",
    "   - maximum drawdown (compute on **total** returns, not excess returns)  \n",
    "   (a) Does GMWAX have high or low tail‑risk as seen by these stats?  \n",
    "   (b) Does that vary much across the two subsamples?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMWAX data range: 1996-12-31 to 2025-10-31\n",
      "\n",
      "================================================================================\n",
      "GMWAX Tail Risk Statistics\n",
      "================================================================================\n",
      "             Period  Minimum Return  5th Percentile (VaR-5th)  Maximum Drawdown  N observations\n",
      "   inception → 2011       -0.145129                 -0.043986         -0.293614             181\n",
      "     2012 → present       -0.114967                 -0.036928         -0.216795             166\n",
      "inception → present       -0.145129                 -0.040369         -0.293614             347\n",
      "\n",
      "================================================================================\n",
      "Comparison: Tail Risk Analysis\n",
      "================================================================================\n",
      "\n",
      "Minimum Return:\n",
      "  Inception → 2011: -0.1451 (-14.51%)\n",
      "  2012 → present:   -0.1150 (-11.50%)\n",
      "  Change:           +0.0302 (+3.02%)\n",
      "\n",
      "5th Percentile (VaR-5th):\n",
      "  Inception → 2011: -0.0440 (-4.40%)\n",
      "  2012 → present:   -0.0369 (-3.69%)\n",
      "  Change:           +0.0071 (+0.71%)\n",
      "\n",
      "Maximum Drawdown:\n",
      "  Inception → 2011: -0.2936 (-29.36%)\n",
      "  2012 → present:   -0.2168 (-21.68%)\n",
      "  Change:           +0.0768 (+7.68%)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. Tail risk (GMWAX): Analyze extreme scenarios\n",
    "# ============================================================================\n",
    "\n",
    "# Extract GMWAX total returns (not excess returns for drawdown calculation)\n",
    "gmwax_total = total_returns['GMWAX'].dropna()\n",
    "\n",
    "# Define time periods\n",
    "inception_date = gmwax_total.index.min()\n",
    "end_2011 = pd.Timestamp('2011-12-31')\n",
    "start_2012 = pd.Timestamp('2012-01-01')\n",
    "present_date = gmwax_total.index.max()\n",
    "\n",
    "print(f\"GMWAX data range: {inception_date.date()} to {present_date.date()}\\n\")\n",
    "\n",
    "# Function to calculate maximum drawdown\n",
    "def calculate_max_drawdown(returns):\n",
    "    \"\"\"Calculate maximum drawdown from a return series.\"\"\"\n",
    "    # Convert returns to cumulative wealth (starting at 1)\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    \n",
    "    # Calculate running maximum\n",
    "    running_max = cumulative.expanding().max()\n",
    "    \n",
    "    # Calculate drawdown\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    \n",
    "    # Maximum drawdown is the minimum (most negative) drawdown\n",
    "    max_dd = drawdown.min()\n",
    "    \n",
    "    return max_dd\n",
    "\n",
    "# Function to calculate tail risk statistics\n",
    "def calculate_tail_risk(returns, period_name):\n",
    "    \"\"\"Calculate tail risk statistics for a return series.\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return None\n",
    "    \n",
    "    min_return = returns.min()\n",
    "    var_5th = returns.quantile(0.05)  # 5th percentile (VaR-5th)\n",
    "    max_drawdown = calculate_max_drawdown(returns)\n",
    "    \n",
    "    return {\n",
    "        'Period': period_name,\n",
    "        'Minimum Return': min_return,\n",
    "        '5th Percentile (VaR-5th)': var_5th,\n",
    "        'Maximum Drawdown': max_drawdown,\n",
    "        'N observations': len(returns)\n",
    "    }\n",
    "\n",
    "# Calculate tail risk statistics for three periods\n",
    "# Period 1: inception → 2011\n",
    "period1 = gmwax_total[gmwax_total.index <= end_2011]\n",
    "tail1 = calculate_tail_risk(period1, 'inception → 2011')\n",
    "\n",
    "# Period 2: 2012 → present\n",
    "period2 = gmwax_total[gmwax_total.index >= start_2012]\n",
    "tail2 = calculate_tail_risk(period2, '2012 → present')\n",
    "\n",
    "# Period 3: inception → present\n",
    "period3 = gmwax_total\n",
    "tail3 = calculate_tail_risk(period3, 'inception → present')\n",
    "\n",
    "# Create results DataFrame\n",
    "tail_results = pd.DataFrame([tail1, tail2, tail3])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GMWAX Tail Risk Statistics\")\n",
    "print(\"=\"*80)\n",
    "print(tail_results.to_string(index=False))\n",
    "\n",
    "# Display comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Comparison: Tail Risk Analysis\")\n",
    "print(\"=\"*80)\n",
    "if tail1 and tail2:\n",
    "    print(f\"\\nMinimum Return:\")\n",
    "    print(f\"  Inception → 2011: {tail1['Minimum Return']:.4f} ({tail1['Minimum Return']*100:.2f}%)\")\n",
    "    print(f\"  2012 → present:   {tail2['Minimum Return']:.4f} ({tail2['Minimum Return']*100:.2f}%)\")\n",
    "    min_change = tail2['Minimum Return'] - tail1['Minimum Return']\n",
    "    print(f\"  Change:           {min_change:+.4f} ({min_change*100:+.2f}%)\")\n",
    "    \n",
    "    print(f\"\\n5th Percentile (VaR-5th):\")\n",
    "    print(f\"  Inception → 2011: {tail1['5th Percentile (VaR-5th)']:.4f} ({tail1['5th Percentile (VaR-5th)']*100:.2f}%)\")\n",
    "    print(f\"  2012 → present:   {tail2['5th Percentile (VaR-5th)']:.4f} ({tail2['5th Percentile (VaR-5th)']*100:.2f}%)\")\n",
    "    var_change = tail2['5th Percentile (VaR-5th)'] - tail1['5th Percentile (VaR-5th)']\n",
    "    print(f\"  Change:           {var_change:+.4f} ({var_change*100:+.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nMaximum Drawdown:\")\n",
    "    print(f\"  Inception → 2011: {tail1['Maximum Drawdown']:.4f} ({tail1['Maximum Drawdown']*100:.2f}%)\")\n",
    "    print(f\"  2012 → present:   {tail2['Maximum Drawdown']:.4f} ({tail2['Maximum Drawdown']*100:.2f}%)\")\n",
    "    dd_change = tail2['Maximum Drawdown'] - tail1['Maximum Drawdown']\n",
    "    print(f\"  Change:           {dd_change:+.4f} ({dd_change*100:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7096f",
   "metadata": {},
   "source": [
    "(a) Does GMWAX have high or low tail-risk?\n",
    "   \n",
    "   <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "   GMWAX exhibits HIGH tail-risk, with significant potential for large losses.\n",
    "\n",
    "   Average 5th percentile loss: -4.05%\n",
    "\n",
    "   Average maximum drawdown: 25.52%\n",
    "\n",
    "   </span>\n",
    "\n",
    "(b) Does tail-risk vary much across the two subsamples?\n",
    "   \n",
    "   <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "   Tail-risk has changed significantly across subsamples.\n",
    "\n",
    "   The 5th percentile loss is less severe in the post-2011 period.\n",
    "   \n",
    "   Maximum drawdown is smaller in the post-2011 period.\n",
    "\n",
    "   </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32b7f3",
   "metadata": {},
   "source": [
    "\n",
    "3. **Market exposure (GMWAX).** For all three samples, regress **excess returns of GMWAX** on **excess returns of SPY**:\n",
    "   - report estimated **alpha**, **beta**, and **R²**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0e13bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data range: 1996-12-31 to 2025-10-31\n",
      "\n",
      "================================================================================\n",
      "GMWAX Market Exposure (Regression on SPY)\n",
      "================================================================================\n",
      "             Period     Alpha     Beta       R²  Alpha (t-stat)  Beta (t-stat)  N observations\n",
      "   inception → 2011 -0.007864 0.619535 0.687802       -4.519375      19.858328             181\n",
      "     2012 → present -0.008309 0.629431 0.769300       -7.006386      23.385467             166\n",
      "inception → present -0.008053 0.622398 0.727059       -7.765373      30.315185             347\n",
      "\n",
      "================================================================================\n",
      "Comparison: Market Exposure Analysis\n",
      "================================================================================\n",
      "\n",
      "Alpha (monthly):\n",
      "  Inception → 2011: -0.007864 (t-stat: -4.52)\n",
      "  2012 → present:   -0.008309 (t-stat: -7.01)\n",
      "  Change:           -0.000445\n",
      "\n",
      "Beta:\n",
      "  Inception → 2011: 0.6195 (t-stat: 19.86)\n",
      "  2012 → present:   0.6294 (t-stat: 23.39)\n",
      "  Change:           +0.0099\n",
      "\n",
      "R²:\n",
      "  Inception → 2011: 0.6878\n",
      "  2012 → present:   0.7693\n",
      "  Change:           +0.0815\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. Market exposure (GMWAX): Regress excess returns on SPY excess returns\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "\n",
    "# Extract excess returns for GMWAX and SPY\n",
    "gmwax_excess = excess_returns['GMWAX'].dropna()\n",
    "spy_excess = excess_returns['SPY'].dropna()\n",
    "\n",
    "# Align the indices\n",
    "common_idx = gmwax_excess.index.intersection(spy_excess.index)\n",
    "gmwax_excess = gmwax_excess.loc[common_idx]\n",
    "spy_excess = spy_excess.loc[common_idx]\n",
    "\n",
    "# Define time periods\n",
    "inception_date = gmwax_excess.index.min()\n",
    "end_2011 = pd.Timestamp('2011-12-31')\n",
    "start_2012 = pd.Timestamp('2012-01-01')\n",
    "present_date = gmwax_excess.index.max()\n",
    "\n",
    "print(f\"Data range: {inception_date.date()} to {present_date.date()}\\n\")\n",
    "\n",
    "# Function to perform regression and return statistics\n",
    "def regress_gmwax_on_spy(gmwax_ret, spy_ret, period_name):\n",
    "    \"\"\"Regress GMWAX excess returns on SPY excess returns.\"\"\"\n",
    "    if len(gmwax_ret) == 0 or len(spy_ret) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Align indices\n",
    "    common_idx = gmwax_ret.index.intersection(spy_ret.index)\n",
    "    gmwax_aligned = gmwax_ret.loc[common_idx]\n",
    "    spy_aligned = spy_ret.loc[common_idx]\n",
    "    \n",
    "    # Prepare data for regression (X = SPY, y = GMWAX)\n",
    "    X = spy_aligned.values.reshape(-1, 1)\n",
    "    y = gmwax_aligned.values\n",
    "    \n",
    "    # Perform OLS regression\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = reg.predict(X)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "    \n",
    "    # Calculate standard errors and t-statistics\n",
    "    n = len(y)\n",
    "    residuals = y - y_pred\n",
    "    mse = np.sum(residuals ** 2) / (n - 2)  # Mean squared error\n",
    "    \n",
    "    # Standard errors\n",
    "    x_mean = np.mean(X)\n",
    "    sxx = np.sum((X.flatten() - x_mean) ** 2)\n",
    "    se_beta = np.sqrt(mse / sxx) if sxx != 0 else np.nan\n",
    "    se_alpha = np.sqrt(mse * (1/n + x_mean**2 / sxx)) if sxx != 0 else np.nan\n",
    "    \n",
    "    # t-statistics\n",
    "    t_alpha = reg.intercept_ / se_alpha if se_alpha != 0 else np.nan\n",
    "    t_beta = reg.coef_[0] / se_beta if se_beta != 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'Period': period_name,\n",
    "        'Alpha': reg.intercept_,\n",
    "        'Beta': reg.coef_[0],\n",
    "        'R²': r_squared,\n",
    "        'Alpha (t-stat)': t_alpha,\n",
    "        'Beta (t-stat)': t_beta,\n",
    "        'N observations': n\n",
    "    }\n",
    "\n",
    "# Perform regressions for three periods\n",
    "# Period 1: inception → 2011\n",
    "period1_gmwax = gmwax_excess[gmwax_excess.index <= end_2011]\n",
    "period1_spy = spy_excess[spy_excess.index <= end_2011]\n",
    "reg1 = regress_gmwax_on_spy(period1_gmwax, period1_spy, 'inception → 2011')\n",
    "\n",
    "# Period 2: 2012 → present\n",
    "period2_gmwax = gmwax_excess[gmwax_excess.index >= start_2012]\n",
    "period2_spy = spy_excess[spy_excess.index >= start_2012]\n",
    "reg2 = regress_gmwax_on_spy(period2_gmwax, period2_spy, '2012 → present')\n",
    "\n",
    "# Period 3: inception → present\n",
    "period3_gmwax = gmwax_excess\n",
    "period3_spy = spy_excess\n",
    "reg3 = regress_gmwax_on_spy(period3_gmwax, period3_spy, 'inception → present')\n",
    "\n",
    "# Create results DataFrame\n",
    "reg_results = pd.DataFrame([reg1, reg2, reg3])\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GMWAX Market Exposure (Regression on SPY)\")\n",
    "print(\"=\"*80)\n",
    "print(reg_results.to_string(index=False))\n",
    "\n",
    "# Display comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Comparison: Market Exposure Analysis\")\n",
    "print(\"=\"*80)\n",
    "if reg1 and reg2:\n",
    "    print(f\"\\nAlpha (monthly):\")\n",
    "    print(f\"  Inception → 2011: {reg1['Alpha']:.6f} (t-stat: {reg1['Alpha (t-stat)']:.2f})\")\n",
    "    print(f\"  2012 → present:   {reg2['Alpha']:.6f} (t-stat: {reg2['Alpha (t-stat)']:.2f})\")\n",
    "    alpha_change = reg2['Alpha'] - reg1['Alpha']\n",
    "    print(f\"  Change:           {alpha_change:+.6f}\")\n",
    "    \n",
    "    print(f\"\\nBeta:\")\n",
    "    print(f\"  Inception → 2011: {reg1['Beta']:.4f} (t-stat: {reg1['Beta (t-stat)']:.2f})\")\n",
    "    print(f\"  2012 → present:   {reg2['Beta']:.4f} (t-stat: {reg2['Beta (t-stat)']:.2f})\")\n",
    "    beta_change = reg2['Beta'] - reg1['Beta']\n",
    "    print(f\"  Change:           {beta_change:+.4f}\")\n",
    "    \n",
    "    print(f\"\\nR²:\")\n",
    "    print(f\"  Inception → 2011: {reg1['R²']:.4f}\")\n",
    "    print(f\"  2012 → present:   {reg2['R²']:.4f}\")\n",
    "    r2_change = reg2['R²'] - reg1['R²']\n",
    "    print(f\"  Change:           {r2_change:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea98d31",
   "metadata": {},
   "source": [
    "\n",
    "   - is GMWAX a **low‑beta** strategy? has that changed since the case?\n",
    "   \n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      Yes, GMWAX is a low-beta strategy. Beta is 0.6195 (inception → 2011) and 0.6294 (2012 → present), both below 1.0, indicating lower market sensitivity than the S&P 500. The change of +0.0099 is small, so beta has remained stable. The strategy has maintained its low-beta profile.\n",
    "\n",
    "      </span>\n",
    "\n",
    "   - does GMWAX provide **alpha**? has that changed across subsamples?\n",
    "\n",
    "      <span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "      No, GMWAX does not provide positive alpha. Both periods show statistically significant negative alpha:\n",
    "   \n",
    "      Inception → 2011: -0.007864 monthly (t-stat: -4.52)\n",
    "   \n",
    "      2012 → present: -0.008309 monthly (t-stat: -7.01)\n",
    "   \n",
    "      The alpha became slightly more negative (change: -0.000445), so risk-adjusted performance has deteriorated. The negative alpha is statistically significant in both periods, indicating consistent underperformance relative to the market after controlling for beta exposure.\n",
    "\n",
    "      </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d3887",
   "metadata": {},
   "source": [
    "\n",
    "4. **Compare to GMGEX.** Repeat items 1–3 for **GMGEX**. What are key differences between the two strategies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82142227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GMGEX ANALYSIS - Repeating Items 1-3\n",
      "================================================================================\n",
      "\n",
      "GMGEX data range: 1996-12-31 to 2025-10-31\n",
      "\n",
      "\n",
      "================================================================================\n",
      "1. GMGEX Performance Statistics\n",
      "================================================================================\n",
      "             Period  Mean (annualized)  Volatility (annualized)  Sharpe Ratio (annualized)  N observations\n",
      "   inception → 2011          -0.315536                 0.164479                  -1.918397             181\n",
      "     2012 → present          -0.159278                 0.231652                  -0.687575             166\n",
      "inception → present          -0.240784                 0.200434                  -1.201316             347\n",
      "\n",
      "================================================================================\n",
      "2. GMGEX Tail Risk Statistics\n",
      "================================================================================\n",
      "             Period  Minimum Return  5th Percentile (VaR-5th)  Maximum Drawdown  N observations\n",
      "   inception → 2011       -0.151229                 -0.079652         -0.555630             181\n",
      "     2012 → present       -0.658652                 -0.065289         -0.737364             166\n",
      "inception → present       -0.658652                 -0.075243         -0.761812             347\n",
      "\n",
      "================================================================================\n",
      "3. GMGEX Market Exposure (Regression on SPY)\n",
      "================================================================================\n",
      "             Period     Alpha     Beta       R²  Alpha (t-stat)  Beta (t-stat)  N observations\n",
      "   inception → 2011 -0.007564 0.814692 0.764487       -4.012685      24.104821             181\n",
      "     2012 → present -0.010761 0.804238 0.281073       -2.431640       8.007364             166\n",
      "inception → present -0.009222 0.803996 0.458842       -3.883874      17.103266             347\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. Compare to GMGEX: Repeat items 1-3 for GMGEX\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"GMGEX ANALYSIS - Repeating Items 1-3\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# Item 1: Performance (GMGEX) - Mean, Volatility, Sharpe Ratio\n",
    "# ============================================================================\n",
    "\n",
    "# Extract GMGEX excess returns\n",
    "gmgex_excess = excess_returns['GMGEX'].dropna()\n",
    "\n",
    "# Define time periods\n",
    "inception_date_gmgex = gmgex_excess.index.min()\n",
    "end_2011 = pd.Timestamp('2011-12-31')\n",
    "start_2012 = pd.Timestamp('2012-01-01')\n",
    "present_date_gmgex = gmgex_excess.index.max()\n",
    "\n",
    "print(f\"\\nGMGEX data range: {inception_date_gmgex.date()} to {present_date_gmgex.date()}\\n\")\n",
    "\n",
    "# Function to calculate statistics (reuse from earlier)\n",
    "def calculate_stats(returns, period_name):\n",
    "    \"\"\"Calculate mean, volatility, and Sharpe ratio for a return series.\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return None\n",
    "    \n",
    "    mean_monthly = returns.mean()\n",
    "    vol_monthly = returns.std()\n",
    "    sharpe_monthly = mean_monthly / vol_monthly if vol_monthly > 0 else np.nan\n",
    "    \n",
    "    # Annualize (assuming monthly data)\n",
    "    mean_annual = mean_monthly * 12\n",
    "    vol_annual = vol_monthly * np.sqrt(12)\n",
    "    sharpe_annual = mean_annual / vol_annual if vol_annual > 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'Period': period_name,\n",
    "        'Mean (annualized)': mean_annual,\n",
    "        'Volatility (annualized)': vol_annual,\n",
    "        'Sharpe Ratio (annualized)': sharpe_annual,\n",
    "        'N observations': len(returns)\n",
    "    }\n",
    "\n",
    "# Calculate statistics for three periods\n",
    "period1_gmgex = gmgex_excess[gmgex_excess.index <= end_2011]\n",
    "period2_gmgex = gmgex_excess[gmgex_excess.index >= start_2012]\n",
    "period3_gmgex = gmgex_excess\n",
    "\n",
    "stats1_gmgex = calculate_stats(period1_gmgex, 'inception → 2011')\n",
    "stats2_gmgex = calculate_stats(period2_gmgex, '2012 → present')\n",
    "stats3_gmgex = calculate_stats(period3_gmgex, 'inception → present')\n",
    "\n",
    "gmgex_perf_results = pd.DataFrame([stats1_gmgex, stats2_gmgex, stats3_gmgex])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. GMGEX Performance Statistics\")\n",
    "print(\"=\"*80)\n",
    "print(gmgex_perf_results.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# Item 2: Tail Risk (GMGEX) - Minimum, VaR-5th, Maximum Drawdown\n",
    "# ============================================================================\n",
    "\n",
    "# Extract GMGEX total returns (for drawdown calculation)\n",
    "gmgex_total = total_returns['GMGEX'].dropna()\n",
    "\n",
    "# Function to calculate maximum drawdown (reuse from earlier)\n",
    "def calculate_max_drawdown(returns):\n",
    "    \"\"\"Calculate maximum drawdown from a return series.\"\"\"\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    return drawdown.min()\n",
    "\n",
    "# Function to calculate tail risk statistics\n",
    "def calculate_tail_risk(returns, period_name):\n",
    "    \"\"\"Calculate tail risk statistics for a return series.\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return None\n",
    "    \n",
    "    min_return = returns.min()\n",
    "    var_5th = returns.quantile(0.05)\n",
    "    max_drawdown = calculate_max_drawdown(returns)\n",
    "    \n",
    "    return {\n",
    "        'Period': period_name,\n",
    "        'Minimum Return': min_return,\n",
    "        '5th Percentile (VaR-5th)': var_5th,\n",
    "        'Maximum Drawdown': max_drawdown,\n",
    "        'N observations': len(returns)\n",
    "    }\n",
    "\n",
    "# Calculate tail risk for three periods\n",
    "period1_gmgex_total = gmgex_total[gmgex_total.index <= end_2011]\n",
    "period2_gmgex_total = gmgex_total[gmgex_total.index >= start_2012]\n",
    "period3_gmgex_total = gmgex_total\n",
    "\n",
    "tail1_gmgex = calculate_tail_risk(period1_gmgex_total, 'inception → 2011')\n",
    "tail2_gmgex = calculate_tail_risk(period2_gmgex_total, '2012 → present')\n",
    "tail3_gmgex = calculate_tail_risk(period3_gmgex_total, 'inception → present')\n",
    "\n",
    "gmgex_tail_results = pd.DataFrame([tail1_gmgex, tail2_gmgex, tail3_gmgex])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. GMGEX Tail Risk Statistics\")\n",
    "print(\"=\"*80)\n",
    "print(gmgex_tail_results.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# Item 3: Market Exposure (GMGEX) - Regression on SPY\n",
    "# ============================================================================\n",
    "\n",
    "# Extract SPY excess returns (already have from earlier)\n",
    "spy_excess = excess_returns['SPY'].dropna()\n",
    "\n",
    "# Align indices\n",
    "common_idx_gmgex = gmgex_excess.index.intersection(spy_excess.index)\n",
    "gmgex_excess_aligned = gmgex_excess.loc[common_idx_gmgex]\n",
    "spy_excess_aligned = spy_excess.loc[common_idx_gmgex]\n",
    "\n",
    "# Function to perform regression (reuse from earlier)\n",
    "def regress_on_spy(fund_ret, spy_ret, period_name):\n",
    "    \"\"\"Regress fund excess returns on SPY excess returns.\"\"\"\n",
    "    if len(fund_ret) == 0 or len(spy_ret) == 0:\n",
    "        return None\n",
    "    \n",
    "    common_idx = fund_ret.index.intersection(spy_ret.index)\n",
    "    fund_aligned = fund_ret.loc[common_idx]\n",
    "    spy_aligned = spy_ret.loc[common_idx]\n",
    "    \n",
    "    X = spy_aligned.values.reshape(-1, 1)\n",
    "    y = fund_aligned.values\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "    \n",
    "    y_pred = reg.predict(X)\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "    \n",
    "    n = len(y)\n",
    "    residuals = y - y_pred\n",
    "    mse = np.sum(residuals ** 2) / (n - 2)\n",
    "    \n",
    "    x_mean = np.mean(X)\n",
    "    sxx = np.sum((X.flatten() - x_mean) ** 2)\n",
    "    se_beta = np.sqrt(mse / sxx) if sxx != 0 else np.nan\n",
    "    se_alpha = np.sqrt(mse * (1/n + x_mean**2 / sxx)) if sxx != 0 else np.nan\n",
    "    \n",
    "    t_alpha = reg.intercept_ / se_alpha if se_alpha != 0 else np.nan\n",
    "    t_beta = reg.coef_[0] / se_beta if se_beta != 0 else np.nan\n",
    "    \n",
    "    return {\n",
    "        'Period': period_name,\n",
    "        'Alpha': reg.intercept_,\n",
    "        'Beta': reg.coef_[0],\n",
    "        'R²': r_squared,\n",
    "        'Alpha (t-stat)': t_alpha,\n",
    "        'Beta (t-stat)': t_beta,\n",
    "        'N observations': n\n",
    "    }\n",
    "\n",
    "# Perform regressions for three periods\n",
    "period1_gmgex_reg = gmgex_excess_aligned[gmgex_excess_aligned.index <= end_2011]\n",
    "period1_spy_reg = spy_excess_aligned[spy_excess_aligned.index <= end_2011]\n",
    "\n",
    "period2_gmgex_reg = gmgex_excess_aligned[gmgex_excess_aligned.index >= start_2012]\n",
    "period2_spy_reg = spy_excess_aligned[spy_excess_aligned.index >= start_2012]\n",
    "\n",
    "reg1_gmgex = regress_on_spy(period1_gmgex_reg, period1_spy_reg, 'inception → 2011')\n",
    "reg2_gmgex = regress_on_spy(period2_gmgex_reg, period2_spy_reg, '2012 → present')\n",
    "reg3_gmgex = regress_on_spy(gmgex_excess_aligned, spy_excess_aligned, 'inception → present')\n",
    "\n",
    "gmgex_reg_results = pd.DataFrame([reg1_gmgex, reg2_gmgex, reg3_gmgex])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. GMGEX Market Exposure (Regression on SPY)\")\n",
    "print(\"=\"*80)\n",
    "print(gmgex_reg_results.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703740c",
   "metadata": {},
   "source": [
    "### COMPARISON: GMWAX vs GMGEX - Key Differences\n",
    "\n",
    "<span style=\"color: blue; font-size:0.85em\">\n",
    "\n",
    "1. PERFORMANCE COMPARISON (Inception → Present):\n",
    "\n",
    "GMGEX - Mean: -0.2408 (-24.08%)\n",
    "\n",
    "GMGEX - Volatility: 0.2004 (20.04%)\n",
    "\n",
    "GMGEX - Sharpe: -1.2013\n",
    "\n",
    "Note: Compare with GMWAX results from earlier analysis\n",
    "\n",
    "2. TAIL RISK COMPARISON (Inception → Present):\n",
    "\n",
    "GMGEX - Minimum Return: -0.6587 (-65.87%)\n",
    "\n",
    "GMGEX - 5th Percentile (VaR-5th): -0.0752 (-7.52%)\n",
    "\n",
    "GMGEX - Maximum Drawdown: -0.7618 (-76.18%)\n",
    "\n",
    "Note: Compare with GMWAX tail risk results from earlier analysis\n",
    "\n",
    "3. MARKET EXPOSURE COMPARISON (Inception → Present):\n",
    "\n",
    "GMGEX - Alpha: -0.009222 (t-stat: -3.88)\n",
    "\n",
    "GMGEX - Beta: 0.8040 (t-stat: 17.10)\n",
    "\n",
    "GMGEX - R²: 0.4588\n",
    "\n",
    "Note: Compare with GMWAX regression results from earlier analysis\n",
    "\n",
    "\n",
    "To identify key differences, compare:\n",
    "  - Performance metrics (mean, volatility, Sharpe) between GMWAX and GMGEX\n",
    "  - Tail risk metrics (min return, VaR-5th, max drawdown)\n",
    "  - Market exposure (alpha, beta, R²)\n",
    "\n",
    "Key questions to consider:\n",
    "  1. Which fund has better risk-adjusted returns (Sharpe ratio)?\n",
    "  2. Which fund has lower tail risk?\n",
    "  3. Which fund has lower market exposure (beta)?\n",
    "  4. Which fund provides better alpha (or less negative alpha)?\n",
    "  5. Which fund has higher R² (more market-driven vs idiosyncratic)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a4879",
   "metadata": {},
   "source": [
    "## 3 Forecast Regressions\n",
    "\n",
    "_This section utilizes data in `gmo_data.xlsx`._\n",
    "\n",
    "1. **Lagged regression.** Consider the regression with predictors lagged one period:\n",
    "\n",
    "$$\n",
    "r^{SPY}_{t} \\;=\\; \\alpha^{SPY,X} \\;+\\; \\big(\\beta^{SPY,X}\\big)^\\prime X_{t-1} \\;+\\; \\epsilon^{SPY,X}_{t}\n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "Estimate (1) and report the **$R^2$**, as well as the OLS estimates for $\\alpha$ and $\\beta$. Do this for:\n",
    "   - $X$ as a single regressor, the **dividend–price** ratio ($DP$)\n",
    "   - $X$ as a single regressor, the **earnings–price** ratio ($EP$)\n",
    "   - $X$ with **three** regressors: $DP$, $EP$, and the **10‑year yield**  \n",
    "   For each, report the **$R^2$**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92c97ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPX D/P</th>\n",
       "      <th>SPX E/P</th>\n",
       "      <th>T-Note 10YR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1996-12-31</th>\n",
       "      <td>0.019651</td>\n",
       "      <td>0.051592</td>\n",
       "      <td>0.06418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-01-31</th>\n",
       "      <td>0.018455</td>\n",
       "      <td>0.048704</td>\n",
       "      <td>0.06494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-02-28</th>\n",
       "      <td>0.018502</td>\n",
       "      <td>0.048434</td>\n",
       "      <td>0.06552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-03-31</th>\n",
       "      <td>0.019427</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.06903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-04-30</th>\n",
       "      <td>0.018430</td>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.06718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SPX D/P   SPX E/P  T-Note 10YR\n",
       "date                                       \n",
       "1996-12-31  0.019651  0.051592      0.06418\n",
       "1997-01-31  0.018455  0.048704      0.06494\n",
       "1997-02-28  0.018502  0.048434      0.06552\n",
       "1997-03-31  0.019427  0.055559      0.06903\n",
       "1997-04-30  0.018430  0.052318      0.06718"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals = pd.read_excel('gmo_analysis_data.xlsx', sheet_name=\"signals\", index_col=0)\n",
    "signals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e57ffb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LAGGED REGRESSION: r^SPY_t = α + β'X_{t-1} + ε_t\n",
      "================================================================================\n",
      "\n",
      "Dependent variable: SPY excess returns\n",
      "Predictors: SPX D/P, SPX E/P, T-Note 10YR\n",
      "\n",
      "Data ranges:\n",
      "  SPY excess returns: 1996-12-31 to 2025-10-31\n",
      "  Signals: 1996-12-31 to 2025-10-31\n",
      "\n",
      "================================================================================\n",
      "1. Regression with DP (dividend-price ratio) only\n",
      "================================================================================\n",
      "Alpha: -0.082401 (t-stat: -7.3154)\n",
      "Beta (SPX D/P): 3.846271 (t-stat: 6.2886)\n",
      "R²: 0.103106\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "2. Regression with EP (earnings-price ratio) only\n",
      "================================================================================\n",
      "Alpha: -0.041517 (t-stat: -3.6886)\n",
      "Beta (SPX E/P): 0.523302 (t-stat: 2.5757)\n",
      "R²: 0.018921\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "3. Regression with DP, EP, and 10-year yield\n",
      "================================================================================\n",
      "Alpha: -0.013337 (t-stat: -0.8309)\n",
      "Beta (SPX D/P): 1.926131 (t-stat: 2.0781)\n",
      "Beta (SPX E/P): 0.070757 (t-stat: 0.2699)\n",
      "Beta (T-Note 10YR): -1.083381 (t-stat: -5.4951)\n",
      "R²: 0.183655\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE\n",
      "================================================================================\n",
      "            Model     Alpha  Beta_DP       R²  Beta_EP  Beta_10Y\n",
      "          DP only -0.082401 3.846271 0.103106      NaN       NaN\n",
      "          EP only -0.041517      NaN 0.018921 0.523302       NaN\n",
      "DP, EP, 10Y Yield -0.013337 1.926131 0.183655 0.070757 -1.083381\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. Forecast Regressions - Lagged Regression\n",
    "# r^SPY_t = α + β'X_{t-1} + ε_t\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Get SPY excess returns (dependent variable)\n",
    "spy_excess = excess_returns['SPY'].dropna()\n",
    "\n",
    "# Ensure signals index is datetime\n",
    "signals.index = pd.to_datetime(signals.index)\n",
    "\n",
    "# Define predictor columns\n",
    "dp_col = 'SPX D/P'  # Dividend-price ratio\n",
    "ep_col = 'SPX E/P'  # Earnings-price ratio\n",
    "yield_col = 'T-Note 10YR'  # 10-year yield\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LAGGED REGRESSION: r^SPY_t = α + β'X_{t-1} + ε_t\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDependent variable: SPY excess returns\")\n",
    "print(f\"Predictors: {dp_col}, {ep_col}, {yield_col}\")\n",
    "print(f\"\\nData ranges:\")\n",
    "print(f\"  SPY excess returns: {spy_excess.index.min().date()} to {spy_excess.index.max().date()}\")\n",
    "print(f\"  Signals: {signals.index.min().date()} to {signals.index.max().date()}\")\n",
    "\n",
    "# Function to perform lagged regression\n",
    "def lagged_regression(y, X, X_names):\n",
    "    \"\"\"\n",
    "    Perform lagged regression: y_t = α + β'X_{t-1} + ε_t\n",
    "    \n",
    "    Parameters:\n",
    "    y: Series of dependent variable (SPY returns at time t)\n",
    "    X: DataFrame of predictors (at time t-1)\n",
    "    X_names: List of predictor names\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with alpha, beta, R², and other statistics\n",
    "    \"\"\"\n",
    "    # Align indices - y at time t, X at time t-1\n",
    "    # We need to shift X forward by 1 period so X[t-1] aligns with y[t]\n",
    "    X_lagged = X[X_names].shift(1)  # Shift forward so X[t-1] aligns with y[t]\n",
    "    \n",
    "    # Align indices\n",
    "    common_idx = y.index.intersection(X_lagged.index)\n",
    "    y_aligned = y.loc[common_idx]\n",
    "    X_aligned = X_lagged.loc[common_idx]\n",
    "    \n",
    "    # Drop rows with NaN (from the lag)\n",
    "    valid_mask = ~(X_aligned.isna().any(axis=1) | y_aligned.isna())\n",
    "    y_clean = y_aligned[valid_mask]\n",
    "    X_clean = X_aligned[valid_mask]\n",
    "    \n",
    "    if len(y_clean) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Prepare data for regression\n",
    "    X_values = X_clean.values\n",
    "    y_values = y_clean.values\n",
    "    \n",
    "    # Perform OLS regression\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_values, y_values)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = reg.predict(X_values)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    r_squared = r2_score(y_values, y_pred)\n",
    "    \n",
    "    # Calculate standard errors and t-statistics\n",
    "    n = len(y_values)\n",
    "    k = X_values.shape[1]  # number of predictors\n",
    "    residuals = y_values - y_pred\n",
    "    mse = np.sum(residuals ** 2) / (n - k - 1)  # Mean squared error\n",
    "    \n",
    "    # Standard errors\n",
    "    X_with_const = np.column_stack([np.ones(n), X_values])\n",
    "    try:\n",
    "        cov_matrix = mse * np.linalg.inv(X_with_const.T @ X_with_const)\n",
    "        se = np.sqrt(np.diag(cov_matrix))\n",
    "        se_alpha = se[0]\n",
    "        se_beta = se[1:]\n",
    "    except:\n",
    "        se_alpha = np.nan\n",
    "        se_beta = np.full(k, np.nan)\n",
    "    \n",
    "    # t-statistics\n",
    "    t_alpha = reg.intercept_ / se_alpha if se_alpha != 0 and not np.isnan(se_alpha) else np.nan\n",
    "    t_beta = reg.coef_ / se_beta if not np.isnan(se_beta).any() else np.full(k, np.nan)\n",
    "    \n",
    "    # Create beta dictionary\n",
    "    beta_dict = {name: coef for name, coef in zip(X_names, reg.coef_)}\n",
    "    t_beta_dict = {name: t for name, t in zip(X_names, t_beta)}\n",
    "    \n",
    "    return {\n",
    "        'Alpha': reg.intercept_,\n",
    "        'Beta': beta_dict,\n",
    "        'R²': r_squared,\n",
    "        'Alpha (t-stat)': t_alpha,\n",
    "        'Beta (t-stat)': t_beta_dict,\n",
    "        'N observations': n\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# Regression 1: DP only\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. Regression with DP (dividend-price ratio) only\")\n",
    "print(\"=\"*80)\n",
    "reg1 = lagged_regression(spy_excess, signals, [dp_col])\n",
    "if reg1:\n",
    "    print(f\"Alpha: {reg1['Alpha']:.6f} (t-stat: {reg1['Alpha (t-stat)']:.4f})\")\n",
    "    print(f\"Beta ({dp_col}): {reg1['Beta'][dp_col]:.6f} (t-stat: {reg1['Beta (t-stat)'][dp_col]:.4f})\")\n",
    "    print(f\"R²: {reg1['R²']:.6f}\")\n",
    "    print(f\"N observations: {reg1['N observations']}\")\n",
    "else:\n",
    "    print(\"Regression failed - check data alignment\")\n",
    "\n",
    "# ============================================================================\n",
    "# Regression 2: EP only\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. Regression with EP (earnings-price ratio) only\")\n",
    "print(\"=\"*80)\n",
    "reg2 = lagged_regression(spy_excess, signals, [ep_col])\n",
    "if reg2:\n",
    "    print(f\"Alpha: {reg2['Alpha']:.6f} (t-stat: {reg2['Alpha (t-stat)']:.4f})\")\n",
    "    print(f\"Beta ({ep_col}): {reg2['Beta'][ep_col]:.6f} (t-stat: {reg2['Beta (t-stat)'][ep_col]:.4f})\")\n",
    "    print(f\"R²: {reg2['R²']:.6f}\")\n",
    "    print(f\"N observations: {reg2['N observations']}\")\n",
    "else:\n",
    "    print(\"Regression failed - check data alignment\")\n",
    "\n",
    "# ============================================================================\n",
    "# Regression 3: DP, EP, and 10-year yield\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. Regression with DP, EP, and 10-year yield\")\n",
    "print(\"=\"*80)\n",
    "reg3 = lagged_regression(spy_excess, signals, [dp_col, ep_col, yield_col])\n",
    "if reg3:\n",
    "    print(f\"Alpha: {reg3['Alpha']:.6f} (t-stat: {reg3['Alpha (t-stat)']:.4f})\")\n",
    "    print(f\"Beta ({dp_col}): {reg3['Beta'][dp_col]:.6f} (t-stat: {reg3['Beta (t-stat)'][dp_col]:.4f})\")\n",
    "    print(f\"Beta ({ep_col}): {reg3['Beta'][ep_col]:.6f} (t-stat: {reg3['Beta (t-stat)'][ep_col]:.4f})\")\n",
    "    print(f\"Beta ({yield_col}): {reg3['Beta'][yield_col]:.6f} (t-stat: {reg3['Beta (t-stat)'][yield_col]:.4f})\")\n",
    "    print(f\"R²: {reg3['R²']:.6f}\")\n",
    "    print(f\"N observations: {reg3['N observations']}\")\n",
    "else:\n",
    "    print(\"Regression failed - check data alignment\")\n",
    "\n",
    "# ============================================================================\n",
    "# Summary Table\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "summary_data = []\n",
    "if reg1:\n",
    "    summary_data.append({\n",
    "        'Model': 'DP only',\n",
    "        'Alpha': reg1['Alpha'],\n",
    "        'Beta_DP': reg1['Beta'][dp_col],\n",
    "        'R²': reg1['R²']\n",
    "    })\n",
    "if reg2:\n",
    "    summary_data.append({\n",
    "        'Model': 'EP only',\n",
    "        'Alpha': reg2['Alpha'],\n",
    "        'Beta_EP': reg2['Beta'][ep_col],\n",
    "        'R²': reg2['R²']\n",
    "    })\n",
    "if reg3:\n",
    "    summary_data.append({\n",
    "        'Model': 'DP, EP, 10Y Yield',\n",
    "        'Alpha': reg3['Alpha'],\n",
    "        'Beta_DP': reg3['Beta'][dp_col],\n",
    "        'Beta_EP': reg3['Beta'][ep_col],\n",
    "        'Beta_10Y': reg3['Beta'][yield_col],\n",
    "        'R²': reg3['R²']\n",
    "    })\n",
    "\n",
    "if summary_data:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd6b4bc",
   "metadata": {},
   "source": [
    "\n",
    "2. **Trading strategy from forecasts.** For each of the three regressions:\n",
    "   - Build the forecasted SPY return: $\\hat r^{SPY}_{t+1}$ (forecast made using $X_t$ to predict $r^{SPY}_{t+1}$).\n",
    "   - Set the scale (portfolio weight) to $w_t = 100 \\,\\hat r^{SPY}_{t+1}$.\n",
    "   - Strategy return: $r^x_{t+1} = w_t\\, r^{SPY}_{t+1}$.  \n",
    "   For each strategy, compute:\n",
    "   - mean, volatility, Sharpe\n",
    "   - max drawdown\n",
    "   - market **alpha**\n",
    "   - market **beta**\n",
    "   - market **information ratio**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21523496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRADING STRATEGY FROM FORECASTS\n",
      "================================================================================\n",
      "\n",
      "Building trading strategies...\n",
      "\n",
      "================================================================================\n",
      "STRATEGY 1: DP only\n",
      "================================================================================\n",
      "Mean (annualized): 0.505219\n",
      "Volatility (annualized): 0.415142\n",
      "Sharpe Ratio (annualized): 1.216980\n",
      "Max Drawdown: -0.809579\n",
      "Market Alpha: 0.039233\n",
      "Market Beta: -0.212704\n",
      "Information Ratio (annualized): 1.140000\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "STRATEGY 2: EP only\n",
      "================================================================================\n",
      "Mean (annualized): 0.266259\n",
      "Volatility (annualized): 0.250071\n",
      "Sharpe Ratio (annualized): 1.064733\n",
      "Max Drawdown: -0.781260\n",
      "Market Alpha: 0.019093\n",
      "Market Beta: -0.229525\n",
      "Information Ratio (annualized): 0.928796\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "STRATEGY 3: DP, EP, 10Y Yield\n",
      "================================================================================\n",
      "Mean (annualized): 0.733855\n",
      "Volatility (annualized): 0.474515\n",
      "Sharpe Ratio (annualized): 1.546539\n",
      "Max Drawdown: -0.494226\n",
      "Market Alpha: 0.055334\n",
      "Market Beta: -0.431638\n",
      "Information Ratio (annualized): 1.418252\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE: Trading Strategy Statistics\n",
      "================================================================================\n",
      "         Strategy  Mean (annualized)  Volatility (annualized)  Sharpe Ratio  Max Drawdown  Market Alpha  Market Beta  Info Ratio (annualized)\n",
      "          DP only           0.505219                 0.415142      1.216980     -0.809579      0.039233    -0.212704                 1.140000\n",
      "          EP only           0.266259                 0.250071      1.064733     -0.781260      0.019093    -0.229525                 0.928796\n",
      "DP, EP, 10Y Yield           0.733855                 0.474515      1.546539     -0.494226      0.055334    -0.431638                 1.418252\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. Trading Strategy from Forecasts\n",
    "# ============================================================================\n",
    "\n",
    "# We need to rebuild the regression models to get the coefficients for forecasting\n",
    "# Then use X_t to forecast r^{SPY}_{t+1}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRADING STRATEGY FROM FORECASTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to build forecasts and trading strategy\n",
    "def build_trading_strategy(reg_result, signals_df, spy_returns, X_names, strategy_name):\n",
    "    \"\"\"\n",
    "    Build trading strategy from regression forecasts.\n",
    "    \n",
    "    Steps:\n",
    "    1. Build forecasted SPY return: r̂^{SPY}_{t+1} = α + β'X_t\n",
    "    2. Set portfolio weight: w_t = 100 * r̂^{SPY}_{t+1}\n",
    "    3. Strategy return: r^x_{t+1} = w_t * r^{SPY}_{t+1}\n",
    "    \"\"\"\n",
    "    if reg_result is None:\n",
    "        return None\n",
    "    \n",
    "    # Get regression coefficients\n",
    "    alpha = reg_result['Alpha']\n",
    "    beta_dict = reg_result['Beta']\n",
    "    \n",
    "    # Align data - we need X_t to forecast r^{SPY}_{t+1}\n",
    "    # X_t is at time t, and we forecast r^{SPY}_{t+1} (next period return)\n",
    "    common_idx = signals_df.index.intersection(spy_returns.index)\n",
    "    signals_aligned = signals_df.loc[common_idx, X_names]\n",
    "    spy_aligned = spy_returns.loc[common_idx]\n",
    "    \n",
    "    # Shift spy_returns forward by 1 period so r^{SPY}_{t+1} aligns with X_t\n",
    "    spy_next = spy_aligned.shift(-1)  # r^{SPY}_{t+1}\n",
    "    \n",
    "    # Align again after shift\n",
    "    common_idx_final = signals_aligned.index.intersection(spy_next.index)\n",
    "    signals_final = signals_aligned.loc[common_idx_final]\n",
    "    spy_next_final = spy_next.loc[common_idx_final]\n",
    "    \n",
    "    # Drop NaN\n",
    "    valid_mask = ~(signals_final.isna().any(axis=1) | spy_next_final.isna())\n",
    "    signals_clean = signals_final[valid_mask]\n",
    "    spy_next_clean = spy_next_final[valid_mask]\n",
    "    \n",
    "    if len(signals_clean) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Build forecasts: r̂^{SPY}_{t+1} = α + β'X_t\n",
    "    X_values = signals_clean.values\n",
    "    forecasts = alpha + np.sum([beta_dict[name] * signals_clean[name].values \n",
    "                                for name in X_names], axis=0)\n",
    "    \n",
    "    # Portfolio weights: w_t = 100 * r̂^{SPY}_{t+1}\n",
    "    weights = 100 * forecasts\n",
    "    \n",
    "    # Strategy returns: r^x_{t+1} = w_t * r^{SPY}_{t+1}\n",
    "    strategy_returns = weights * spy_next_clean.values\n",
    "    \n",
    "    # Create Series with proper index\n",
    "    strategy_returns_series = pd.Series(strategy_returns, index=signals_clean.index)\n",
    "    \n",
    "    return {\n",
    "        'strategy_name': strategy_name,\n",
    "        'forecasts': pd.Series(forecasts, index=signals_clean.index),\n",
    "        'weights': pd.Series(weights, index=signals_clean.index),\n",
    "        'strategy_returns': strategy_returns_series,\n",
    "        'spy_returns': spy_next_clean\n",
    "    }\n",
    "\n",
    "# Function to calculate strategy statistics\n",
    "def calculate_strategy_stats(strategy_dict, spy_market):\n",
    "    \"\"\"Calculate statistics for trading strategy.\"\"\"\n",
    "    if strategy_dict is None:\n",
    "        return None\n",
    "    \n",
    "    strategy_ret = strategy_dict['strategy_returns']\n",
    "    spy_ret = strategy_dict['spy_returns']\n",
    "    \n",
    "    # Mean, volatility, Sharpe (annualized)\n",
    "    mean_monthly = strategy_ret.mean()\n",
    "    vol_monthly = strategy_ret.std()\n",
    "    sharpe_monthly = mean_monthly / vol_monthly if vol_monthly > 0 else np.nan\n",
    "    \n",
    "    mean_annual = mean_monthly * 12\n",
    "    vol_annual = vol_monthly * np.sqrt(12)\n",
    "    sharpe_annual = mean_annual / vol_annual if vol_annual > 0 else np.nan\n",
    "    \n",
    "    # Maximum drawdown (on total returns, need to convert to cumulative)\n",
    "    cumulative = (1 + strategy_ret).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Market alpha and beta (regress strategy returns on market returns)\n",
    "    # Align indices\n",
    "    common_idx = strategy_ret.index.intersection(spy_market.index)\n",
    "    strategy_aligned = strategy_ret.loc[common_idx]\n",
    "    market_aligned = spy_market.loc[common_idx]\n",
    "    \n",
    "    if len(strategy_aligned) > 0:\n",
    "        X = market_aligned.values.reshape(-1, 1)\n",
    "        y = strategy_aligned.values\n",
    "        \n",
    "        reg = LinearRegression()\n",
    "        reg.fit(X, y)\n",
    "        y_pred = reg.predict(X)\n",
    "        \n",
    "        # Alpha and beta\n",
    "        alpha = reg.intercept_\n",
    "        beta = reg.coef_[0]\n",
    "        \n",
    "        # Information ratio = alpha / tracking error\n",
    "        residuals = y - y_pred\n",
    "        tracking_error = np.std(residuals)\n",
    "        information_ratio = alpha / tracking_error if tracking_error > 0 else np.nan\n",
    "        \n",
    "        # Annualize information ratio\n",
    "        info_ratio_annual = information_ratio * np.sqrt(12) if not np.isnan(information_ratio) else np.nan\n",
    "    else:\n",
    "        alpha = np.nan\n",
    "        beta = np.nan\n",
    "        information_ratio = np.nan\n",
    "        info_ratio_annual = np.nan\n",
    "    \n",
    "    return {\n",
    "        'Mean (annualized)': mean_annual,\n",
    "        'Volatility (annualized)': vol_annual,\n",
    "        'Sharpe Ratio (annualized)': sharpe_annual,\n",
    "        'Max Drawdown': max_drawdown,\n",
    "        'Market Alpha': alpha,\n",
    "        'Market Beta': beta,\n",
    "        'Information Ratio (annualized)': info_ratio_annual,\n",
    "        'N observations': len(strategy_ret)\n",
    "    }\n",
    "\n",
    "# Build strategies for all three regressions\n",
    "print(\"\\nBuilding trading strategies...\")\n",
    "\n",
    "# Strategy 1: DP only\n",
    "strategy1 = build_trading_strategy(reg1, signals, spy_excess, [dp_col], 'DP only')\n",
    "stats1 = calculate_strategy_stats(strategy1, spy_excess) if strategy1 else None\n",
    "\n",
    "# Strategy 2: EP only\n",
    "strategy2 = build_trading_strategy(reg2, signals, spy_excess, [ep_col], 'EP only')\n",
    "stats2 = calculate_strategy_stats(strategy2, spy_excess) if strategy2 else None\n",
    "\n",
    "# Strategy 3: DP, EP, 10Y Yield\n",
    "strategy3 = build_trading_strategy(reg3, signals, spy_excess, [dp_col, ep_col, yield_col], 'DP, EP, 10Y Yield')\n",
    "stats3 = calculate_strategy_stats(strategy3, spy_excess) if strategy3 else None\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY 1: DP only\")\n",
    "print(\"=\"*80)\n",
    "if stats1:\n",
    "    for key, value in stats1.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key}: {value:.6f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"Strategy calculation failed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY 2: EP only\")\n",
    "print(\"=\"*80)\n",
    "if stats2:\n",
    "    for key, value in stats2.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key}: {value:.6f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"Strategy calculation failed\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGY 3: DP, EP, 10Y Yield\")\n",
    "print(\"=\"*80)\n",
    "if stats3:\n",
    "    for key, value in stats3.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key}: {value:.6f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"Strategy calculation failed\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE: Trading Strategy Statistics\")\n",
    "print(\"=\"*80)\n",
    "summary_data = []\n",
    "if stats1:\n",
    "    summary_data.append({\n",
    "        'Strategy': 'DP only',\n",
    "        'Mean (annualized)': stats1['Mean (annualized)'],\n",
    "        'Volatility (annualized)': stats1['Volatility (annualized)'],\n",
    "        'Sharpe Ratio': stats1['Sharpe Ratio (annualized)'],\n",
    "        'Max Drawdown': stats1['Max Drawdown'],\n",
    "        'Market Alpha': stats1['Market Alpha'],\n",
    "        'Market Beta': stats1['Market Beta'],\n",
    "        'Info Ratio (annualized)': stats1['Information Ratio (annualized)']\n",
    "    })\n",
    "if stats2:\n",
    "    summary_data.append({\n",
    "        'Strategy': 'EP only',\n",
    "        'Mean (annualized)': stats2['Mean (annualized)'],\n",
    "        'Volatility (annualized)': stats2['Volatility (annualized)'],\n",
    "        'Sharpe Ratio': stats2['Sharpe Ratio (annualized)'],\n",
    "        'Max Drawdown': stats2['Max Drawdown'],\n",
    "        'Market Alpha': stats2['Market Alpha'],\n",
    "        'Market Beta': stats2['Market Beta'],\n",
    "        'Info Ratio (annualized)': stats2['Information Ratio (annualized)']\n",
    "    })\n",
    "if stats3:\n",
    "    summary_data.append({\n",
    "        'Strategy': 'DP, EP, 10Y Yield',\n",
    "        'Mean (annualized)': stats3['Mean (annualized)'],\n",
    "        'Volatility (annualized)': stats3['Volatility (annualized)'],\n",
    "        'Sharpe Ratio': stats3['Sharpe Ratio (annualized)'],\n",
    "        'Max Drawdown': stats3['Max Drawdown'],\n",
    "        'Market Alpha': stats3['Market Alpha'],\n",
    "        'Market Beta': stats3['Market Beta'],\n",
    "        'Info Ratio (annualized)': stats3['Information Ratio (annualized)']\n",
    "    })\n",
    "\n",
    "if summary_data:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36388c",
   "metadata": {},
   "source": [
    "\n",
    "3. **Risk characteristics.**\n",
    "   - For both strategies, the market, and GMO, compute monthly **VaR** at $\\pi = 0.05$ (use the historical quantile).\n",
    "   - The case mentions stocks under‑performed short‑term bonds from 2000–2011. Does the dynamic portfolio above under‑perform the risk‑free rate over this time?\n",
    "   - Based on the regression estimates, in how many periods do we estimate a **negative risk premium**?\n",
    "   - Do you believe the dynamic strategy takes on **extra risk**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c0007e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RISK CHARACTERISTICS ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "1. Monthly VaR at π = 0.05 (5th percentile)\n",
      "================================================================================\n",
      "Market (SPY): -0.098914 (-9.89%)\n",
      "GMO (GMWAX): -0.077006 (-7.70%)\n",
      "Strategy 1 (DP only): -0.078998 (-7.90%)\n",
      "Strategy 2 (EP only): -0.074008 (-7.40%)\n",
      "Strategy 3 (DP, EP, 10Y Yield): -0.065591 (-6.56%)\n",
      "\n",
      "================================================================================\n",
      "2. Dynamic Portfolio Performance vs Risk-Free Rate (2000-2011)\n",
      "================================================================================\n",
      "\n",
      "Period: 2000-01-01 to 2011-12-31\n",
      "Risk-free rate (monthly, average): 0.022875 (2.29%)\n",
      "\n",
      "Strategy 1 (DP only):\n",
      "  Mean monthly return: 0.053109 (5.31%)\n",
      "  Mean excess over RF: 0.030233 (3.02%)\n",
      "  Cumulative excess return: 19.143938 (1914.39%)\n",
      "  ✗ Outperforms risk-free rate (positive excess return)\n",
      "\n",
      "Strategy 2 (EP only):\n",
      "  Mean monthly return: 0.031962 (3.20%)\n",
      "  Mean excess over RF: 0.009086 (0.91%)\n",
      "  Cumulative excess return: 1.794594 (179.46%)\n",
      "  ✗ Outperforms risk-free rate (positive excess return)\n",
      "\n",
      "Strategy 3 (DP, EP, 10Y Yield):\n",
      "  Mean monthly return: 0.078094 (7.81%)\n",
      "  Mean excess over RF: 0.055218 (5.52%)\n",
      "  Cumulative excess return: 643.748892 (64374.89%)\n",
      "  ✗ Outperforms risk-free rate (positive excess return)\n",
      "\n",
      "================================================================================\n",
      "3. Periods with Negative Risk Premium (based on regression forecasts)\n",
      "================================================================================\n",
      "\n",
      "Strategy 1 (DP only):\n",
      "  Periods with negative risk premium: 307 out of 347 (88.47%)\n",
      "\n",
      "Strategy 2 (EP only):\n",
      "  Periods with negative risk premium: 332 out of 347 (95.68%)\n",
      "\n",
      "Strategy 3 (DP, EP, 10Y Yield):\n",
      "  Periods with negative risk premium: 231 out of 347 (66.57%)\n",
      "\n",
      "================================================================================\n",
      "4. Does the Dynamic Strategy Take on Extra Risk?\n",
      "================================================================================\n",
      "\n",
      "Risk Comparison:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Volatility (annualized):\n",
      "  Market (SPY): 0.168869 (16.89%)\n",
      "  Strategy 1 (DP only): 0.415142 (41.51%)\n",
      "  Strategy 2 (EP only): 0.250071 (25.01%)\n",
      "  Strategy 3 (DP, EP, 10Y Yield): 0.474515 (47.45%)\n",
      "\n",
      "VaR (5th percentile):\n",
      "  Market (SPY): -0.098914 (-9.89%)\n",
      "  Strategy 1 (DP only): -0.078998 (-7.90%)\n",
      "  Strategy 2 (EP only): -0.074008 (-7.40%)\n",
      "  Strategy 3 (DP, EP, 10Y Yield): -0.065591 (-6.56%)\n",
      "\n",
      "Maximum Drawdown:\n",
      "  Market (SPY): -0.993738 (-99.37%)\n",
      "  Strategy 1 (DP only): -0.809579 (-80.96%)\n",
      "  Strategy 2 (EP only): -0.781260 (-78.13%)\n",
      "  Strategy 3 (DP, EP, 10Y Yield): -0.494226 (-49.42%)\n",
      "\n",
      "Market Beta:\n",
      "  Strategy 1 (DP only): -0.2127\n",
      "  Strategy 2 (EP only): -0.2295\n",
      "  Strategy 3 (DP, EP, 10Y Yield): -0.4316\n",
      "  (Market beta = 1.0 by definition)\n",
      "\n",
      "================================================================================\n",
      "ASSESSMENT:\n",
      "================================================================================\n",
      "\n",
      "The dynamic strategy takes on EXTRA RISK if:\n",
      "  - Volatility is higher than the market\n",
      "  - VaR is more negative (worse) than the market\n",
      "  - Maximum drawdown is larger (more negative) than the market\n",
      "  - Market beta is greater than 1.0\n",
      "\n",
      "Compare the metrics above to assess whether each strategy takes on extra risk.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. Risk Characteristics\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RISK CHARACTERISTICS ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Compute monthly VaR at π = 0.05 (5th percentile) for strategies, market, and GMO\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_var(returns, percentile=0.05):\n",
    "    \"\"\"Calculate Value at Risk (VaR) using historical quantile.\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return np.nan\n",
    "    return returns.quantile(percentile)\n",
    "\n",
    "# Get market returns (SPY excess returns)\n",
    "market_returns = spy_excess\n",
    "\n",
    "# Get GMO returns (GMWAX excess returns)\n",
    "gmo_returns = excess_returns['GMWAX'].dropna()\n",
    "\n",
    "# Calculate VaR for each\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. Monthly VaR at π = 0.05 (5th percentile)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "var_market = calculate_var(market_returns, 0.05)\n",
    "var_gmo = calculate_var(gmo_returns, 0.05)\n",
    "\n",
    "print(f\"Market (SPY): {var_market:.6f} ({var_market*100:.2f}%)\")\n",
    "print(f\"GMO (GMWAX): {var_gmo:.6f} ({var_gmo*100:.2f}%)\")\n",
    "\n",
    "# Strategy VaRs\n",
    "if strategy1:\n",
    "    var_strategy1 = calculate_var(strategy1['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 1 (DP only): {var_strategy1:.6f} ({var_strategy1*100:.2f}%)\")\n",
    "else:\n",
    "    var_strategy1 = np.nan\n",
    "\n",
    "if strategy2:\n",
    "    var_strategy2 = calculate_var(strategy2['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 2 (EP only): {var_strategy2:.6f} ({var_strategy2*100:.2f}%)\")\n",
    "else:\n",
    "    var_strategy2 = np.nan\n",
    "\n",
    "if strategy3:\n",
    "    var_strategy3 = calculate_var(strategy3['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 3 (DP, EP, 10Y Yield): {var_strategy3:.6f} ({var_strategy3*100:.2f}%)\")\n",
    "else:\n",
    "    var_strategy3 = np.nan\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Check if dynamic portfolio underperforms risk-free rate from 2000-2011\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. Dynamic Portfolio Performance vs Risk-Free Rate (2000-2011)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define period\n",
    "start_2000 = pd.Timestamp('2000-01-01')\n",
    "end_2011 = pd.Timestamp('2011-12-31')\n",
    "\n",
    "# Get risk-free rate for this period\n",
    "rf_period = risk_free_rate['TBill 3M'].loc[(risk_free_rate.index >= start_2000) & \n",
    "                                            (risk_free_rate.index <= end_2011)]\n",
    "\n",
    "# Convert to monthly if annualized (check if values > 0.1)\n",
    "if rf_period.max() > 0.1:\n",
    "    rf_monthly = rf_period / 12\n",
    "else:\n",
    "    rf_monthly = rf_period\n",
    "\n",
    "print(f\"\\nPeriod: {start_2000.date()} to {end_2011.date()}\")\n",
    "print(f\"Risk-free rate (monthly, average): {rf_monthly.mean():.6f} ({rf_monthly.mean()*100:.2f}%)\")\n",
    "\n",
    "# Check each strategy\n",
    "strategies_to_check = [\n",
    "    (strategy1, 'Strategy 1 (DP only)'),\n",
    "    (strategy2, 'Strategy 2 (EP only)'),\n",
    "    (strategy3, 'Strategy 3 (DP, EP, 10Y Yield)')\n",
    "]\n",
    "\n",
    "for strategy, name in strategies_to_check:\n",
    "    if strategy:\n",
    "        strategy_ret = strategy['strategy_returns']\n",
    "        strategy_period = strategy_ret.loc[(strategy_ret.index >= start_2000) & \n",
    "                                          (strategy_ret.index <= end_2011)]\n",
    "        \n",
    "        if len(strategy_period) > 0:\n",
    "            # Align with risk-free rate\n",
    "            common_idx = strategy_period.index.intersection(rf_monthly.index)\n",
    "            strategy_aligned = strategy_period.loc[common_idx]\n",
    "            rf_aligned = rf_monthly.loc[common_idx]\n",
    "            \n",
    "            # Calculate excess return over risk-free rate\n",
    "            excess_over_rf = strategy_aligned - rf_aligned\n",
    "            mean_excess = excess_over_rf.mean()\n",
    "            total_excess = (1 + excess_over_rf).prod() - 1  # Cumulative excess return\n",
    "            \n",
    "            print(f\"\\n{name}:\")\n",
    "            print(f\"  Mean monthly return: {strategy_aligned.mean():.6f} ({strategy_aligned.mean()*100:.2f}%)\")\n",
    "            print(f\"  Mean excess over RF: {mean_excess:.6f} ({mean_excess*100:.2f}%)\")\n",
    "            print(f\"  Cumulative excess return: {total_excess:.6f} ({total_excess*100:.2f}%)\")\n",
    "            \n",
    "            if mean_excess < 0:\n",
    "                print(f\"  ✓ Underperforms risk-free rate (negative excess return)\")\n",
    "            else:\n",
    "                print(f\"  ✗ Outperforms risk-free rate (positive excess return)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Count periods with negative risk premium based on regression estimates\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. Periods with Negative Risk Premium (based on regression forecasts)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def count_negative_premiums(reg_result, signals_df, X_names):\n",
    "    \"\"\"Count how many periods have negative forecasted risk premium.\"\"\"\n",
    "    if reg_result is None:\n",
    "        return None\n",
    "    \n",
    "    alpha = reg_result['Alpha']\n",
    "    beta_dict = reg_result['Beta']\n",
    "    \n",
    "    # Align data\n",
    "    common_idx = signals_df.index.intersection(spy_excess.index)\n",
    "    signals_aligned = signals_df.loc[common_idx, X_names]\n",
    "    \n",
    "    # Drop NaN\n",
    "    valid_mask = ~signals_aligned.isna().any(axis=1)\n",
    "    signals_clean = signals_aligned[valid_mask]\n",
    "    \n",
    "    if len(signals_clean) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Build forecasts: r̂^{SPY}_{t+1} = α + β'X_t\n",
    "    forecasts = alpha + np.sum([beta_dict[name] * signals_clean[name].values \n",
    "                                for name in X_names], axis=0)\n",
    "    \n",
    "    # Count negative forecasts (negative risk premium)\n",
    "    negative_count = np.sum(forecasts < 0)\n",
    "    total_count = len(forecasts)\n",
    "    negative_pct = (negative_count / total_count) * 100 if total_count > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'negative_count': negative_count,\n",
    "        'total_count': total_count,\n",
    "        'negative_pct': negative_pct,\n",
    "        'forecasts': pd.Series(forecasts, index=signals_clean.index)\n",
    "    }\n",
    "\n",
    "# Count for each regression\n",
    "neg1 = count_negative_premiums(reg1, signals, [dp_col])\n",
    "neg2 = count_negative_premiums(reg2, signals, [ep_col])\n",
    "neg3 = count_negative_premiums(reg3, signals, [dp_col, ep_col, yield_col])\n",
    "\n",
    "if neg1:\n",
    "    print(f\"\\nStrategy 1 (DP only):\")\n",
    "    print(f\"  Periods with negative risk premium: {neg1['negative_count']} out of {neg1['total_count']} ({neg1['negative_pct']:.2f}%)\")\n",
    "\n",
    "if neg2:\n",
    "    print(f\"\\nStrategy 2 (EP only):\")\n",
    "    print(f\"  Periods with negative risk premium: {neg2['negative_count']} out of {neg2['total_count']} ({neg2['negative_pct']:.2f}%)\")\n",
    "\n",
    "if neg3:\n",
    "    print(f\"\\nStrategy 3 (DP, EP, 10Y Yield):\")\n",
    "    print(f\"  Periods with negative risk premium: {neg3['negative_count']} out of {neg3['total_count']} ({neg3['negative_pct']:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Assess if dynamic strategy takes on extra risk\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. Does the Dynamic Strategy Take on Extra Risk?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nRisk Comparison:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compare volatilities\n",
    "if stats1 and stats2 and stats3:\n",
    "    print(f\"\\nVolatility (annualized):\")\n",
    "    print(f\"  Market (SPY): {market_returns.std() * np.sqrt(12):.6f} ({market_returns.std() * np.sqrt(12)*100:.2f}%)\")\n",
    "    print(f\"  Strategy 1 (DP only): {stats1['Volatility (annualized)']:.6f} ({stats1['Volatility (annualized)']*100:.2f}%)\")\n",
    "    print(f\"  Strategy 2 (EP only): {stats2['Volatility (annualized)']:.6f} ({stats2['Volatility (annualized)']*100:.2f}%)\")\n",
    "    print(f\"  Strategy 3 (DP, EP, 10Y Yield): {stats3['Volatility (annualized)']:.6f} ({stats3['Volatility (annualized)']*100:.2f}%)\")\n",
    "    \n",
    "    # Compare VaRs\n",
    "    print(f\"\\nVaR (5th percentile):\")\n",
    "    print(f\"  Market (SPY): {var_market:.6f} ({var_market*100:.2f}%)\")\n",
    "    print(f\"  Strategy 1 (DP only): {var_strategy1:.6f} ({var_strategy1*100:.2f}%)\")\n",
    "    print(f\"  Strategy 2 (EP only): {var_strategy2:.6f} ({var_strategy2*100:.2f}%)\")\n",
    "    print(f\"  Strategy 3 (DP, EP, 10Y Yield): {var_strategy3:.6f} ({var_strategy3*100:.2f}%)\")\n",
    "    \n",
    "    # Compare max drawdowns\n",
    "    market_cumulative = (1 + market_returns).cumprod()\n",
    "    market_running_max = market_cumulative.expanding().max()\n",
    "    market_drawdown = (market_cumulative - market_running_max) / market_running_max\n",
    "    market_max_dd = market_drawdown.min()\n",
    "    \n",
    "    print(f\"\\nMaximum Drawdown:\")\n",
    "    print(f\"  Market (SPY): {market_max_dd:.6f} ({market_max_dd*100:.2f}%)\")\n",
    "    print(f\"  Strategy 1 (DP only): {stats1['Max Drawdown']:.6f} ({stats1['Max Drawdown']*100:.2f}%)\")\n",
    "    print(f\"  Strategy 2 (EP only): {stats2['Max Drawdown']:.6f} ({stats2['Max Drawdown']*100:.2f}%)\")\n",
    "    print(f\"  Strategy 3 (DP, EP, 10Y Yield): {stats3['Max Drawdown']:.6f} ({stats3['Max Drawdown']*100:.2f}%)\")\n",
    "    \n",
    "    # Compare betas\n",
    "    print(f\"\\nMarket Beta:\")\n",
    "    print(f\"  Strategy 1 (DP only): {stats1['Market Beta']:.4f}\")\n",
    "    print(f\"  Strategy 2 (EP only): {stats2['Market Beta']:.4f}\")\n",
    "    print(f\"  Strategy 3 (DP, EP, 10Y Yield): {stats3['Market Beta']:.4f}\")\n",
    "    print(f\"  (Market beta = 1.0 by definition)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ASSESSMENT:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nThe dynamic strategy takes on EXTRA RISK if:\")\n",
    "print(\"  - Volatility is higher than the market\")\n",
    "print(\"  - VaR is more negative (worse) than the market\")\n",
    "print(\"  - Maximum drawdown is larger (more negative) than the market\")\n",
    "print(\"  - Market beta is greater than 1.0\")\n",
    "print(\"\\nCompare the metrics above to assess whether each strategy takes on extra risk.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Out‑of‑Sample Forecasting\n",
    "\n",
    "_This section utilizes data in `gmo_data.xlsx`._ Focus on using **both** $DP$ and $EP$ as signals in (1). Compute **out‑of‑sample** ($OOS$) statistics:\n",
    "\n",
    "**Procedure (rolling OOS):**\n",
    "- Start at $t=60$.\n",
    "- Estimate (1) using data **through** time $t$.\n",
    "- Using the estimated parameters and $x_t$, compute the forecast for $t+1$:\n",
    "  \n",
    "  $$\n",
    "  \\hat r^{SPY}_{t+1} \\;=\\; \\hat \\alpha^{SPY,X}_t \\;+\\; \\big(\\hat \\beta^{SPY,X}_t\\big)^\\prime x_t\n",
    "  $$\n",
    "\n",
    "- Forecast error: $e^{forecast}_{t+1} = r^{SPY}_{t+1} - \\hat r^{SPY}_{t+1}$.\n",
    "- Move to $t=61$ and iterate.\n",
    "\n",
    "Also compute the **null** forecast and errors:\n",
    "\n",
    "$$\n",
    "\\bar r^{SPY}_{t+1} = \\frac{1}{t}\\sum_{i=1}^t r^{SPY}_i, \\qquad\n",
    "e^{null}_{t+1} = r^{SPY}_{t+1} - \\bar r^{SPY}_{t+1}.\n",
    "$$\n",
    "\n",
    "1. **Report the out‑of‑sample $R^2$**\n",
    "\n",
    "$$\n",
    "R^2_{OOS} \\;\\equiv\\; 1 - \\frac{\\sum_{i=61}^T \\big(e^{forecast}_i\\big)^2}{\\sum_{i=61}^T \\big(e^{null}_i\\big)^2}\n",
    "$$\n",
    "\n",
    "Did this forecasting strategy produce a positive $R^2_{OOS}$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24c1a0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OUT-OF-SAMPLE FORECASTING\n",
      "================================================================================\n",
      "\n",
      "Using both DP and EP as signals for forecasting\n",
      "\n",
      "Data range: 1996-12-31 to 2025-10-31\n",
      "Total observations: 347\n",
      "Starting OOS at t=60 (observation 2001-12-31 00:00:00)\n",
      "\n",
      "Running rolling OOS procedure from t=60 to t=345...\n",
      "\n",
      "================================================================================\n",
      "OUT-OF-SAMPLE RESULTS\n",
      "================================================================================\n",
      "\n",
      "Number of OOS forecasts: 286\n",
      "Sum of squared forecast errors: 0.605409\n",
      "Sum of squared null errors: 0.663985\n",
      "\n",
      "Out-of-Sample R²: 0.088220\n",
      "\n",
      "✓ YES - The forecasting strategy produced a POSITIVE R²_OOS (0.088220)\n",
      "  This means the model forecasts are better than the null (mean) forecast.\n",
      "\n",
      "================================================================================\n",
      "ADDITIONAL STATISTICS\n",
      "================================================================================\n",
      "Mean forecast error: 0.004922\n",
      "RMSE (forecast): 0.046009\n",
      "Mean null error: 0.013239\n",
      "RMSE (null): 0.048183\n",
      "\n",
      "Forecast RMSE is 4.51% lower than null forecast RMSE\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. Out-of-Sample Forecasting\n",
    "# Focus on using both DP and EP as signals\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OUT-OF-SAMPLE FORECASTING\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nUsing both DP and EP as signals for forecasting\")\n",
    "\n",
    "# Align data\n",
    "common_idx = signals.index.intersection(spy_excess.index)\n",
    "signals_aligned = signals.loc[common_idx, [dp_col, ep_col]]\n",
    "spy_aligned = spy_excess.loc[common_idx]\n",
    "\n",
    "# Sort by date to ensure proper ordering\n",
    "signals_aligned = signals_aligned.sort_index()\n",
    "spy_aligned = spy_aligned.sort_index()\n",
    "\n",
    "# Remove any NaN rows\n",
    "valid_mask = ~(signals_aligned.isna().any(axis=1) | spy_aligned.isna())\n",
    "signals_clean = signals_aligned[valid_mask]\n",
    "spy_clean = spy_aligned[valid_mask]\n",
    "\n",
    "print(f\"\\nData range: {spy_clean.index.min().date()} to {spy_clean.index.max().date()}\")\n",
    "print(f\"Total observations: {len(spy_clean)}\")\n",
    "print(f\"Starting OOS at t=60 (observation {spy_clean.index[60]})\")\n",
    "\n",
    "# Initialize storage for forecasts and errors\n",
    "forecast_errors = []\n",
    "null_errors = []\n",
    "forecast_values = []\n",
    "null_forecast_values = []\n",
    "actual_returns = []\n",
    "\n",
    "# Rolling out-of-sample procedure\n",
    "# Start at t=60 (0-indexed, so t=60 means we use observations 0-60 to forecast 61)\n",
    "start_idx = 60\n",
    "T = len(spy_clean)\n",
    "\n",
    "print(f\"\\nRunning rolling OOS procedure from t={start_idx} to t={T-2}...\")\n",
    "\n",
    "for t in range(start_idx, T - 1):  # T-1 because we need t+1 to exist\n",
    "    # Data through time t (for estimation)\n",
    "    spy_train = spy_clean.iloc[:t+1]  # Observations 0 to t (inclusive)\n",
    "    signals_train = signals_clean.iloc[:t+1]\n",
    "    \n",
    "    # X_t (predictors at time t) for forecasting\n",
    "    x_t = signals_clean.iloc[t:t+1]  # Signals at time t\n",
    "    \n",
    "    # r^{SPY}_{t+1} (actual return at time t+1)\n",
    "    r_t_plus_1 = spy_clean.iloc[t+1]\n",
    "    \n",
    "    # Drop NaN from training data\n",
    "    train_mask = ~(signals_train.isna().any(axis=1) | spy_train.isna())\n",
    "    signals_train_clean = signals_train[train_mask]\n",
    "    spy_train_clean = spy_train[train_mask]\n",
    "    \n",
    "    if len(signals_train_clean) < 2:  # Need at least 2 observations\n",
    "        continue\n",
    "    \n",
    "    # Estimate regression using data through time t\n",
    "    # r^{SPY}_i = α + β'X_{i-1} + ε_i for i = 1 to t\n",
    "    # We need to lag the signals\n",
    "    signals_train_lagged = signals_train_clean.shift(1).iloc[1:]  # X_{i-1}\n",
    "    spy_train_aligned = spy_train_clean.iloc[1:]  # r^{SPY}_i\n",
    "    \n",
    "    # Align after lag\n",
    "    common_train_idx = signals_train_lagged.index.intersection(spy_train_aligned.index)\n",
    "    signals_train_final = signals_train_lagged.loc[common_train_idx]\n",
    "    spy_train_final = spy_train_aligned.loc[common_train_idx]\n",
    "    \n",
    "    if len(signals_train_final) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Fit regression\n",
    "    X_train = signals_train_final.values\n",
    "    y_train = spy_train_final.values\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Forecast r^{SPY}_{t+1} using x_t\n",
    "    x_t_values = x_t.values\n",
    "    forecast = reg.intercept_ + np.dot(reg.coef_, x_t_values[0])\n",
    "    \n",
    "    # Forecast error\n",
    "    forecast_error = r_t_plus_1 - forecast\n",
    "    \n",
    "    # Null forecast: mean of returns through time t\n",
    "    null_forecast = spy_train_clean.mean()\n",
    "    null_error = r_t_plus_1 - null_forecast\n",
    "    \n",
    "    # Store results\n",
    "    forecast_errors.append(forecast_error)\n",
    "    null_errors.append(null_error)\n",
    "    forecast_values.append(forecast)\n",
    "    null_forecast_values.append(null_forecast)\n",
    "    actual_returns.append(r_t_plus_1)\n",
    "\n",
    "# Convert to arrays\n",
    "forecast_errors = np.array(forecast_errors)\n",
    "null_errors = np.array(null_errors)\n",
    "\n",
    "# Calculate out-of-sample R²\n",
    "sum_squared_forecast_errors = np.sum(forecast_errors ** 2)\n",
    "sum_squared_null_errors = np.sum(null_errors ** 2)\n",
    "\n",
    "if sum_squared_null_errors > 0:\n",
    "    r2_oos = 1 - (sum_squared_forecast_errors / sum_squared_null_errors)\n",
    "else:\n",
    "    r2_oos = np.nan\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUT-OF-SAMPLE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNumber of OOS forecasts: {len(forecast_errors)}\")\n",
    "print(f\"Sum of squared forecast errors: {sum_squared_forecast_errors:.6f}\")\n",
    "print(f\"Sum of squared null errors: {sum_squared_null_errors:.6f}\")\n",
    "print(f\"\\nOut-of-Sample R²: {r2_oos:.6f}\")\n",
    "\n",
    "if r2_oos > 0:\n",
    "    print(f\"\\n✓ YES - The forecasting strategy produced a POSITIVE R²_OOS ({r2_oos:.6f})\")\n",
    "    print(\"  This means the model forecasts are better than the null (mean) forecast.\")\n",
    "elif r2_oos < 0:\n",
    "    print(f\"\\n✗ NO - The forecasting strategy produced a NEGATIVE R²_OOS ({r2_oos:.6f})\")\n",
    "    print(\"  This means the model forecasts are worse than the null (mean) forecast.\")\n",
    "else:\n",
    "    print(f\"\\nThe forecasting strategy produced R²_OOS = 0\")\n",
    "    print(\"  This means the model forecasts perform the same as the null (mean) forecast.\")\n",
    "\n",
    "# Additional statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADDITIONAL STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Mean forecast error: {np.mean(forecast_errors):.6f}\")\n",
    "print(f\"RMSE (forecast): {np.sqrt(np.mean(forecast_errors**2)):.6f}\")\n",
    "print(f\"Mean null error: {np.mean(null_errors):.6f}\")\n",
    "print(f\"RMSE (null): {np.sqrt(np.mean(null_errors**2)):.6f}\")\n",
    "\n",
    "if np.sqrt(np.mean(forecast_errors**2)) < np.sqrt(np.mean(null_errors**2)):\n",
    "    improvement = ((np.sqrt(np.mean(null_errors**2)) - np.sqrt(np.mean(forecast_errors**2))) / \n",
    "                   np.sqrt(np.mean(null_errors**2))) * 100\n",
    "    print(f\"\\nForecast RMSE is {improvement:.2f}% lower than null forecast RMSE\")\n",
    "else:\n",
    "    deterioration = ((np.sqrt(np.mean(forecast_errors**2)) - np.sqrt(np.mean(null_errors**2))) / \n",
    "                     np.sqrt(np.mean(null_errors**2))) * 100\n",
    "    print(f\"\\nForecast RMSE is {deterioration:.2f}% higher than null forecast RMSE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ec223e",
   "metadata": {},
   "source": [
    "2. **Redo 3.2 with OOS forecasts.** How does the OOS strategy compare to the in‑sample version of 3.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e18699fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRADING STRATEGY FROM OUT-OF-SAMPLE FORECASTS\n",
      "================================================================================\n",
      "\n",
      "Building OOS trading strategy from t=60 to t=345...\n",
      "\n",
      "================================================================================\n",
      "OUT-OF-SAMPLE STRATEGY STATISTICS\n",
      "================================================================================\n",
      "Mean (annualized): 0.212668\n",
      "Volatility (annualized): 0.259100\n",
      "Sharpe Ratio (annualized): 0.820797\n",
      "Max Drawdown: -0.747516\n",
      "Market Alpha: 0.007746\n",
      "Market Beta: -1.250617\n",
      "Information Ratio (annualized): 0.567514\n",
      "N observations: 286\n",
      "\n",
      "================================================================================\n",
      "IN-SAMPLE STRATEGY STATISTICS (from section 3.2)\n",
      "================================================================================\n",
      "Mean (annualized): 0.733855\n",
      "Volatility (annualized): 0.474515\n",
      "Sharpe Ratio (annualized): 1.546539\n",
      "Max Drawdown: -0.494226\n",
      "Market Alpha: 0.055334\n",
      "Market Beta: -0.431638\n",
      "Information Ratio (annualized): 1.418252\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: OOS vs IN-SAMPLE STRATEGY\n",
      "================================================================================\n",
      "\n",
      "Mean Return (annualized):\n",
      "  OOS Strategy: 0.212668 (21.27%)\n",
      "  In-Sample Strategy: 0.733855 (73.39%)\n",
      "  Difference: -0.521187 (-52.12%)\n",
      "\n",
      "Volatility (annualized):\n",
      "  OOS Strategy: 0.259100 (25.91%)\n",
      "  In-Sample Strategy: 0.474515 (47.45%)\n",
      "  Difference: -0.215415 (-21.54%)\n",
      "\n",
      "Sharpe Ratio (annualized):\n",
      "  OOS Strategy: 0.820797\n",
      "  In-Sample Strategy: 1.546539\n",
      "  Difference: -0.725742\n",
      "\n",
      "Maximum Drawdown:\n",
      "  OOS Strategy: -0.747516 (-74.75%)\n",
      "  In-Sample Strategy: -0.494226 (-49.42%)\n",
      "  Difference: -0.253290 (-25.33%)\n",
      "\n",
      "Market Alpha:\n",
      "  OOS Strategy: 0.007746\n",
      "  In-Sample Strategy: 0.055334\n",
      "  Difference: -0.047588\n",
      "\n",
      "Market Beta:\n",
      "  OOS Strategy: -1.250617\n",
      "  In-Sample Strategy: -0.431638\n",
      "  Difference: -0.818979\n",
      "\n",
      "Information Ratio (annualized):\n",
      "  OOS Strategy: 0.567514\n",
      "  In-Sample Strategy: 1.418252\n",
      "  Difference: -0.850738\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. Redo 3.2 with OOS Forecasts\n",
    "# Build trading strategy using out-of-sample forecasts and compare to in-sample\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRADING STRATEGY FROM OUT-OF-SAMPLE FORECASTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# We need to rebuild the OOS procedure to get forecasts and build the strategy\n",
    "# The forecasts from the previous cell should be available, but let's rebuild to ensure we have everything\n",
    "\n",
    "# Rebuild OOS forecasts and strategy returns\n",
    "oos_forecasts_list = []\n",
    "oos_weights_list = []\n",
    "oos_strategy_returns_list = []\n",
    "oos_actual_returns_list = []\n",
    "oos_dates = []\n",
    "\n",
    "# Align data (same as before)\n",
    "common_idx = signals.index.intersection(spy_excess.index)\n",
    "signals_aligned = signals.loc[common_idx, [dp_col, ep_col]]\n",
    "spy_aligned = spy_excess.loc[common_idx]\n",
    "\n",
    "signals_aligned = signals_aligned.sort_index()\n",
    "spy_aligned = spy_aligned.sort_index()\n",
    "\n",
    "valid_mask = ~(signals_aligned.isna().any(axis=1) | spy_aligned.isna())\n",
    "signals_clean = signals_aligned[valid_mask]\n",
    "spy_clean = spy_aligned[valid_mask]\n",
    "\n",
    "start_idx = 60\n",
    "T = len(spy_clean)\n",
    "\n",
    "print(f\"\\nBuilding OOS trading strategy from t={start_idx} to t={T-2}...\")\n",
    "\n",
    "for t in range(start_idx, T - 1):\n",
    "    # Data through time t (for estimation)\n",
    "    spy_train = spy_clean.iloc[:t+1]\n",
    "    signals_train = signals_clean.iloc[:t+1]\n",
    "    \n",
    "    # X_t (predictors at time t) for forecasting\n",
    "    x_t = signals_clean.iloc[t:t+1]\n",
    "    \n",
    "    # r^{SPY}_{t+1} (actual return at time t+1)\n",
    "    r_t_plus_1 = spy_clean.iloc[t+1]\n",
    "    date_t_plus_1 = spy_clean.index[t+1]\n",
    "    \n",
    "    # Drop NaN from training data\n",
    "    train_mask = ~(signals_train.isna().any(axis=1) | spy_train.isna())\n",
    "    signals_train_clean = signals_train[train_mask]\n",
    "    spy_train_clean = spy_train[train_mask]\n",
    "    \n",
    "    if len(signals_train_clean) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Estimate regression using data through time t (with lagging)\n",
    "    signals_train_lagged = signals_train_clean.shift(1).iloc[1:]\n",
    "    spy_train_aligned = spy_train_clean.iloc[1:]\n",
    "    \n",
    "    common_train_idx = signals_train_lagged.index.intersection(spy_train_aligned.index)\n",
    "    signals_train_final = signals_train_lagged.loc[common_train_idx]\n",
    "    spy_train_final = spy_train_aligned.loc[common_train_idx]\n",
    "    \n",
    "    if len(signals_train_final) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Fit regression\n",
    "    X_train = signals_train_final.values\n",
    "    y_train = spy_train_final.values\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X_train, y_train)\n",
    "    \n",
    "    # Forecast r^{SPY}_{t+1} using x_t\n",
    "    x_t_values = x_t.values\n",
    "    forecast = reg.intercept_ + np.dot(reg.coef_, x_t_values[0])\n",
    "    \n",
    "    # Portfolio weight: w_t = 100 * r̂^{SPY}_{t+1}\n",
    "    weight = 100 * forecast\n",
    "    \n",
    "    # Strategy return: r^x_{t+1} = w_t * r^{SPY}_{t+1}\n",
    "    strategy_return = weight * r_t_plus_1\n",
    "    \n",
    "    # Store results\n",
    "    oos_forecasts_list.append(forecast)\n",
    "    oos_weights_list.append(weight)\n",
    "    oos_strategy_returns_list.append(strategy_return)\n",
    "    oos_actual_returns_list.append(r_t_plus_1)\n",
    "    oos_dates.append(date_t_plus_1)\n",
    "\n",
    "# Create Series for OOS strategy\n",
    "oos_strategy_returns = pd.Series(oos_strategy_returns_list, index=oos_dates)\n",
    "oos_actual_returns_series = pd.Series(oos_actual_returns_list, index=oos_dates)\n",
    "\n",
    "# Calculate OOS strategy statistics\n",
    "def calculate_strategy_stats_oos(strategy_returns, market_returns):\n",
    "    \"\"\"Calculate statistics for OOS trading strategy.\"\"\"\n",
    "    if len(strategy_returns) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Mean, volatility, Sharpe (annualized)\n",
    "    mean_monthly = strategy_returns.mean()\n",
    "    vol_monthly = strategy_returns.std()\n",
    "    sharpe_monthly = mean_monthly / vol_monthly if vol_monthly > 0 else np.nan\n",
    "    \n",
    "    mean_annual = mean_monthly * 12\n",
    "    vol_annual = vol_monthly * np.sqrt(12)\n",
    "    sharpe_annual = mean_annual / vol_annual if vol_annual > 0 else np.nan\n",
    "    \n",
    "    # Maximum drawdown\n",
    "    cumulative = (1 + strategy_returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Market alpha and beta\n",
    "    # Align indices\n",
    "    common_idx = strategy_returns.index.intersection(market_returns.index)\n",
    "    strategy_aligned = strategy_returns.loc[common_idx]\n",
    "    market_aligned = market_returns.loc[common_idx]\n",
    "    \n",
    "    if len(strategy_aligned) > 0:\n",
    "        X = market_aligned.values.reshape(-1, 1)\n",
    "        y = strategy_aligned.values\n",
    "        \n",
    "        reg = LinearRegression()\n",
    "        reg.fit(X, y)\n",
    "        y_pred = reg.predict(X)\n",
    "        \n",
    "        alpha = reg.intercept_\n",
    "        beta = reg.coef_[0]\n",
    "        \n",
    "        # Information ratio = alpha / tracking error\n",
    "        residuals = y - y_pred\n",
    "        tracking_error = np.std(residuals)\n",
    "        information_ratio = alpha / tracking_error if tracking_error > 0 else np.nan\n",
    "        info_ratio_annual = information_ratio * np.sqrt(12) if not np.isnan(information_ratio) else np.nan\n",
    "    else:\n",
    "        alpha = np.nan\n",
    "        beta = np.nan\n",
    "        info_ratio_annual = np.nan\n",
    "    \n",
    "    return {\n",
    "        'Mean (annualized)': mean_annual,\n",
    "        'Volatility (annualized)': vol_annual,\n",
    "        'Sharpe Ratio (annualized)': sharpe_annual,\n",
    "        'Max Drawdown': max_drawdown,\n",
    "        'Market Alpha': alpha,\n",
    "        'Market Beta': beta,\n",
    "        'Information Ratio (annualized)': info_ratio_annual,\n",
    "        'N observations': len(strategy_returns)\n",
    "    }\n",
    "\n",
    "# Calculate OOS strategy statistics\n",
    "oos_stats = calculate_strategy_stats_oos(oos_strategy_returns, spy_excess)\n",
    "\n",
    "# Get in-sample strategy statistics (Strategy 3 from section 3.2, which used DP and EP)\n",
    "# Note: strategy3 should be available from the earlier code\n",
    "in_sample_stats = stats3 if 'stats3' in globals() and stats3 else None\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUT-OF-SAMPLE STRATEGY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "if oos_stats:\n",
    "    for key, value in oos_stats.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key}: {value:.6f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IN-SAMPLE STRATEGY STATISTICS (from section 3.2)\")\n",
    "print(\"=\"*80)\n",
    "if in_sample_stats:\n",
    "    for key, value in in_sample_stats.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key}: {value:.6f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"In-sample statistics not available. Please run section 3.2 first.\")\n",
    "\n",
    "# Comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: OOS vs IN-SAMPLE STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if oos_stats and in_sample_stats:\n",
    "    print(\"\\nMean Return (annualized):\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Mean (annualized)']:.6f} ({oos_stats['Mean (annualized)']*100:.2f}%)\")\n",
    "    print(f\"  In-Sample Strategy: {in_sample_stats['Mean (annualized)']:.6f} ({in_sample_stats['Mean (annualized)']*100:.2f}%)\")\n",
    "    mean_diff = oos_stats['Mean (annualized)'] - in_sample_stats['Mean (annualized)']\n",
    "    print(f\"  Difference: {mean_diff:+.6f} ({mean_diff*100:+.2f}%)\")\n",
    "    \n",
    "    print(\"\\nVolatility (annualized):\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Volatility (annualized)']:.6f} ({oos_stats['Volatility (annualized)']*100:.2f}%)\")\n",
    "    print(f\"  In-Sample Strategy: {in_sample_stats['Volatility (annualized)']:.6f} ({in_sample_stats['Volatility (annualized)']*100:.2f}%)\")\n",
    "    vol_diff = oos_stats['Volatility (annualized)'] - in_sample_stats['Volatility (annualized)']\n",
    "    print(f\"  Difference: {vol_diff:+.6f} ({vol_diff*100:+.2f}%)\")\n",
    "    \n",
    "    print(\"\\nSharpe Ratio (annualized):\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  In-Sample Strategy: {in_sample_stats['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    sharpe_diff = oos_stats['Sharpe Ratio (annualized)'] - in_sample_stats['Sharpe Ratio (annualized)']\n",
    "    print(f\"  Difference: {sharpe_diff:+.6f}\")\n",
    "    \n",
    "    print(\"\\nMaximum Drawdown:\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Max Drawdown']:.6f} ({oos_stats['Max Drawdown']*100:.2f}%)\")\n",
    "    print(f\"  In-Sample Strategy: {in_sample_stats['Max Drawdown']:.6f} ({in_sample_stats['Max Drawdown']*100:.2f}%)\")\n",
    "    dd_diff = oos_stats['Max Drawdown'] - in_sample_stats['Max Drawdown']\n",
    "    print(f\"  Difference: {dd_diff:+.6f} ({dd_diff*100:+.2f}%)\")\n",
    "    \n",
    "    print(\"\\nMarket Alpha:\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Market Alpha']:.6f}\")\n",
    "    print(f\"  In-Sample Strategy: {in_sample_stats['Market Alpha']:.6f}\")\n",
    "    alpha_diff = oos_stats['Market Alpha'] - in_sample_stats['Market Alpha']\n",
    "    print(f\"  Difference: {alpha_diff:+.6f}\")\n",
    "    \n",
    "    print(\"\\nMarket Beta:\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Market Beta']:.6f}\")\n",
    "    print(f\"  In-Sample Strategy: {in_sample_stats['Market Beta']:.6f}\")\n",
    "    beta_diff = oos_stats['Market Beta'] - in_sample_stats['Market Beta']\n",
    "    print(f\"  Difference: {beta_diff:+.6f}\")\n",
    "    \n",
    "    print(\"\\nInformation Ratio (annualized):\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Information Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  In-Sample Strategy: {in_sample_stats['Information Ratio (annualized)']:.6f}\")\n",
    "    ir_diff = oos_stats['Information Ratio (annualized)'] - in_sample_stats['Information Ratio (annualized)']\n",
    "    print(f\"  Difference: {ir_diff:+.6f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41986e7",
   "metadata": {},
   "source": [
    "How does the OOS strategy compare to the in-sample version?\n",
    "\n",
    "Key observations:\n",
    "  - OOS strategy has LOWER mean return than in-sample\n",
    "  - OOS strategy has WORSE risk-adjusted returns (lower Sharpe)\n",
    "  - OOS strategy has LOWER volatility than in-sample\n",
    "\n",
    "Note: OOS strategy is more realistic as it uses only information available at each point in time.\n",
    "In-sample strategy may be overfitted to the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21cb2a0",
   "metadata": {},
   "source": [
    "3. **Redo 3.3 with OOS forecasts.** Is the point‑in‑time version of the strategy **riskier**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08a064c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "RISK CHARACTERISTICS: OOS STRATEGY vs IN-SAMPLE STRATEGY\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "1. Monthly VaR at π = 0.05 (5th percentile)\n",
      "================================================================================\n",
      "OOS Strategy: -0.080101 (-8.01%)\n",
      "In-Sample Strategy: -0.065591 (-6.56%)\n",
      "Market (SPY): -0.098914 (-9.89%)\n",
      "GMO (GMWAX): -0.077006 (-7.70%)\n",
      "\n",
      "================================================================================\n",
      "2. OOS Strategy Performance vs Risk-Free Rate (2000-2011)\n",
      "================================================================================\n",
      "\n",
      "Period: 2000-01-01 to 2011-12-31\n",
      "Risk-free rate (monthly, average): 0.022875 (2.29%)\n",
      "\n",
      "OOS Strategy:\n",
      "  Mean monthly return: 0.017031 (1.70%)\n",
      "  Mean excess over RF: -0.001095 (-0.11%)\n",
      "  Cumulative excess return: -0.325721 (-32.57%)\n",
      "  ✓ Underperforms risk-free rate\n",
      "\n",
      "In-Sample Strategy:\n",
      "  Mean monthly return: 0.078094 (7.81%)\n",
      "  Mean excess over RF: 0.055218 (5.52%)\n",
      "  Cumulative excess return: 643.748892 (64374.89%)\n",
      "  ✗ Outperforms risk-free rate\n",
      "\n",
      "================================================================================\n",
      "3. Periods with Negative Risk Premium (OOS forecasts)\n",
      "================================================================================\n",
      "\n",
      "OOS Strategy:\n",
      "  Periods with negative risk premium: 265 out of 286 (92.66%)\n",
      "\n",
      "In-Sample Strategy (from section 3.3):\n",
      "  Periods with negative risk premium: 231 out of 347 (66.57%)\n",
      "\n",
      "================================================================================\n",
      "4. Is the Point-in-Time (OOS) Strategy Riskier?\n",
      "================================================================================\n",
      "\n",
      "Risk Comparison:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Volatility (annualized):\n",
      "  OOS Strategy: 0.259100 (25.91%)\n",
      "  In-Sample Strategy: 0.474515 (47.45%)\n",
      "  Market (SPY): 0.168869 (16.89%)\n",
      "\n",
      "  OOS vs In-Sample: -0.215415 (-21.54%)\n",
      "  OOS vs Market: +0.090231 (+9.02%)\n",
      "\n",
      "VaR (5th percentile):\n",
      "  OOS Strategy: -0.080101 (-8.01%)\n",
      "  In-Sample Strategy: -0.065591 (-6.56%)\n",
      "  Market (SPY): -0.098914 (-9.89%)\n",
      "\n",
      "  OOS vs In-Sample: -0.014510 (-1.45%)\n",
      "  OOS vs Market: +0.018813 (+1.88%)\n",
      "  (More negative = riskier)\n",
      "\n",
      "Maximum Drawdown:\n",
      "  OOS Strategy: -0.747516 (-74.75%)\n",
      "  In-Sample Strategy: -0.494226 (-49.42%)\n",
      "  Market (SPY): -0.993738 (-99.37%)\n",
      "\n",
      "  OOS vs In-Sample: -0.253290 (-25.33%)\n",
      "  OOS vs Market: +0.246223 (+24.62%)\n",
      "  (More negative = riskier)\n",
      "\n",
      "Market Beta:\n",
      "  OOS Strategy: -1.250617\n",
      "  In-Sample Strategy: -0.431638\n",
      "  Market (SPY): 1.0 (by definition)\n",
      "\n",
      "  OOS vs In-Sample: -0.818979\n",
      "  OOS vs Market: -2.250617\n",
      "  (Higher = riskier)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. Redo 3.3 with OOS Forecasts - Risk Characteristics\n",
    "# Is the point-in-time (OOS) version of the strategy riskier?\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RISK CHARACTERISTICS: OOS STRATEGY vs IN-SAMPLE STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Compute monthly VaR at π = 0.05 for OOS strategy\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_var(returns, percentile=0.05):\n",
    "    \"\"\"Calculate Value at Risk (VaR) using historical quantile.\"\"\"\n",
    "    if len(returns) == 0:\n",
    "        return np.nan\n",
    "    return returns.quantile(percentile)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. Monthly VaR at π = 0.05 (5th percentile)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# OOS strategy VaR\n",
    "if 'oos_strategy_returns' in globals() and len(oos_strategy_returns) > 0:\n",
    "    var_oos = calculate_var(oos_strategy_returns, 0.05)\n",
    "    print(f\"OOS Strategy: {var_oos:.6f} ({var_oos*100:.2f}%)\")\n",
    "else:\n",
    "    var_oos = np.nan\n",
    "    print(\"OOS Strategy: Not available\")\n",
    "\n",
    "# In-sample strategy VaR (from section 3.3)\n",
    "if 'strategy3' in globals() and strategy3:\n",
    "    var_in_sample = calculate_var(strategy3['strategy_returns'], 0.05)\n",
    "    print(f\"In-Sample Strategy: {var_in_sample:.6f} ({var_in_sample*100:.2f}%)\")\n",
    "else:\n",
    "    var_in_sample = np.nan\n",
    "    print(\"In-Sample Strategy: Not available\")\n",
    "\n",
    "# Market and GMO VaR (for reference)\n",
    "market_returns = spy_excess\n",
    "gmo_returns = excess_returns['GMWAX'].dropna()\n",
    "var_market = calculate_var(market_returns, 0.05)\n",
    "var_gmo = calculate_var(gmo_returns, 0.05)\n",
    "print(f\"Market (SPY): {var_market:.6f} ({var_market*100:.2f}%)\")\n",
    "print(f\"GMO (GMWAX): {var_gmo:.6f} ({var_gmo*100:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Check if OOS strategy underperforms risk-free rate from 2000-2011\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. OOS Strategy Performance vs Risk-Free Rate (2000-2011)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "start_2000 = pd.Timestamp('2000-01-01')\n",
    "end_2011 = pd.Timestamp('2011-12-31')\n",
    "\n",
    "# Get risk-free rate for this period\n",
    "rf_period = risk_free_rate['TBill 3M'].loc[(risk_free_rate.index >= start_2000) & \n",
    "                                            (risk_free_rate.index <= end_2011)]\n",
    "\n",
    "# Convert to monthly if annualized\n",
    "if rf_period.max() > 0.1:\n",
    "    rf_monthly = rf_period / 12\n",
    "else:\n",
    "    rf_monthly = rf_period\n",
    "\n",
    "print(f\"\\nPeriod: {start_2000.date()} to {end_2011.date()}\")\n",
    "print(f\"Risk-free rate (monthly, average): {rf_monthly.mean():.6f} ({rf_monthly.mean()*100:.2f}%)\")\n",
    "\n",
    "# OOS strategy performance\n",
    "if 'oos_strategy_returns' in globals() and len(oos_strategy_returns) > 0:\n",
    "    oos_period = oos_strategy_returns.loc[(oos_strategy_returns.index >= start_2000) & \n",
    "                                          (oos_strategy_returns.index <= end_2011)]\n",
    "    \n",
    "    if len(oos_period) > 0:\n",
    "        common_idx = oos_period.index.intersection(rf_monthly.index)\n",
    "        oos_aligned = oos_period.loc[common_idx]\n",
    "        rf_aligned = rf_monthly.loc[common_idx]\n",
    "        \n",
    "        excess_over_rf_oos = oos_aligned - rf_aligned\n",
    "        mean_excess_oos = excess_over_rf_oos.mean()\n",
    "        total_excess_oos = (1 + excess_over_rf_oos).prod() - 1\n",
    "        \n",
    "        print(f\"\\nOOS Strategy:\")\n",
    "        print(f\"  Mean monthly return: {oos_aligned.mean():.6f} ({oos_aligned.mean()*100:.2f}%)\")\n",
    "        print(f\"  Mean excess over RF: {mean_excess_oos:.6f} ({mean_excess_oos*100:.2f}%)\")\n",
    "        print(f\"  Cumulative excess return: {total_excess_oos:.6f} ({total_excess_oos*100:.2f}%)\")\n",
    "        \n",
    "        if mean_excess_oos < 0:\n",
    "            print(f\"  ✓ Underperforms risk-free rate\")\n",
    "        else:\n",
    "            print(f\"  ✗ Outperforms risk-free rate\")\n",
    "\n",
    "# In-sample strategy performance (for comparison)\n",
    "if 'strategy3' in globals() and strategy3:\n",
    "    in_sample_period = strategy3['strategy_returns'].loc[(strategy3['strategy_returns'].index >= start_2000) & \n",
    "                                                         (strategy3['strategy_returns'].index <= end_2011)]\n",
    "    \n",
    "    if len(in_sample_period) > 0:\n",
    "        common_idx = in_sample_period.index.intersection(rf_monthly.index)\n",
    "        in_sample_aligned = in_sample_period.loc[common_idx]\n",
    "        rf_aligned = rf_monthly.loc[common_idx]\n",
    "        \n",
    "        excess_over_rf_in = in_sample_aligned - rf_aligned\n",
    "        mean_excess_in = excess_over_rf_in.mean()\n",
    "        total_excess_in = (1 + excess_over_rf_in).prod() - 1\n",
    "        \n",
    "        print(f\"\\nIn-Sample Strategy:\")\n",
    "        print(f\"  Mean monthly return: {in_sample_aligned.mean():.6f} ({in_sample_aligned.mean()*100:.2f}%)\")\n",
    "        print(f\"  Mean excess over RF: {mean_excess_in:.6f} ({mean_excess_in*100:.2f}%)\")\n",
    "        print(f\"  Cumulative excess return: {total_excess_in:.6f} ({total_excess_in*100:.2f}%)\")\n",
    "        \n",
    "        if mean_excess_in < 0:\n",
    "            print(f\"  ✓ Underperforms risk-free rate\")\n",
    "        else:\n",
    "            print(f\"  ✗ Outperforms risk-free rate\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Count periods with negative risk premium (based on OOS forecasts)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. Periods with Negative Risk Premium (OOS forecasts)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count negative forecasts from OOS procedure\n",
    "if 'oos_forecasts_list' in globals() and len(oos_forecasts_list) > 0:\n",
    "    oos_forecasts_array = np.array(oos_forecasts_list)\n",
    "    negative_count_oos = np.sum(oos_forecasts_array < 0)\n",
    "    total_count_oos = len(oos_forecasts_array)\n",
    "    negative_pct_oos = (negative_count_oos / total_count_oos) * 100 if total_count_oos > 0 else 0\n",
    "    \n",
    "    print(f\"\\nOOS Strategy:\")\n",
    "    print(f\"  Periods with negative risk premium: {negative_count_oos} out of {total_count_oos} ({negative_pct_oos:.2f}%)\")\n",
    "else:\n",
    "    print(\"\\nOOS forecasts not available\")\n",
    "\n",
    "# In-sample comparison (from section 3.3)\n",
    "if 'neg3' in globals() and neg3:\n",
    "    print(f\"\\nIn-Sample Strategy (from section 3.3):\")\n",
    "    print(f\"  Periods with negative risk premium: {neg3['negative_count']} out of {neg3['total_count']} ({neg3['negative_pct']:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Assess if OOS strategy takes on extra risk (compared to in-sample and market)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. Is the Point-in-Time (OOS) Strategy Riskier?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nRisk Comparison:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Get statistics\n",
    "oos_stats_available = 'oos_stats' in globals() and oos_stats\n",
    "in_sample_stats_available = 'stats3' in globals() and stats3\n",
    "\n",
    "if oos_stats_available and in_sample_stats_available:\n",
    "    print(\"\\nVolatility (annualized):\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Volatility (annualized)']:.6f} ({oos_stats['Volatility (annualized)']*100:.2f}%)\")\n",
    "    print(f\"  In-Sample Strategy: {stats3['Volatility (annualized)']:.6f} ({stats3['Volatility (annualized)']*100:.2f}%)\")\n",
    "    print(f\"  Market (SPY): {market_returns.std() * np.sqrt(12):.6f} ({market_returns.std() * np.sqrt(12)*100:.2f}%)\")\n",
    "    \n",
    "    vol_diff = oos_stats['Volatility (annualized)'] - stats3['Volatility (annualized)']\n",
    "    vol_diff_market = oos_stats['Volatility (annualized)'] - (market_returns.std() * np.sqrt(12))\n",
    "    \n",
    "    print(f\"\\n  OOS vs In-Sample: {vol_diff:+.6f} ({vol_diff*100:+.2f}%)\")\n",
    "    print(f\"  OOS vs Market: {vol_diff_market:+.6f} ({vol_diff_market*100:+.2f}%)\")\n",
    "    \n",
    "    print(\"\\nVaR (5th percentile):\")\n",
    "    print(f\"  OOS Strategy: {var_oos:.6f} ({var_oos*100:.2f}%)\")\n",
    "    print(f\"  In-Sample Strategy: {var_in_sample:.6f} ({var_in_sample*100:.2f}%)\")\n",
    "    print(f\"  Market (SPY): {var_market:.6f} ({var_market*100:.2f}%)\")\n",
    "    \n",
    "    var_diff = var_oos - var_in_sample\n",
    "    var_diff_market = var_oos - var_market\n",
    "    \n",
    "    print(f\"\\n  OOS vs In-Sample: {var_diff:+.6f} ({var_diff*100:+.2f}%)\")\n",
    "    print(f\"  OOS vs Market: {var_diff_market:+.6f} ({var_diff_market*100:+.2f}%)\")\n",
    "    print(f\"  (More negative = riskier)\")\n",
    "    \n",
    "    print(\"\\nMaximum Drawdown:\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Max Drawdown']:.6f} ({oos_stats['Max Drawdown']*100:.2f}%)\")\n",
    "    print(f\"  In-Sample Strategy: {stats3['Max Drawdown']:.6f} ({stats3['Max Drawdown']*100:.2f}%)\")\n",
    "    \n",
    "    # Market max drawdown\n",
    "    market_cumulative = (1 + market_returns).cumprod()\n",
    "    market_running_max = market_cumulative.expanding().max()\n",
    "    market_drawdown = (market_cumulative - market_running_max) / market_running_max\n",
    "    market_max_dd = market_drawdown.min()\n",
    "    \n",
    "    print(f\"  Market (SPY): {market_max_dd:.6f} ({market_max_dd*100:.2f}%)\")\n",
    "    \n",
    "    dd_diff = oos_stats['Max Drawdown'] - stats3['Max Drawdown']\n",
    "    dd_diff_market = oos_stats['Max Drawdown'] - market_max_dd\n",
    "    \n",
    "    print(f\"\\n  OOS vs In-Sample: {dd_diff:+.6f} ({dd_diff*100:+.2f}%)\")\n",
    "    print(f\"  OOS vs Market: {dd_diff_market:+.6f} ({dd_diff_market*100:+.2f}%)\")\n",
    "    print(f\"  (More negative = riskier)\")\n",
    "    \n",
    "    print(\"\\nMarket Beta:\")\n",
    "    print(f\"  OOS Strategy: {oos_stats['Market Beta']:.6f}\")\n",
    "    print(f\"  In-Sample Strategy: {stats3['Market Beta']:.6f}\")\n",
    "    print(f\"  Market (SPY): 1.0 (by definition)\")\n",
    "    \n",
    "    beta_diff = oos_stats['Market Beta'] - stats3['Market Beta']\n",
    "    beta_diff_market = oos_stats['Market Beta'] - 1.0\n",
    "    \n",
    "    print(f\"\\n  OOS vs In-Sample: {beta_diff:+.6f}\")\n",
    "    print(f\"  OOS vs Market: {beta_diff_market:+.6f}\")\n",
    "    print(f\"  (Higher = riskier)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9c6b82",
   "metadata": {},
   "source": [
    "\n",
    "The OOS strategy shows mixed risk characteristics.\n",
    "  Some risk indicators suggest it's riskier (2 out of 4), but not consistently.\n",
    "  Risk indicators: Worse VaR (more negative), Larger maximum drawdown\n",
    "\n",
    "Comparison to Market:\n",
    "  - OOS strategy has HIGHER volatility than market\n",
    "  - OOS strategy has BETTER VaR than market (less risky)\n",
    "  - OOS strategy has SMALLER maximum drawdown than market (less risky)\n",
    "  - OOS strategy has LOWER beta than market (less risky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 EXTRA: ML Forecasts\n",
    "\n",
    "1. **CART.** Re‑do Section 3 using **CART** (e.g., `RandomForestRegressor` from `sklearn.ensemble`). If you want to visualize, try `sklearn.tree`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec64d993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ML FORECASTS: CART (RandomForestRegressor)\n",
      "================================================================================\n",
      "\n",
      "Re-doing Section 3 using RandomForestRegressor instead of linear regression\n",
      "\n",
      "Data range: 1996-12-31 to 2025-10-31\n",
      "Total observations: 347\n",
      "\n",
      "================================================================================\n",
      "1. CART Regression: r^SPY_t = f(X_{t-1}) using RandomForestRegressor\n",
      "================================================================================\n",
      "\n",
      "1.1. CART Regression with DP only:\n",
      "--------------------------------------------------------------------------------\n",
      "R²: 0.805219\n",
      "Feature Importance (DP): 1.000000\n",
      "N observations: 346\n",
      "\n",
      "1.2. CART Regression with EP only:\n",
      "--------------------------------------------------------------------------------\n",
      "R²: 0.805305\n",
      "Feature Importance (EP): 1.000000\n",
      "N observations: 346\n",
      "\n",
      "1.3. CART Regression with DP, EP, and 10-year yield:\n",
      "--------------------------------------------------------------------------------\n",
      "R²: 0.872010\n",
      "Feature Importance:\n",
      "  SPX D/P: 0.320564\n",
      "  SPX E/P: 0.261813\n",
      "  T-Note 10YR: 0.417624\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: CART Regression R²\n",
      "================================================================================\n",
      "                   Model       R²\n",
      "          DP only (CART) 0.805219\n",
      "          EP only (CART) 0.805305\n",
      "DP, EP, 10Y Yield (CART) 0.872010\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Comparison with Linear Regression (from Section 3):\n",
      "  DP only - Linear: 0.103106, CART: 0.805219, Difference: +0.702113\n",
      "  EP only - Linear: 0.018921, CART: 0.805305, Difference: +0.786384\n",
      "  DP, EP, 10Y - Linear: 0.183655, CART: 0.872010, Difference: +0.688355\n",
      "\n",
      "================================================================================\n",
      "2. Trading Strategy from CART Forecasts (re-do Section 3.2)\n",
      "================================================================================\n",
      "\n",
      "Building CART trading strategies...\n",
      "\n",
      "================================================================================\n",
      "CART STRATEGY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Strategy 1: DP only (CART)\n",
      "--------------------------------------------------------------------------------\n",
      "Mean (annualized): 2.053908\n",
      "Volatility (annualized): 1.012724\n",
      "Sharpe Ratio (annualized): 2.028103\n",
      "Max Drawdown: -0.054923\n",
      "Market Alpha: 0.152190\n",
      "Market Beta: -1.406729\n",
      "Information Ratio (annualized): 1.857931\n",
      "N observations: 346\n",
      "\n",
      "Strategy 2: EP only (CART)\n",
      "--------------------------------------------------------------------------------\n",
      "Mean (annualized): 2.055024\n",
      "Volatility (annualized): 0.998472\n",
      "Sharpe Ratio (annualized): 2.058169\n",
      "Max Drawdown: -0.126299\n",
      "Market Alpha: 0.154748\n",
      "Market Beta: -1.223876\n",
      "Information Ratio (annualized): 1.903869\n",
      "N observations: 346\n",
      "\n",
      "Strategy 3: DP, EP, 10Y Yield (CART)\n",
      "--------------------------------------------------------------------------------\n",
      "Mean (annualized): 2.241944\n",
      "Volatility (annualized): 1.072244\n",
      "Sharpe Ratio (annualized): 2.090890\n",
      "Max Drawdown: -0.026462\n",
      "Market Alpha: 0.168256\n",
      "Market Beta: -1.377334\n",
      "Information Ratio (annualized): 1.931891\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: CART vs Linear Regression Strategies\n",
      "================================================================================\n",
      "\n",
      "Focusing on Strategy 3 (DP, EP, 10Y Yield) for comparison:\n",
      "\n",
      "Mean Return (annualized):\n",
      "  CART: 2.241944\n",
      "  Linear: 0.733855\n",
      "  Difference: +1.508089\n",
      "\n",
      "Volatility (annualized):\n",
      "  CART: 1.072244\n",
      "  Linear: 0.474515\n",
      "  Difference: +0.597730\n",
      "\n",
      "Sharpe Ratio (annualized):\n",
      "  CART: 2.090890\n",
      "  Linear: 1.546539\n",
      "  Difference: +0.544351\n",
      "\n",
      "Maximum Drawdown:\n",
      "  CART: -0.026462\n",
      "  Linear: -0.494226\n",
      "  Difference: +0.467764\n",
      "\n",
      "Market Alpha:\n",
      "  CART: 0.168256\n",
      "  Linear: 0.055334\n",
      "  Difference: +0.112922\n",
      "\n",
      "Market Beta:\n",
      "  CART: -1.377334\n",
      "  Linear: -0.431638\n",
      "  Difference: -0.945696\n",
      "\n",
      "Information Ratio (annualized):\n",
      "  CART: 1.931891\n",
      "  Linear: 1.418252\n",
      "  Difference: +0.513640\n",
      "\n",
      "================================================================================\n",
      "3. Risk Characteristics for CART Strategies (re-do Section 3.3)\n",
      "================================================================================\n",
      "\n",
      "Monthly VaR at π = 0.05:\n",
      "--------------------------------------------------------------------------------\n",
      "Strategy 1 (DP only, CART): -0.006326 (-0.63%)\n",
      "Strategy 2 (EP only, CART): -0.007280 (-0.73%)\n",
      "Strategy 3 (DP, EP, 10Y, CART): -0.004247 (-0.42%)\n",
      "\n",
      "Comparison with Linear Regression:\n",
      "  DP only - Linear: -0.078998, CART: -0.006326\n",
      "  EP only - Linear: -0.074008, CART: -0.007280\n",
      "  DP, EP, 10Y - Linear: -0.065591, CART: -0.004247\n",
      "\n",
      "================================================================================\n",
      "CART IMPLEMENTATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Note: CART (RandomForest) can capture non-linear relationships that linear regression cannot.\n",
      "However, it may also be more prone to overfitting, especially with small datasets.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. EXTRA: ML Forecasts - CART (RandomForestRegressor)\n",
    "# Re-do Section 3 using CART instead of linear regression\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ML FORECASTS: CART (RandomForestRegressor)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nRe-doing Section 3 using RandomForestRegressor instead of linear regression\")\n",
    "\n",
    "# Align data\n",
    "common_idx = signals.index.intersection(spy_excess.index)\n",
    "signals_aligned = signals.loc[common_idx, [dp_col, ep_col, yield_col]]\n",
    "spy_aligned = spy_excess.loc[common_idx]\n",
    "\n",
    "signals_aligned = signals_aligned.sort_index()\n",
    "spy_aligned = spy_aligned.sort_index()\n",
    "\n",
    "valid_mask = ~(signals_aligned.isna().any(axis=1) | spy_aligned.isna())\n",
    "signals_clean = signals_aligned[valid_mask]\n",
    "spy_clean = spy_aligned[valid_mask]\n",
    "\n",
    "print(f\"\\nData range: {spy_clean.index.min().date()} to {spy_clean.index.max().date()}\")\n",
    "print(f\"Total observations: {len(spy_clean)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Lagged Regression using CART (RandomForestRegressor)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. CART Regression: r^SPY_t = f(X_{t-1}) using RandomForestRegressor\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to perform lagged regression using RandomForest\n",
    "def lagged_regression_cart(y, X, X_names, model_type='random_forest', n_estimators=100, max_depth=None):\n",
    "    \"\"\"\n",
    "    Perform lagged regression using CART (RandomForest or DecisionTree).\n",
    "    \n",
    "    Parameters:\n",
    "    y: Series of dependent variable (SPY returns at time t)\n",
    "    X: DataFrame of predictors (at time t-1)\n",
    "    X_names: List of predictor names\n",
    "    model_type: 'random_forest' or 'decision_tree'\n",
    "    n_estimators: Number of trees for RandomForest\n",
    "    max_depth: Maximum depth of trees\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with model, R², and other statistics\n",
    "    \"\"\"\n",
    "    # Align indices - y at time t, X at time t-1\n",
    "    X_lagged = X[X_names].shift(1)  # Shift forward so X[t-1] aligns with y[t]\n",
    "    \n",
    "    # Align indices\n",
    "    common_idx = y.index.intersection(X_lagged.index)\n",
    "    y_aligned = y.loc[common_idx]\n",
    "    X_aligned = X_lagged.loc[common_idx]\n",
    "    \n",
    "    # Drop rows with NaN\n",
    "    valid_mask = ~(X_aligned.isna().any(axis=1) | y_aligned.isna())\n",
    "    y_clean = y_aligned[valid_mask]\n",
    "    X_clean = X_aligned[valid_mask]\n",
    "    \n",
    "    if len(y_clean) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    X_values = X_clean.values\n",
    "    y_values = y_clean.values\n",
    "    \n",
    "    # Fit CART model\n",
    "    if model_type == 'random_forest':\n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    else:\n",
    "        model = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
    "    \n",
    "    model.fit(X_values, y_values)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_values)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    ss_res = np.sum((y_values - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_values - np.mean(y_values)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "    \n",
    "    # Feature importance (for RandomForest)\n",
    "    if model_type == 'random_forest':\n",
    "        feature_importance = {name: imp for name, imp in zip(X_names, model.feature_importances_)}\n",
    "    else:\n",
    "        feature_importance = {name: 0 for name in X_names}  # DecisionTree doesn't have feature_importances_ in same way\n",
    "    \n",
    "    return {\n",
    "        'Model': model,\n",
    "        'Model Type': model_type,\n",
    "        'R²': r_squared,\n",
    "        'Feature Importance': feature_importance,\n",
    "        'N observations': len(y_clean),\n",
    "        'Predictions': y_pred,\n",
    "        'Actual': y_values\n",
    "    }\n",
    "\n",
    "# Perform CART regressions for three cases (similar to Section 3.1)\n",
    "print(\"\\n1.1. CART Regression with DP only:\")\n",
    "print(\"-\" * 80)\n",
    "cart_reg1 = lagged_regression_cart(spy_clean, signals_clean, [dp_col], model_type='random_forest')\n",
    "if cart_reg1:\n",
    "    print(f\"R²: {cart_reg1['R²']:.6f}\")\n",
    "    print(f\"Feature Importance (DP): {cart_reg1['Feature Importance'][dp_col]:.6f}\")\n",
    "    print(f\"N observations: {cart_reg1['N observations']}\")\n",
    "else:\n",
    "    print(\"Regression failed\")\n",
    "\n",
    "print(\"\\n1.2. CART Regression with EP only:\")\n",
    "print(\"-\" * 80)\n",
    "cart_reg2 = lagged_regression_cart(spy_clean, signals_clean, [ep_col], model_type='random_forest')\n",
    "if cart_reg2:\n",
    "    print(f\"R²: {cart_reg2['R²']:.6f}\")\n",
    "    print(f\"Feature Importance (EP): {cart_reg2['Feature Importance'][ep_col]:.6f}\")\n",
    "    print(f\"N observations: {cart_reg2['N observations']}\")\n",
    "else:\n",
    "    print(\"Regression failed\")\n",
    "\n",
    "print(\"\\n1.3. CART Regression with DP, EP, and 10-year yield:\")\n",
    "print(\"-\" * 80)\n",
    "cart_reg3 = lagged_regression_cart(spy_clean, signals_clean, [dp_col, ep_col, yield_col], model_type='random_forest')\n",
    "if cart_reg3:\n",
    "    print(f\"R²: {cart_reg3['R²']:.6f}\")\n",
    "    print(f\"Feature Importance:\")\n",
    "    for name, imp in cart_reg3['Feature Importance'].items():\n",
    "        print(f\"  {name}: {imp:.6f}\")\n",
    "    print(f\"N observations: {cart_reg3['N observations']}\")\n",
    "else:\n",
    "    print(\"Regression failed\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: CART Regression R²\")\n",
    "print(\"=\"*80)\n",
    "summary_cart = []\n",
    "if cart_reg1:\n",
    "    summary_cart.append({'Model': 'DP only (CART)', 'R²': cart_reg1['R²']})\n",
    "if cart_reg2:\n",
    "    summary_cart.append({'Model': 'EP only (CART)', 'R²': cart_reg2['R²']})\n",
    "if cart_reg3:\n",
    "    summary_cart.append({'Model': 'DP, EP, 10Y Yield (CART)', 'R²': cart_reg3['R²']})\n",
    "\n",
    "if summary_cart:\n",
    "    summary_cart_df = pd.DataFrame(summary_cart)\n",
    "    print(summary_cart_df.to_string(index=False))\n",
    "    \n",
    "    # Compare with linear regression R² from Section 3\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"Comparison with Linear Regression (from Section 3):\")\n",
    "    if 'reg1' in globals() and reg1:\n",
    "        print(f\"  DP only - Linear: {reg1['R²']:.6f}, CART: {cart_reg1['R²']:.6f}, Difference: {cart_reg1['R²'] - reg1['R²']:+.6f}\")\n",
    "    if 'reg2' in globals() and reg2:\n",
    "        print(f\"  EP only - Linear: {reg2['R²']:.6f}, CART: {cart_reg2['R²']:.6f}, Difference: {cart_reg2['R²'] - reg2['R²']:+.6f}\")\n",
    "    if 'reg3' in globals() and reg3:\n",
    "        print(f\"  DP, EP, 10Y - Linear: {reg3['R²']:.6f}, CART: {cart_reg3['R²']:.6f}, Difference: {cart_reg3['R²'] - reg3['R²']:+.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Trading Strategy from CART Forecasts (re-do Section 3.2)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. Trading Strategy from CART Forecasts (re-do Section 3.2)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to build trading strategy from CART forecasts\n",
    "def build_trading_strategy_cart(cart_reg_result, signals_df, spy_returns, X_names, strategy_name):\n",
    "    \"\"\"\n",
    "    Build trading strategy from CART regression forecasts.\n",
    "    Similar to build_trading_strategy but uses CART model.\n",
    "    \"\"\"\n",
    "    if cart_reg_result is None:\n",
    "        return None\n",
    "    \n",
    "    model = cart_reg_result['Model']\n",
    "    \n",
    "    # Align data - we need X_t to forecast r^{SPY}_{t+1}\n",
    "    common_idx = signals_df.index.intersection(spy_returns.index)\n",
    "    signals_aligned = signals_df.loc[common_idx, X_names]\n",
    "    spy_aligned = spy_returns.loc[common_idx]\n",
    "    \n",
    "    # Shift spy_returns forward by 1 period so r^{SPY}_{t+1} aligns with X_t\n",
    "    spy_next = spy_aligned.shift(-1)\n",
    "    \n",
    "    # Align again after shift\n",
    "    common_idx_final = signals_aligned.index.intersection(spy_next.index)\n",
    "    signals_final = signals_aligned.loc[common_idx_final]\n",
    "    spy_next_final = spy_next.loc[common_idx_final]\n",
    "    \n",
    "    # Drop NaN\n",
    "    valid_mask = ~(signals_final.isna().any(axis=1) | spy_next_final.isna())\n",
    "    signals_clean = signals_final[valid_mask]\n",
    "    spy_next_clean = spy_next_final[valid_mask]\n",
    "    \n",
    "    if len(signals_clean) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Build forecasts using CART model\n",
    "    X_values = signals_clean.values\n",
    "    forecasts = model.predict(X_values)\n",
    "    \n",
    "    # Portfolio weights: w_t = 100 * r̂^{SPY}_{t+1}\n",
    "    weights = 100 * forecasts\n",
    "    \n",
    "    # Strategy returns: r^x_{t+1} = w_t * r^{SPY}_{t+1}\n",
    "    strategy_returns = weights * spy_next_clean.values\n",
    "    \n",
    "    # Create Series\n",
    "    strategy_returns_series = pd.Series(strategy_returns, index=signals_clean.index)\n",
    "    \n",
    "    return {\n",
    "        'strategy_name': strategy_name,\n",
    "        'forecasts': pd.Series(forecasts, index=signals_clean.index),\n",
    "        'weights': pd.Series(weights, index=signals_clean.index),\n",
    "        'strategy_returns': strategy_returns_series,\n",
    "        'spy_returns': spy_next_clean\n",
    "    }\n",
    "\n",
    "# Build strategies for all three CART models\n",
    "print(\"\\nBuilding CART trading strategies...\")\n",
    "\n",
    "# Strategy 1: DP only (CART)\n",
    "cart_strategy1 = build_trading_strategy_cart(cart_reg1, signals_clean, spy_clean, [dp_col], 'DP only (CART)')\n",
    "cart_stats1 = calculate_strategy_stats(cart_strategy1, spy_excess) if cart_strategy1 else None\n",
    "\n",
    "# Strategy 2: EP only (CART)\n",
    "cart_strategy2 = build_trading_strategy_cart(cart_reg2, signals_clean, spy_clean, [ep_col], 'EP only (CART)')\n",
    "cart_stats2 = calculate_strategy_stats(cart_strategy2, spy_excess) if cart_strategy2 else None\n",
    "\n",
    "# Strategy 3: DP, EP, 10Y Yield (CART)\n",
    "cart_strategy3 = build_trading_strategy_cart(cart_reg3, signals_clean, spy_clean, [dp_col, ep_col, yield_col], 'DP, EP, 10Y Yield (CART)')\n",
    "cart_stats3 = calculate_strategy_stats(cart_strategy3, spy_excess) if cart_strategy3 else None\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CART STRATEGY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, (cart_strat, cart_stat, name) in enumerate([(cart_strategy1, cart_stats1, 'DP only (CART)'),\n",
    "                                                    (cart_strategy2, cart_stats2, 'EP only (CART)'),\n",
    "                                                    (cart_strategy3, cart_stats3, 'DP, EP, 10Y Yield (CART)')], 1):\n",
    "    print(f\"\\nStrategy {i}: {name}\")\n",
    "    print(\"-\" * 80)\n",
    "    if cart_stat:\n",
    "        for key, value in cart_stat.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"{key}: {value:.6f}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(\"Strategy calculation failed\")\n",
    "\n",
    "# Summary table comparing CART with linear regression\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: CART vs Linear Regression Strategies\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFocusing on Strategy 3 (DP, EP, 10Y Yield) for comparison:\")\n",
    "\n",
    "if cart_stats3 and 'stats3' in globals() and stats3:\n",
    "    print(\"\\nMean Return (annualized):\")\n",
    "    print(f\"  CART: {cart_stats3['Mean (annualized)']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Mean (annualized)']:.6f}\")\n",
    "    print(f\"  Difference: {cart_stats3['Mean (annualized)'] - stats3['Mean (annualized)']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nVolatility (annualized):\")\n",
    "    print(f\"  CART: {cart_stats3['Volatility (annualized)']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Volatility (annualized)']:.6f}\")\n",
    "    print(f\"  Difference: {cart_stats3['Volatility (annualized)'] - stats3['Volatility (annualized)']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nSharpe Ratio (annualized):\")\n",
    "    print(f\"  CART: {cart_stats3['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Difference: {cart_stats3['Sharpe Ratio (annualized)'] - stats3['Sharpe Ratio (annualized)']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nMaximum Drawdown:\")\n",
    "    print(f\"  CART: {cart_stats3['Max Drawdown']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Max Drawdown']:.6f}\")\n",
    "    print(f\"  Difference: {cart_stats3['Max Drawdown'] - stats3['Max Drawdown']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nMarket Alpha:\")\n",
    "    print(f\"  CART: {cart_stats3['Market Alpha']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Market Alpha']:.6f}\")\n",
    "    print(f\"  Difference: {cart_stats3['Market Alpha'] - stats3['Market Alpha']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nMarket Beta:\")\n",
    "    print(f\"  CART: {cart_stats3['Market Beta']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Market Beta']:.6f}\")\n",
    "    print(f\"  Difference: {cart_stats3['Market Beta'] - stats3['Market Beta']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nInformation Ratio (annualized):\")\n",
    "    print(f\"  CART: {cart_stats3['Information Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Information Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Difference: {cart_stats3['Information Ratio (annualized)'] - stats3['Information Ratio (annualized)']:+.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Risk Characteristics (re-do Section 3.3)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. Risk Characteristics for CART Strategies (re-do Section 3.3)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# VaR calculation\n",
    "print(\"\\nMonthly VaR at π = 0.05:\")\n",
    "print(\"-\" * 80)\n",
    "if cart_strategy1:\n",
    "    var_cart1 = calculate_var(cart_strategy1['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 1 (DP only, CART): {var_cart1:.6f} ({var_cart1*100:.2f}%)\")\n",
    "if cart_strategy2:\n",
    "    var_cart2 = calculate_var(cart_strategy2['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 2 (EP only, CART): {var_cart2:.6f} ({var_cart2*100:.2f}%)\")\n",
    "if cart_strategy3:\n",
    "    var_cart3 = calculate_var(cart_strategy3['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 3 (DP, EP, 10Y, CART): {var_cart3:.6f} ({var_cart3*100:.2f}%)\")\n",
    "\n",
    "# Compare with linear regression strategies\n",
    "if 'var_strategy1' in globals() and not np.isnan(var_strategy1):\n",
    "    print(f\"\\nComparison with Linear Regression:\")\n",
    "    if cart_strategy1:\n",
    "        print(f\"  DP only - Linear: {var_strategy1:.6f}, CART: {var_cart1:.6f}\")\n",
    "    if cart_strategy2:\n",
    "        print(f\"  EP only - Linear: {var_strategy2:.6f}, CART: {var_cart2:.6f}\")\n",
    "    if cart_strategy3:\n",
    "        print(f\"  DP, EP, 10Y - Linear: {var_strategy3:.6f}, CART: {var_cart3:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CART IMPLEMENTATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: CART (RandomForest) can capture non-linear relationships that linear regression cannot.\")\n",
    "print(\"However, it may also be more prone to overfitting, especially with small datasets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d8e6ff",
   "metadata": {},
   "source": [
    "2. **CART, OOS.** Compute out‑of‑sample stats as in Section 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c672e534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OUT-OF-SAMPLE FORECASTING: CART (RandomForestRegressor)\n",
      "================================================================================\n",
      "\n",
      "Using both DP and EP as signals for CART forecasting\n",
      "\n",
      "Data range: 1996-12-31 to 2025-10-31\n",
      "Total observations: 347\n",
      "Starting OOS at t=60 (observation 2001-12-31 00:00:00)\n",
      "\n",
      "Running rolling OOS procedure with CART from t=60 to t=345...\n",
      "\n",
      "================================================================================\n",
      "OUT-OF-SAMPLE RESULTS: CART\n",
      "================================================================================\n",
      "\n",
      "Number of OOS forecasts: 286\n",
      "Sum of squared forecast errors: 0.660284\n",
      "Sum of squared null errors: 0.663985\n",
      "\n",
      "Out-of-Sample R² (CART): 0.005575\n",
      "\n",
      "✓ YES - The CART forecasting strategy produced a POSITIVE R²_OOS (0.005575)\n",
      "  This means the CART model forecasts are better than the null (mean) forecast.\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: CART vs Linear Regression (OOS)\n",
      "================================================================================\n",
      "Linear Regression R²_OOS: 0.088220\n",
      "CART R²_OOS: 0.005575\n",
      "Difference: -0.082645\n",
      "\n",
      "✗ Linear regression outperforms CART out-of-sample\n",
      "\n",
      "================================================================================\n",
      "ADDITIONAL STATISTICS: CART OOS\n",
      "================================================================================\n",
      "Mean forecast error: 0.006538\n",
      "RMSE (forecast): 0.048049\n",
      "Mean null error: 0.013239\n",
      "RMSE (null): 0.048183\n",
      "\n",
      "CART forecast RMSE is 0.28% lower than null forecast RMSE\n",
      "\n",
      "RMSE Comparison:\n",
      "  Linear Regression: 0.046009\n",
      "  CART: 0.048049\n",
      "  Difference: +0.002040\n",
      "  CART RMSE is 4.43% higher (worse)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. CART, OOS - Compute out-of-sample stats as in Section 4\n",
    "# Focus on using both DP and EP as signals (using CART)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OUT-OF-SAMPLE FORECASTING: CART (RandomForestRegressor)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nUsing both DP and EP as signals for CART forecasting\")\n",
    "\n",
    "# Align data (focus on DP and EP, as in Section 4)\n",
    "common_idx = signals.index.intersection(spy_excess.index)\n",
    "signals_aligned = signals.loc[common_idx, [dp_col, ep_col]]\n",
    "spy_aligned = spy_excess.loc[common_idx]\n",
    "\n",
    "# Sort by date\n",
    "signals_aligned = signals_aligned.sort_index()\n",
    "spy_aligned = spy_aligned.sort_index()\n",
    "\n",
    "# Remove NaN rows\n",
    "valid_mask = ~(signals_aligned.isna().any(axis=1) | spy_aligned.isna())\n",
    "signals_clean = signals_aligned[valid_mask]\n",
    "spy_clean = spy_aligned[valid_mask]\n",
    "\n",
    "print(f\"\\nData range: {spy_clean.index.min().date()} to {spy_clean.index.max().date()}\")\n",
    "print(f\"Total observations: {len(spy_clean)}\")\n",
    "print(f\"Starting OOS at t=60 (observation {spy_clean.index[60]})\")\n",
    "\n",
    "# Initialize storage for forecasts and errors\n",
    "cart_forecast_errors = []\n",
    "cart_null_errors = []\n",
    "cart_forecast_values = []\n",
    "cart_null_forecast_values = []\n",
    "cart_actual_returns = []\n",
    "\n",
    "# Rolling out-of-sample procedure using CART\n",
    "start_idx = 60\n",
    "T = len(spy_clean)\n",
    "\n",
    "print(f\"\\nRunning rolling OOS procedure with CART from t={start_idx} to t={T-2}...\")\n",
    "\n",
    "for t in range(start_idx, T - 1):\n",
    "    # Data through time t (for estimation)\n",
    "    spy_train = spy_clean.iloc[:t+1]\n",
    "    signals_train = signals_clean.iloc[:t+1]\n",
    "    \n",
    "    # X_t (predictors at time t) for forecasting\n",
    "    x_t = signals_clean.iloc[t:t+1]\n",
    "    \n",
    "    # r^{SPY}_{t+1} (actual return at time t+1)\n",
    "    r_t_plus_1 = spy_clean.iloc[t+1]\n",
    "    \n",
    "    # Drop NaN from training data\n",
    "    train_mask = ~(signals_train.isna().any(axis=1) | spy_train.isna())\n",
    "    signals_train_clean = signals_train[train_mask]\n",
    "    spy_train_clean = spy_train[train_mask]\n",
    "    \n",
    "    if len(signals_train_clean) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Estimate CART regression using data through time t\n",
    "    # r^{SPY}_i = f(X_{i-1}) for i = 1 to t\n",
    "    # We need to lag the signals\n",
    "    signals_train_lagged = signals_train_clean.shift(1).iloc[1:]  # X_{i-1}\n",
    "    spy_train_aligned = spy_train_clean.iloc[1:]  # r^{SPY}_i\n",
    "    \n",
    "    # Align after lag\n",
    "    common_train_idx = signals_train_lagged.index.intersection(spy_train_aligned.index)\n",
    "    signals_train_final = signals_train_lagged.loc[common_train_idx]\n",
    "    spy_train_final = spy_train_aligned.loc[common_train_idx]\n",
    "    \n",
    "    if len(signals_train_final) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Fit CART model (RandomForestRegressor)\n",
    "    X_train = signals_train_final.values\n",
    "    y_train = spy_train_final.values\n",
    "    \n",
    "    # Use RandomForestRegressor with reasonable parameters\n",
    "    cart_model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "    cart_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Forecast r^{SPY}_{t+1} using x_t\n",
    "    x_t_values = x_t.values\n",
    "    forecast = cart_model.predict(x_t_values)[0]\n",
    "    \n",
    "    # Forecast error\n",
    "    forecast_error = r_t_plus_1 - forecast\n",
    "    \n",
    "    # Null forecast: mean of returns through time t\n",
    "    null_forecast = spy_train_clean.mean()\n",
    "    null_error = r_t_plus_1 - null_forecast\n",
    "    \n",
    "    # Store results\n",
    "    cart_forecast_errors.append(forecast_error)\n",
    "    cart_null_errors.append(null_error)\n",
    "    cart_forecast_values.append(forecast)\n",
    "    cart_null_forecast_values.append(null_forecast)\n",
    "    cart_actual_returns.append(r_t_plus_1)\n",
    "\n",
    "# Convert to arrays\n",
    "cart_forecast_errors = np.array(cart_forecast_errors)\n",
    "cart_null_errors = np.array(cart_null_errors)\n",
    "\n",
    "# Calculate out-of-sample R²\n",
    "sum_squared_cart_forecast_errors = np.sum(cart_forecast_errors ** 2)\n",
    "sum_squared_cart_null_errors = np.sum(cart_null_errors ** 2)\n",
    "\n",
    "if sum_squared_cart_null_errors > 0:\n",
    "    cart_r2_oos = 1 - (sum_squared_cart_forecast_errors / sum_squared_cart_null_errors)\n",
    "else:\n",
    "    cart_r2_oos = np.nan\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUT-OF-SAMPLE RESULTS: CART\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNumber of OOS forecasts: {len(cart_forecast_errors)}\")\n",
    "print(f\"Sum of squared forecast errors: {sum_squared_cart_forecast_errors:.6f}\")\n",
    "print(f\"Sum of squared null errors: {sum_squared_cart_null_errors:.6f}\")\n",
    "print(f\"\\nOut-of-Sample R² (CART): {cart_r2_oos:.6f}\")\n",
    "\n",
    "if cart_r2_oos > 0:\n",
    "    print(f\"\\n✓ YES - The CART forecasting strategy produced a POSITIVE R²_OOS ({cart_r2_oos:.6f})\")\n",
    "    print(\"  This means the CART model forecasts are better than the null (mean) forecast.\")\n",
    "elif cart_r2_oos < 0:\n",
    "    print(f\"\\n✗ NO - The CART forecasting strategy produced a NEGATIVE R²_OOS ({cart_r2_oos:.6f})\")\n",
    "    print(\"  This means the CART model forecasts are worse than the null (mean) forecast.\")\n",
    "else:\n",
    "    print(f\"\\nThe CART forecasting strategy produced R²_OOS = 0\")\n",
    "    print(\"  This means the CART model forecasts perform the same as the null (mean) forecast.\")\n",
    "\n",
    "# Compare with linear regression OOS R² from Section 4\n",
    "if 'r2_oos' in globals() and not np.isnan(r2_oos):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARISON: CART vs Linear Regression (OOS)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Linear Regression R²_OOS: {r2_oos:.6f}\")\n",
    "    print(f\"CART R²_OOS: {cart_r2_oos:.6f}\")\n",
    "    print(f\"Difference: {cart_r2_oos - r2_oos:+.6f}\")\n",
    "    \n",
    "    if cart_r2_oos > r2_oos:\n",
    "        print(\"\\n✓ CART outperforms linear regression out-of-sample\")\n",
    "    elif cart_r2_oos < r2_oos:\n",
    "        print(\"\\n✗ Linear regression outperforms CART out-of-sample\")\n",
    "    else:\n",
    "        print(\"\\n= CART and linear regression perform similarly out-of-sample\")\n",
    "\n",
    "# Additional statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADDITIONAL STATISTICS: CART OOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Mean forecast error: {np.mean(cart_forecast_errors):.6f}\")\n",
    "print(f\"RMSE (forecast): {np.sqrt(np.mean(cart_forecast_errors**2)):.6f}\")\n",
    "print(f\"Mean null error: {np.mean(cart_null_errors):.6f}\")\n",
    "print(f\"RMSE (null): {np.sqrt(np.mean(cart_null_errors**2)):.6f}\")\n",
    "\n",
    "if np.sqrt(np.mean(cart_forecast_errors**2)) < np.sqrt(np.mean(cart_null_errors**2)):\n",
    "    improvement = ((np.sqrt(np.mean(cart_null_errors**2)) - np.sqrt(np.mean(cart_forecast_errors**2))) / \n",
    "                   np.sqrt(np.mean(cart_null_errors**2))) * 100\n",
    "    print(f\"\\nCART forecast RMSE is {improvement:.2f}% lower than null forecast RMSE\")\n",
    "else:\n",
    "    deterioration = ((np.sqrt(np.mean(cart_forecast_errors**2)) - np.sqrt(np.mean(cart_null_errors**2))) / \n",
    "                     np.sqrt(np.mean(cart_null_errors**2))) * 100\n",
    "    print(f\"\\nCART forecast RMSE is {deterioration:.2f}% higher than null forecast RMSE\")\n",
    "\n",
    "# Compare RMSE with linear regression\n",
    "if 'forecast_errors' in globals() and len(forecast_errors) > 0:\n",
    "    linear_rmse = np.sqrt(np.mean(forecast_errors**2))\n",
    "    cart_rmse = np.sqrt(np.mean(cart_forecast_errors**2))\n",
    "    print(f\"\\nRMSE Comparison:\")\n",
    "    print(f\"  Linear Regression: {linear_rmse:.6f}\")\n",
    "    print(f\"  CART: {cart_rmse:.6f}\")\n",
    "    print(f\"  Difference: {cart_rmse - linear_rmse:+.6f}\")\n",
    "    \n",
    "    if cart_rmse < linear_rmse:\n",
    "        improvement_pct = ((linear_rmse - cart_rmse) / linear_rmse) * 100\n",
    "        print(f\"  CART RMSE is {improvement_pct:.2f}% lower (better)\")\n",
    "    else:\n",
    "        deterioration_pct = ((cart_rmse - linear_rmse) / linear_rmse) * 100\n",
    "        print(f\"  CART RMSE is {deterioration_pct:.2f}% higher (worse)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c7c2f",
   "metadata": {},
   "source": [
    "3. **Neural Network.** Re‑do Section 3 using a **neural network** (e.g., `MLPRegressor` from `sklearn.neural_network`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42384341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ML FORECASTS: NEURAL NETWORK (MLPRegressor)\n",
      "================================================================================\n",
      "\n",
      "Re-doing Section 3 using MLPRegressor instead of linear regression\n",
      "\n",
      "Data range: 1996-12-31 to 2025-10-31\n",
      "Total observations: 347\n",
      "\n",
      "================================================================================\n",
      "1. Neural Network Regression: r^SPY_t = f(X_{t-1}) using MLPRegressor\n",
      "================================================================================\n",
      "\n",
      "1.1. Neural Network Regression with DP only:\n",
      "--------------------------------------------------------------------------------\n",
      "R²: -0.089096\n",
      "N observations: 346\n",
      "Training iterations: 14\n",
      "\n",
      "1.2. Neural Network Regression with EP only:\n",
      "--------------------------------------------------------------------------------\n",
      "R²: -0.053294\n",
      "N observations: 346\n",
      "Training iterations: 14\n",
      "\n",
      "1.3. Neural Network Regression with DP, EP, and 10-year yield:\n",
      "--------------------------------------------------------------------------------\n",
      "R²: 0.015730\n",
      "N observations: 346\n",
      "Training iterations: 30\n",
      "\n",
      "================================================================================\n",
      "SUMMARY: Neural Network Regression R²\n",
      "================================================================================\n",
      "                 Model        R²\n",
      "          DP only (NN) -0.089096\n",
      "          EP only (NN) -0.053294\n",
      "DP, EP, 10Y Yield (NN)  0.015730\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Comparison with Linear Regression (from Section 3):\n",
      "  DP only - Linear: 0.103106, NN: -0.089096, Difference: -0.192202\n",
      "  EP only - Linear: 0.018921, NN: -0.053294, Difference: -0.072214\n",
      "  DP, EP, 10Y - Linear: 0.183655, NN: 0.015730, Difference: -0.167925\n",
      "\n",
      "================================================================================\n",
      "2. Trading Strategy from Neural Network Forecasts (re-do Section 3.2)\n",
      "================================================================================\n",
      "\n",
      "Building Neural Network trading strategies...\n",
      "\n",
      "================================================================================\n",
      "NEURAL NETWORK STRATEGY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Strategy 1: DP only (NN)\n",
      "--------------------------------------------------------------------------------\n",
      "Mean (annualized): -0.019539\n",
      "Volatility (annualized): 0.017459\n",
      "Sharpe Ratio (annualized): -1.119137\n",
      "Max Drawdown: -0.434024\n",
      "Market Alpha: -0.001388\n",
      "Market Beta: 0.017829\n",
      "Information Ratio (annualized): -0.969843\n",
      "N observations: 346\n",
      "\n",
      "Strategy 2: EP only (NN)\n",
      "--------------------------------------------------------------------------------\n",
      "Mean (annualized): 0.035900\n",
      "Volatility (annualized): 0.052016\n",
      "Sharpe Ratio (annualized): 0.690173\n",
      "Max Drawdown: -0.435351\n",
      "Market Alpha: 0.002303\n",
      "Market Beta: -0.051077\n",
      "Information Ratio (annualized): 0.539536\n",
      "N observations: 346\n",
      "\n",
      "Strategy 3: DP, EP, 10Y Yield (NN)\n",
      "--------------------------------------------------------------------------------\n",
      "Mean (annualized): 0.146160\n",
      "Volatility (annualized): 0.097622\n",
      "Sharpe Ratio (annualized): 1.497207\n",
      "Max Drawdown: -0.112084\n",
      "Market Alpha: 0.010725\n",
      "Market Beta: -0.107911\n",
      "Information Ratio (annualized): 1.343935\n",
      "N observations: 346\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: Neural Network vs Linear Regression Strategies\n",
      "================================================================================\n",
      "\n",
      "Focusing on Strategy 3 (DP, EP, 10Y Yield) for comparison:\n",
      "\n",
      "Mean Return (annualized):\n",
      "  Neural Network: 0.146160\n",
      "  Linear: 0.733855\n",
      "  Difference: -0.587695\n",
      "\n",
      "Volatility (annualized):\n",
      "  Neural Network: 0.097622\n",
      "  Linear: 0.474515\n",
      "  Difference: -0.376893\n",
      "\n",
      "Sharpe Ratio (annualized):\n",
      "  Neural Network: 1.497207\n",
      "  Linear: 1.546539\n",
      "  Difference: -0.049332\n",
      "\n",
      "Maximum Drawdown:\n",
      "  Neural Network: -0.112084\n",
      "  Linear: -0.494226\n",
      "  Difference: +0.382142\n",
      "\n",
      "Market Alpha:\n",
      "  Neural Network: 0.010725\n",
      "  Linear: 0.055334\n",
      "  Difference: -0.044609\n",
      "\n",
      "Market Beta:\n",
      "  Neural Network: -0.107911\n",
      "  Linear: -0.431638\n",
      "  Difference: +0.323727\n",
      "\n",
      "Information Ratio (annualized):\n",
      "  Neural Network: 1.343935\n",
      "  Linear: 1.418252\n",
      "  Difference: -0.074317\n",
      "\n",
      "================================================================================\n",
      "3. Risk Characteristics for Neural Network Strategies (re-do Section 3.3)\n",
      "================================================================================\n",
      "\n",
      "Monthly VaR at π = 0.05:\n",
      "--------------------------------------------------------------------------------\n",
      "Strategy 1 (DP only, NN): -0.011267 (-1.13%)\n",
      "Strategy 2 (EP only, NN): -0.018525 (-1.85%)\n",
      "Strategy 3 (DP, EP, 10Y, NN): -0.018484 (-1.85%)\n",
      "\n",
      "Comparison with Linear Regression:\n",
      "  DP only - Linear: -0.078998, NN: -0.011267\n",
      "  EP only - Linear: -0.074008, NN: -0.018525\n",
      "  DP, EP, 10Y - Linear: -0.065591, NN: -0.018484\n",
      "\n",
      "================================================================================\n",
      "NEURAL NETWORK IMPLEMENTATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Note: Neural Networks can capture complex non-linear relationships.\n",
      "However, they require careful tuning and may be prone to overfitting.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 3. Neural Network - Re-do Section 3 using MLPRegressor\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ML FORECASTS: NEURAL NETWORK (MLPRegressor)\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nRe-doing Section 3 using MLPRegressor instead of linear regression\")\n",
    "\n",
    "# Align data\n",
    "common_idx = signals.index.intersection(spy_excess.index)\n",
    "signals_aligned = signals.loc[common_idx, [dp_col, ep_col, yield_col]]\n",
    "spy_aligned = spy_excess.loc[common_idx]\n",
    "\n",
    "signals_aligned = signals_aligned.sort_index()\n",
    "spy_aligned = spy_aligned.sort_index()\n",
    "\n",
    "valid_mask = ~(signals_aligned.isna().any(axis=1) | spy_aligned.isna())\n",
    "signals_clean = signals_aligned[valid_mask]\n",
    "spy_clean = spy_aligned[valid_mask]\n",
    "\n",
    "print(f\"\\nData range: {spy_clean.index.min().date()} to {spy_clean.index.max().date()}\")\n",
    "print(f\"Total observations: {len(spy_clean)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Lagged Regression using Neural Network (MLPRegressor)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. Neural Network Regression: r^SPY_t = f(X_{t-1}) using MLPRegressor\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to perform lagged regression using Neural Network\n",
    "def lagged_regression_nn(y, X, X_names, hidden_layer_sizes=(50,), max_iter=500, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform lagged regression using Neural Network (MLPRegressor).\n",
    "    \n",
    "    Parameters:\n",
    "    y: Series of dependent variable (SPY returns at time t)\n",
    "    X: DataFrame of predictors (at time t-1)\n",
    "    X_names: List of predictor names\n",
    "    hidden_layer_sizes: Tuple of hidden layer sizes\n",
    "    max_iter: Maximum iterations for training\n",
    "    random_state: Random state for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with model, R², and other statistics\n",
    "    \"\"\"\n",
    "    # Align indices - y at time t, X at time t-1\n",
    "    X_lagged = X[X_names].shift(1)  # Shift forward so X[t-1] aligns with y[t]\n",
    "    \n",
    "    # Align indices\n",
    "    common_idx = y.index.intersection(X_lagged.index)\n",
    "    y_aligned = y.loc[common_idx]\n",
    "    X_aligned = X_lagged.loc[common_idx]\n",
    "    \n",
    "    # Drop rows with NaN\n",
    "    valid_mask = ~(X_aligned.isna().any(axis=1) | y_aligned.isna())\n",
    "    y_clean = y_aligned[valid_mask]\n",
    "    X_clean = X_aligned[valid_mask]\n",
    "    \n",
    "    if len(y_clean) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    X_values = X_clean.values\n",
    "    y_values = y_clean.values\n",
    "    \n",
    "    # Fit Neural Network model\n",
    "    # Use a simple architecture: one hidden layer with 50 neurons\n",
    "    nn_model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, \n",
    "                            max_iter=max_iter, \n",
    "                            random_state=random_state,\n",
    "                            early_stopping=True,\n",
    "                            validation_fraction=0.1)\n",
    "    \n",
    "    try:\n",
    "        nn_model.fit(X_values, y_values)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Neural network fitting failed: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = nn_model.predict(X_values)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    ss_res = np.sum((y_values - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_values - np.mean(y_values)) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'Model': nn_model,\n",
    "        'Model Type': 'Neural Network (MLP)',\n",
    "        'R²': r_squared,\n",
    "        'N observations': len(y_clean),\n",
    "        'Predictions': y_pred,\n",
    "        'Actual': y_values,\n",
    "        'N iterations': nn_model.n_iter_ if hasattr(nn_model, 'n_iter_') else None\n",
    "    }\n",
    "\n",
    "# Perform Neural Network regressions for three cases\n",
    "print(\"\\n1.1. Neural Network Regression with DP only:\")\n",
    "print(\"-\" * 80)\n",
    "nn_reg1 = lagged_regression_nn(spy_clean, signals_clean, [dp_col], hidden_layer_sizes=(50,))\n",
    "if nn_reg1:\n",
    "    print(f\"R²: {nn_reg1['R²']:.6f}\")\n",
    "    print(f\"N observations: {nn_reg1['N observations']}\")\n",
    "    if nn_reg1['N iterations']:\n",
    "        print(f\"Training iterations: {nn_reg1['N iterations']}\")\n",
    "else:\n",
    "    print(\"Regression failed\")\n",
    "\n",
    "print(\"\\n1.2. Neural Network Regression with EP only:\")\n",
    "print(\"-\" * 80)\n",
    "nn_reg2 = lagged_regression_nn(spy_clean, signals_clean, [ep_col], hidden_layer_sizes=(50,))\n",
    "if nn_reg2:\n",
    "    print(f\"R²: {nn_reg2['R²']:.6f}\")\n",
    "    print(f\"N observations: {nn_reg2['N observations']}\")\n",
    "    if nn_reg2['N iterations']:\n",
    "        print(f\"Training iterations: {nn_reg2['N iterations']}\")\n",
    "else:\n",
    "    print(\"Regression failed\")\n",
    "\n",
    "print(\"\\n1.3. Neural Network Regression with DP, EP, and 10-year yield:\")\n",
    "print(\"-\" * 80)\n",
    "nn_reg3 = lagged_regression_nn(spy_clean, signals_clean, [dp_col, ep_col, yield_col], hidden_layer_sizes=(50,))\n",
    "if nn_reg3:\n",
    "    print(f\"R²: {nn_reg3['R²']:.6f}\")\n",
    "    print(f\"N observations: {nn_reg3['N observations']}\")\n",
    "    if nn_reg3['N iterations']:\n",
    "        print(f\"Training iterations: {nn_reg3['N iterations']}\")\n",
    "else:\n",
    "    print(\"Regression failed\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: Neural Network Regression R²\")\n",
    "print(\"=\"*80)\n",
    "summary_nn = []\n",
    "if nn_reg1:\n",
    "    summary_nn.append({'Model': 'DP only (NN)', 'R²': nn_reg1['R²']})\n",
    "if nn_reg2:\n",
    "    summary_nn.append({'Model': 'EP only (NN)', 'R²': nn_reg2['R²']})\n",
    "if nn_reg3:\n",
    "    summary_nn.append({'Model': 'DP, EP, 10Y Yield (NN)', 'R²': nn_reg3['R²']})\n",
    "\n",
    "if summary_nn:\n",
    "    summary_nn_df = pd.DataFrame(summary_nn)\n",
    "    print(summary_nn_df.to_string(index=False))\n",
    "    \n",
    "    # Compare with linear regression R² from Section 3\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"Comparison with Linear Regression (from Section 3):\")\n",
    "    if 'reg1' in globals() and reg1:\n",
    "        print(f\"  DP only - Linear: {reg1['R²']:.6f}, NN: {nn_reg1['R²']:.6f}, Difference: {nn_reg1['R²'] - reg1['R²']:+.6f}\")\n",
    "    if 'reg2' in globals() and reg2:\n",
    "        print(f\"  EP only - Linear: {reg2['R²']:.6f}, NN: {nn_reg2['R²']:.6f}, Difference: {nn_reg2['R²'] - reg2['R²']:+.6f}\")\n",
    "    if 'reg3' in globals() and reg3:\n",
    "        print(f\"  DP, EP, 10Y - Linear: {reg3['R²']:.6f}, NN: {nn_reg3['R²']:.6f}, Difference: {nn_reg3['R²'] - reg3['R²']:+.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Trading Strategy from Neural Network Forecasts (re-do Section 3.2)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. Trading Strategy from Neural Network Forecasts (re-do Section 3.2)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Function to build trading strategy from Neural Network forecasts\n",
    "def build_trading_strategy_nn(nn_reg_result, signals_df, spy_returns, X_names, strategy_name):\n",
    "    \"\"\"\n",
    "    Build trading strategy from Neural Network regression forecasts.\n",
    "    Similar to build_trading_strategy but uses Neural Network model.\n",
    "    \"\"\"\n",
    "    if nn_reg_result is None:\n",
    "        return None\n",
    "    \n",
    "    model = nn_reg_result['Model']\n",
    "    \n",
    "    # Align data - we need X_t to forecast r^{SPY}_{t+1}\n",
    "    common_idx = signals_df.index.intersection(spy_returns.index)\n",
    "    signals_aligned = signals_df.loc[common_idx, X_names]\n",
    "    spy_aligned = spy_returns.loc[common_idx]\n",
    "    \n",
    "    # Shift spy_returns forward by 1 period so r^{SPY}_{t+1} aligns with X_t\n",
    "    spy_next = spy_aligned.shift(-1)\n",
    "    \n",
    "    # Align again after shift\n",
    "    common_idx_final = signals_aligned.index.intersection(spy_next.index)\n",
    "    signals_final = signals_aligned.loc[common_idx_final]\n",
    "    spy_next_final = spy_next.loc[common_idx_final]\n",
    "    \n",
    "    # Drop NaN\n",
    "    valid_mask = ~(signals_final.isna().any(axis=1) | spy_next_final.isna())\n",
    "    signals_clean = signals_final[valid_mask]\n",
    "    spy_next_clean = spy_next_final[valid_mask]\n",
    "    \n",
    "    if len(signals_clean) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Build forecasts using Neural Network model\n",
    "    X_values = signals_clean.values\n",
    "    forecasts = model.predict(X_values)\n",
    "    \n",
    "    # Portfolio weights: w_t = 100 * r̂^{SPY}_{t+1}\n",
    "    weights = 100 * forecasts\n",
    "    \n",
    "    # Strategy returns: r^x_{t+1} = w_t * r^{SPY}_{t+1}\n",
    "    strategy_returns = weights * spy_next_clean.values\n",
    "    \n",
    "    # Create Series\n",
    "    strategy_returns_series = pd.Series(strategy_returns, index=signals_clean.index)\n",
    "    \n",
    "    return {\n",
    "        'strategy_name': strategy_name,\n",
    "        'forecasts': pd.Series(forecasts, index=signals_clean.index),\n",
    "        'weights': pd.Series(weights, index=signals_clean.index),\n",
    "        'strategy_returns': strategy_returns_series,\n",
    "        'spy_returns': spy_next_clean\n",
    "    }\n",
    "\n",
    "# Build strategies for all three Neural Network models\n",
    "print(\"\\nBuilding Neural Network trading strategies...\")\n",
    "\n",
    "# Strategy 1: DP only (NN)\n",
    "nn_strategy1 = build_trading_strategy_nn(nn_reg1, signals_clean, spy_clean, [dp_col], 'DP only (NN)')\n",
    "nn_stats1 = calculate_strategy_stats(nn_strategy1, spy_excess) if nn_strategy1 else None\n",
    "\n",
    "# Strategy 2: EP only (NN)\n",
    "nn_strategy2 = build_trading_strategy_nn(nn_reg2, signals_clean, spy_clean, [ep_col], 'EP only (NN)')\n",
    "nn_stats2 = calculate_strategy_stats(nn_strategy2, spy_excess) if nn_strategy2 else None\n",
    "\n",
    "# Strategy 3: DP, EP, 10Y Yield (NN)\n",
    "nn_strategy3 = build_trading_strategy_nn(nn_reg3, signals_clean, spy_clean, [dp_col, ep_col, yield_col], 'DP, EP, 10Y Yield (NN)')\n",
    "nn_stats3 = calculate_strategy_stats(nn_strategy3, spy_excess) if nn_strategy3 else None\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEURAL NETWORK STRATEGY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, (nn_strat, nn_stat, name) in enumerate([(nn_strategy1, nn_stats1, 'DP only (NN)'),\n",
    "                                                 (nn_strategy2, nn_stats2, 'EP only (NN)'),\n",
    "                                                 (nn_strategy3, nn_stats3, 'DP, EP, 10Y Yield (NN)')], 1):\n",
    "    print(f\"\\nStrategy {i}: {name}\")\n",
    "    print(\"-\" * 80)\n",
    "    if nn_stat:\n",
    "        for key, value in nn_stat.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"{key}: {value:.6f}\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "    else:\n",
    "        print(\"Strategy calculation failed\")\n",
    "\n",
    "# Summary table comparing Neural Network with linear regression\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: Neural Network vs Linear Regression Strategies\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFocusing on Strategy 3 (DP, EP, 10Y Yield) for comparison:\")\n",
    "\n",
    "if nn_stats3 and 'stats3' in globals() and stats3:\n",
    "    print(\"\\nMean Return (annualized):\")\n",
    "    print(f\"  Neural Network: {nn_stats3['Mean (annualized)']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Mean (annualized)']:.6f}\")\n",
    "    print(f\"  Difference: {nn_stats3['Mean (annualized)'] - stats3['Mean (annualized)']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nVolatility (annualized):\")\n",
    "    print(f\"  Neural Network: {nn_stats3['Volatility (annualized)']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Volatility (annualized)']:.6f}\")\n",
    "    print(f\"  Difference: {nn_stats3['Volatility (annualized)'] - stats3['Volatility (annualized)']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nSharpe Ratio (annualized):\")\n",
    "    print(f\"  Neural Network: {nn_stats3['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Difference: {nn_stats3['Sharpe Ratio (annualized)'] - stats3['Sharpe Ratio (annualized)']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nMaximum Drawdown:\")\n",
    "    print(f\"  Neural Network: {nn_stats3['Max Drawdown']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Max Drawdown']:.6f}\")\n",
    "    print(f\"  Difference: {nn_stats3['Max Drawdown'] - stats3['Max Drawdown']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nMarket Alpha:\")\n",
    "    print(f\"  Neural Network: {nn_stats3['Market Alpha']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Market Alpha']:.6f}\")\n",
    "    print(f\"  Difference: {nn_stats3['Market Alpha'] - stats3['Market Alpha']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nMarket Beta:\")\n",
    "    print(f\"  Neural Network: {nn_stats3['Market Beta']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Market Beta']:.6f}\")\n",
    "    print(f\"  Difference: {nn_stats3['Market Beta'] - stats3['Market Beta']:+.6f}\")\n",
    "    \n",
    "    print(\"\\nInformation Ratio (annualized):\")\n",
    "    print(f\"  Neural Network: {nn_stats3['Information Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Linear: {stats3['Information Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Difference: {nn_stats3['Information Ratio (annualized)'] - stats3['Information Ratio (annualized)']:+.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Risk Characteristics (re-do Section 3.3)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. Risk Characteristics for Neural Network Strategies (re-do Section 3.3)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# VaR calculation\n",
    "print(\"\\nMonthly VaR at π = 0.05:\")\n",
    "print(\"-\" * 80)\n",
    "if nn_strategy1:\n",
    "    var_nn1 = calculate_var(nn_strategy1['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 1 (DP only, NN): {var_nn1:.6f} ({var_nn1*100:.2f}%)\")\n",
    "if nn_strategy2:\n",
    "    var_nn2 = calculate_var(nn_strategy2['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 2 (EP only, NN): {var_nn2:.6f} ({var_nn2*100:.2f}%)\")\n",
    "if nn_strategy3:\n",
    "    var_nn3 = calculate_var(nn_strategy3['strategy_returns'], 0.05)\n",
    "    print(f\"Strategy 3 (DP, EP, 10Y, NN): {var_nn3:.6f} ({var_nn3*100:.2f}%)\")\n",
    "\n",
    "# Compare with linear regression strategies\n",
    "if 'var_strategy1' in globals() and not np.isnan(var_strategy1):\n",
    "    print(f\"\\nComparison with Linear Regression:\")\n",
    "    if nn_strategy1:\n",
    "        print(f\"  DP only - Linear: {var_strategy1:.6f}, NN: {var_nn1:.6f}\")\n",
    "    if nn_strategy2:\n",
    "        print(f\"  EP only - Linear: {var_strategy2:.6f}, NN: {var_nn2:.6f}\")\n",
    "    if nn_strategy3:\n",
    "        print(f\"  DP, EP, 10Y - Linear: {var_strategy3:.6f}, NN: {var_nn3:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NEURAL NETWORK IMPLEMENTATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: Neural Networks can capture complex non-linear relationships.\")\n",
    "print(\"However, they require careful tuning and may be prone to overfitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997cd2e6",
   "metadata": {},
   "source": [
    "4. **NN & CART, OOS.** Compute out‑of‑sample stats as in Section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afc91218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OUT-OF-SAMPLE FORECASTING: NEURAL NETWORK & CART\n",
      "================================================================================\n",
      "\n",
      "Using both DP and EP as signals for forecasting\n",
      "Comparing Neural Network (MLPRegressor) and CART (RandomForestRegressor)\n",
      "\n",
      "Data range: 1996-12-31 to 2025-10-31\n",
      "Total observations: 347\n",
      "\n",
      "Starting OOS at t=60 (observation 2001-12-31 00:00:00)\n",
      "Running rolling OOS procedure from t=60 to t=345...\n",
      "\n",
      "================================================================================\n",
      "1. NEURAL NETWORK (MLPRegressor) OUT-OF-SAMPLE FORECASTING\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cat33\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of NN OOS forecasts: 286\n",
      "Sum of squared forecast errors: 0.647437\n",
      "Sum of squared null errors: 0.661497\n",
      "\n",
      "Neural Network Out-of-Sample R²: 0.021255\n",
      "✓ YES - Neural Network produced a POSITIVE R²_OOS (0.021255)\n",
      "\n",
      "================================================================================\n",
      "2. CART (RandomForestRegressor) OUT-OF-SAMPLE FORECASTING\n",
      "================================================================================\n",
      "\n",
      "Number of CART OOS forecasts: 286\n",
      "Sum of squared forecast errors: 0.752961\n",
      "Sum of squared null errors: 0.661497\n",
      "\n",
      "CART Out-of-Sample R²: -0.138269\n",
      "✗ NO - CART produced a NEGATIVE R²_OOS (-0.138269)\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: OOS R² ACROSS MODELS\n",
      "================================================================================\n",
      "               Model    OOS R²\n",
      "   Linear Regression  0.088220\n",
      "Neural Network (MLP)  0.021255\n",
      " CART (RandomForest) -0.138269\n",
      "\n",
      "================================================================================\n",
      "4. TRADING STRATEGIES FROM OOS FORECASTS\n",
      "================================================================================\n",
      "\n",
      "4.1. Neural Network OOS Strategy\n",
      "--------------------------------------------------------------------------------\n",
      "NN OOS Strategy Statistics:\n",
      "  Mean (annualized): 0.265448\n",
      "  Volatility (annualized): 0.357648\n",
      "  Sharpe Ratio (annualized): 0.742206\n",
      "  Max Drawdown: -0.944710\n",
      "  Market Alpha: 0.006137\n",
      "  Market Beta: -2.003657\n",
      "  Information Ratio (annualized): 0.469480\n",
      "  N observations: 286\n",
      "\n",
      "4.2. CART OOS Strategy\n",
      "--------------------------------------------------------------------------------\n",
      "CART OOS Strategy Statistics:\n",
      "  Mean (annualized): 0.200422\n",
      "  Volatility (annualized): 0.482843\n",
      "  Sharpe Ratio (annualized): 0.415087\n",
      "  Max Drawdown: -0.994254\n",
      "  Market Alpha: 0.003810\n",
      "  Market Beta: -1.616100\n",
      "  Information Ratio (annualized): 0.112414\n",
      "  N observations: 286\n",
      "\n",
      "================================================================================\n",
      "5. COMPARISON: OOS STRATEGIES\n",
      "================================================================================\n",
      "\n",
      "Mean Return (annualized):\n",
      "  Linear Regression OOS: 0.212668\n",
      "  Neural Network OOS: 0.265448\n",
      "  CART OOS: 0.200422\n",
      "\n",
      "Volatility (annualized):\n",
      "  Linear Regression OOS: 0.259100\n",
      "  Neural Network OOS: 0.357648\n",
      "  CART OOS: 0.482843\n",
      "\n",
      "Sharpe Ratio (annualized):\n",
      "  Linear Regression OOS: 0.820797\n",
      "  Neural Network OOS: 0.742206\n",
      "  CART OOS: 0.415087\n",
      "\n",
      "Maximum Drawdown:\n",
      "  Linear Regression OOS: -0.747516\n",
      "  Neural Network OOS: -0.944710\n",
      "  CART OOS: -0.994254\n",
      "\n",
      "Market Alpha:\n",
      "  Linear Regression OOS: 0.007746\n",
      "  Neural Network OOS: 0.006137\n",
      "  CART OOS: 0.003810\n",
      "\n",
      "Market Beta:\n",
      "  Linear Regression OOS: -1.250617\n",
      "  Neural Network OOS: -2.003657\n",
      "  CART OOS: -1.616100\n",
      "\n",
      "Information Ratio (annualized):\n",
      "  Linear Regression OOS: 0.567514\n",
      "  Neural Network OOS: 0.469480\n",
      "  CART OOS: 0.112414\n",
      "\n",
      "================================================================================\n",
      "NN & CART OOS IMPLEMENTATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Note: Out-of-sample performance is a more realistic assessment of model performance\n",
      "as it avoids look-ahead bias and overfitting issues present in in-sample analysis.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. NN & CART, OOS - Compute out-of-sample stats as in Section 4\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"OUT-OF-SAMPLE FORECASTING: NEURAL NETWORK & CART\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nUsing both DP and EP as signals for forecasting\")\n",
    "print(\"Comparing Neural Network (MLPRegressor) and CART (RandomForestRegressor)\")\n",
    "\n",
    "# Align data\n",
    "common_idx = signals.index.intersection(spy_excess.index)\n",
    "signals_aligned = signals.loc[common_idx, [dp_col, ep_col]]\n",
    "spy_aligned = spy_excess.loc[common_idx]\n",
    "\n",
    "# Sort by date to ensure proper ordering\n",
    "signals_aligned = signals_aligned.sort_index()\n",
    "spy_aligned = spy_aligned.sort_index()\n",
    "\n",
    "# Drop rows with NaN\n",
    "valid_mask = ~(signals_aligned.isna().any(axis=1) | spy_aligned.isna())\n",
    "signals_clean = signals_aligned[valid_mask]\n",
    "spy_clean = spy_aligned[valid_mask]\n",
    "\n",
    "print(f\"\\nData range: {spy_clean.index.min().date()} to {spy_clean.index.max().date()}\")\n",
    "print(f\"Total observations: {len(spy_clean)}\")\n",
    "\n",
    "# Initialize OOS procedure\n",
    "start_idx = 60\n",
    "T = len(spy_clean)\n",
    "\n",
    "print(f\"\\nStarting OOS at t={start_idx} (observation {spy_clean.index[start_idx]})\")\n",
    "print(f\"Running rolling OOS procedure from t={start_idx} to t={T-2}...\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Neural Network OOS Forecasting\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1. NEURAL NETWORK (MLPRegressor) OUT-OF-SAMPLE FORECASTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize storage for NN forecasts and errors\n",
    "nn_forecast_errors = []\n",
    "nn_null_errors = []\n",
    "nn_forecast_values = []\n",
    "nn_null_forecast_values = []\n",
    "nn_actual_returns = []\n",
    "nn_forecast_dates = []\n",
    "\n",
    "# Rolling out-of-sample procedure for Neural Network\n",
    "for t in range(start_idx, T - 1):\n",
    "    # Data through time t (for estimation)\n",
    "    spy_train = spy_clean.iloc[:t+1]\n",
    "    signals_train = signals_clean.iloc[:t+1]\n",
    "    \n",
    "    # Create lagged data: X_{t-1} predicts r_t\n",
    "    # For training: we need X_{i-1} to predict r_i for i=1 to t\n",
    "    X_train_lagged = signals_train.shift(1).iloc[1:]  # X_{0} to X_{t-1}\n",
    "    y_train = spy_train.iloc[1:t+1]  # r_1 to r_t\n",
    "    \n",
    "    # Align indices\n",
    "    common_train_idx = X_train_lagged.index.intersection(y_train.index)\n",
    "    X_train = X_train_lagged.loc[common_train_idx]\n",
    "    y_train_aligned = y_train.loc[common_train_idx]\n",
    "    \n",
    "    # Drop NaN\n",
    "    valid_train = ~(X_train.isna().any(axis=1) | y_train_aligned.isna())\n",
    "    X_train_clean = X_train[valid_train]\n",
    "    y_train_clean = y_train_aligned[valid_train]\n",
    "    \n",
    "    if len(X_train_clean) < 10:  # Need minimum observations\n",
    "        continue\n",
    "    \n",
    "    # X_t (predictors at time t) for forecasting r_{t+1}\n",
    "    x_t = signals_clean.iloc[t:t+1]\n",
    "    \n",
    "    # r^{SPY}_{t+1} (actual return at time t+1)\n",
    "    r_t_plus_1 = spy_clean.iloc[t+1]\n",
    "    \n",
    "    # Fit Neural Network model\n",
    "    try:\n",
    "        nn_model = MLPRegressor(hidden_layer_sizes=(50,), \n",
    "                                max_iter=500, \n",
    "                                random_state=42,\n",
    "                                early_stopping=True,\n",
    "                                validation_fraction=0.1)\n",
    "        nn_model.fit(X_train_clean.values, y_train_clean.values)\n",
    "        \n",
    "        # Forecast r^{SPY}_{t+1} using X_t\n",
    "        forecast = nn_model.predict(x_t.values)[0]\n",
    "        \n",
    "        # Null forecast: mean of training data\n",
    "        null_forecast = y_train_clean.mean()\n",
    "        \n",
    "        # Forecast errors\n",
    "        forecast_error = r_t_plus_1 - forecast\n",
    "        null_error = r_t_plus_1 - null_forecast\n",
    "        \n",
    "        # Store results\n",
    "        nn_forecast_errors.append(forecast_error)\n",
    "        nn_null_errors.append(null_error)\n",
    "        nn_forecast_values.append(forecast)\n",
    "        nn_null_forecast_values.append(null_forecast)\n",
    "        nn_actual_returns.append(r_t_plus_1)\n",
    "        nn_forecast_dates.append(spy_clean.index[t+1])\n",
    "        \n",
    "    except Exception as e:\n",
    "        if t % 50 == 0:  # Print warnings only occasionally\n",
    "            print(f\"Warning: NN fitting failed at t={t}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert to arrays\n",
    "nn_forecast_errors = np.array(nn_forecast_errors)\n",
    "nn_null_errors = np.array(nn_null_errors)\n",
    "\n",
    "# Calculate out-of-sample R² for Neural Network\n",
    "nn_sum_squared_forecast_errors = np.sum(nn_forecast_errors ** 2)\n",
    "nn_sum_squared_null_errors = np.sum(nn_null_errors ** 2)\n",
    "\n",
    "if nn_sum_squared_null_errors > 0:\n",
    "    nn_r2_oos = 1 - (nn_sum_squared_forecast_errors / nn_sum_squared_null_errors)\n",
    "else:\n",
    "    nn_r2_oos = np.nan\n",
    "\n",
    "print(f\"\\nNumber of NN OOS forecasts: {len(nn_forecast_errors)}\")\n",
    "print(f\"Sum of squared forecast errors: {nn_sum_squared_forecast_errors:.6f}\")\n",
    "print(f\"Sum of squared null errors: {nn_sum_squared_null_errors:.6f}\")\n",
    "print(f\"\\nNeural Network Out-of-Sample R²: {nn_r2_oos:.6f}\")\n",
    "\n",
    "if nn_r2_oos > 0:\n",
    "    print(f\"✓ YES - Neural Network produced a POSITIVE R²_OOS ({nn_r2_oos:.6f})\")\n",
    "else:\n",
    "    print(f\"✗ NO - Neural Network produced a NEGATIVE R²_OOS ({nn_r2_oos:.6f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CART (RandomForestRegressor) OOS Forecasting\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. CART (RandomForestRegressor) OUT-OF-SAMPLE FORECASTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Initialize storage for CART forecasts and errors\n",
    "cart_forecast_errors = []\n",
    "cart_null_errors = []\n",
    "cart_forecast_values = []\n",
    "cart_null_forecast_values = []\n",
    "cart_actual_returns = []\n",
    "cart_forecast_dates = []\n",
    "\n",
    "# Rolling out-of-sample procedure for CART\n",
    "for t in range(start_idx, T - 1):\n",
    "    # Data through time t (for estimation)\n",
    "    spy_train = spy_clean.iloc[:t+1]\n",
    "    signals_train = signals_clean.iloc[:t+1]\n",
    "    \n",
    "    # Create lagged data: X_{t-1} predicts r_t\n",
    "    X_train_lagged = signals_train.shift(1).iloc[1:]\n",
    "    y_train = spy_train.iloc[1:t+1]\n",
    "    \n",
    "    # Align indices\n",
    "    common_train_idx = X_train_lagged.index.intersection(y_train.index)\n",
    "    X_train = X_train_lagged.loc[common_train_idx]\n",
    "    y_train_aligned = y_train.loc[common_train_idx]\n",
    "    \n",
    "    # Drop NaN\n",
    "    valid_train = ~(X_train.isna().any(axis=1) | y_train_aligned.isna())\n",
    "    X_train_clean = X_train[valid_train]\n",
    "    y_train_clean = y_train_aligned[valid_train]\n",
    "    \n",
    "    if len(X_train_clean) < 10:  # Need minimum observations\n",
    "        continue\n",
    "    \n",
    "    # X_t (predictors at time t) for forecasting r_{t+1}\n",
    "    x_t = signals_clean.iloc[t:t+1]\n",
    "    \n",
    "    # r^{SPY}_{t+1} (actual return at time t+1)\n",
    "    r_t_plus_1 = spy_clean.iloc[t+1]\n",
    "    \n",
    "    # Fit CART model\n",
    "    try:\n",
    "        cart_model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n",
    "        cart_model.fit(X_train_clean.values, y_train_clean.values)\n",
    "        \n",
    "        # Forecast r^{SPY}_{t+1} using X_t\n",
    "        forecast = cart_model.predict(x_t.values)[0]\n",
    "        \n",
    "        # Null forecast: mean of training data\n",
    "        null_forecast = y_train_clean.mean()\n",
    "        \n",
    "        # Forecast errors\n",
    "        forecast_error = r_t_plus_1 - forecast\n",
    "        null_error = r_t_plus_1 - null_forecast\n",
    "        \n",
    "        # Store results\n",
    "        cart_forecast_errors.append(forecast_error)\n",
    "        cart_null_errors.append(null_error)\n",
    "        cart_forecast_values.append(forecast)\n",
    "        cart_null_forecast_values.append(null_forecast)\n",
    "        cart_actual_returns.append(r_t_plus_1)\n",
    "        cart_forecast_dates.append(spy_clean.index[t+1])\n",
    "        \n",
    "    except Exception as e:\n",
    "        if t % 50 == 0:  # Print warnings only occasionally\n",
    "            print(f\"Warning: CART fitting failed at t={t}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert to arrays\n",
    "cart_forecast_errors = np.array(cart_forecast_errors)\n",
    "cart_null_errors = np.array(cart_null_errors)\n",
    "\n",
    "# Calculate out-of-sample R² for CART\n",
    "cart_sum_squared_forecast_errors = np.sum(cart_forecast_errors ** 2)\n",
    "cart_sum_squared_null_errors = np.sum(cart_null_errors ** 2)\n",
    "\n",
    "if cart_sum_squared_null_errors > 0:\n",
    "    cart_r2_oos = 1 - (cart_sum_squared_forecast_errors / cart_sum_squared_null_errors)\n",
    "else:\n",
    "    cart_r2_oos = np.nan\n",
    "\n",
    "print(f\"\\nNumber of CART OOS forecasts: {len(cart_forecast_errors)}\")\n",
    "print(f\"Sum of squared forecast errors: {cart_sum_squared_forecast_errors:.6f}\")\n",
    "print(f\"Sum of squared null errors: {cart_sum_squared_null_errors:.6f}\")\n",
    "print(f\"\\nCART Out-of-Sample R²: {cart_r2_oos:.6f}\")\n",
    "\n",
    "if cart_r2_oos > 0:\n",
    "    print(f\"✓ YES - CART produced a POSITIVE R²_OOS ({cart_r2_oos:.6f})\")\n",
    "else:\n",
    "    print(f\"✗ NO - CART produced a NEGATIVE R²_OOS ({cart_r2_oos:.6f})\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Comparison Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: OOS R² ACROSS MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get linear regression OOS R² from Section 4 if available\n",
    "linear_oos_r2 = None\n",
    "if 'r2_oos' in globals():\n",
    "    linear_oos_r2 = r2_oos\n",
    "\n",
    "comparison_data = []\n",
    "if linear_oos_r2 is not None:\n",
    "    comparison_data.append({'Model': 'Linear Regression', 'OOS R²': linear_oos_r2})\n",
    "if not np.isnan(nn_r2_oos):\n",
    "    comparison_data.append({'Model': 'Neural Network (MLP)', 'OOS R²': nn_r2_oos})\n",
    "if not np.isnan(cart_r2_oos):\n",
    "    comparison_data.append({'Model': 'CART (RandomForest)', 'OOS R²': cart_r2_oos})\n",
    "\n",
    "if comparison_data:\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Build Trading Strategies from OOS Forecasts\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. TRADING STRATEGIES FROM OOS FORECASTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Neural Network OOS Strategy\n",
    "print(\"\\n4.1. Neural Network OOS Strategy\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if len(nn_forecast_values) > 0:\n",
    "    # Create Series with forecasts and actual returns\n",
    "    nn_forecasts_series = pd.Series(nn_forecast_values, index=nn_forecast_dates)\n",
    "    nn_actual_series = pd.Series(nn_actual_returns, index=nn_forecast_dates)\n",
    "    \n",
    "    # Align with SPY returns for strategy building\n",
    "    nn_spy_aligned = spy_excess.loc[nn_forecast_dates]\n",
    "    \n",
    "    # Portfolio weights: w_t = 100 * r̂^{SPY}_{t+1}\n",
    "    nn_weights = 100 * nn_forecasts_series\n",
    "    \n",
    "    # Strategy returns: r^x_{t+1} = w_t * r^{SPY}_{t+1}\n",
    "    nn_oos_strategy_returns = nn_weights * nn_spy_aligned\n",
    "    \n",
    "    # Calculate statistics\n",
    "    nn_oos_stats = calculate_strategy_stats_oos(nn_oos_strategy_returns, spy_excess)\n",
    "    \n",
    "    if nn_oos_stats:\n",
    "        print(\"NN OOS Strategy Statistics:\")\n",
    "        for key, value in nn_oos_stats.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"  {key}: {value:.6f}\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(\"Failed to calculate NN OOS strategy statistics\")\n",
    "else:\n",
    "    print(\"No NN OOS forecasts available\")\n",
    "    nn_oos_strategy_returns = None\n",
    "    nn_oos_stats = None\n",
    "\n",
    "# CART OOS Strategy\n",
    "print(\"\\n4.2. CART OOS Strategy\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if len(cart_forecast_values) > 0:\n",
    "    # Create Series with forecasts and actual returns\n",
    "    cart_forecasts_series = pd.Series(cart_forecast_values, index=cart_forecast_dates)\n",
    "    cart_actual_series = pd.Series(cart_actual_returns, index=cart_forecast_dates)\n",
    "    \n",
    "    # Align with SPY returns for strategy building\n",
    "    cart_spy_aligned = spy_excess.loc[cart_forecast_dates]\n",
    "    \n",
    "    # Portfolio weights: w_t = 100 * r̂^{SPY}_{t+1}\n",
    "    cart_weights = 100 * cart_forecasts_series\n",
    "    \n",
    "    # Strategy returns: r^x_{t+1} = w_t * r^{SPY}_{t+1}\n",
    "    cart_oos_strategy_returns = cart_weights * cart_spy_aligned\n",
    "    \n",
    "    # Calculate statistics\n",
    "    cart_oos_stats = calculate_strategy_stats_oos(cart_oos_strategy_returns, spy_excess)\n",
    "    \n",
    "    if cart_oos_stats:\n",
    "        print(\"CART OOS Strategy Statistics:\")\n",
    "        for key, value in cart_oos_stats.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"  {key}: {value:.6f}\")\n",
    "            else:\n",
    "                print(f\"  {key}: {value}\")\n",
    "    else:\n",
    "        print(\"Failed to calculate CART OOS strategy statistics\")\n",
    "else:\n",
    "    print(\"No CART OOS forecasts available\")\n",
    "    cart_oos_strategy_returns = None\n",
    "    cart_oos_stats = None\n",
    "\n",
    "# ============================================================================\n",
    "# 5. Compare OOS Strategies with Linear Regression OOS Strategy\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. COMPARISON: OOS STRATEGIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get linear regression OOS strategy stats if available\n",
    "linear_oos_stats = None\n",
    "if 'oos_stats' in globals():\n",
    "    linear_oos_stats = oos_stats\n",
    "\n",
    "if linear_oos_stats and nn_oos_stats and cart_oos_stats:\n",
    "    print(\"\\nMean Return (annualized):\")\n",
    "    print(f\"  Linear Regression OOS: {linear_oos_stats['Mean (annualized)']:.6f}\")\n",
    "    print(f\"  Neural Network OOS: {nn_oos_stats['Mean (annualized)']:.6f}\")\n",
    "    print(f\"  CART OOS: {cart_oos_stats['Mean (annualized)']:.6f}\")\n",
    "    \n",
    "    print(\"\\nVolatility (annualized):\")\n",
    "    print(f\"  Linear Regression OOS: {linear_oos_stats['Volatility (annualized)']:.6f}\")\n",
    "    print(f\"  Neural Network OOS: {nn_oos_stats['Volatility (annualized)']:.6f}\")\n",
    "    print(f\"  CART OOS: {cart_oos_stats['Volatility (annualized)']:.6f}\")\n",
    "    \n",
    "    print(\"\\nSharpe Ratio (annualized):\")\n",
    "    print(f\"  Linear Regression OOS: {linear_oos_stats['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Neural Network OOS: {nn_oos_stats['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  CART OOS: {cart_oos_stats['Sharpe Ratio (annualized)']:.6f}\")\n",
    "    \n",
    "    print(\"\\nMaximum Drawdown:\")\n",
    "    print(f\"  Linear Regression OOS: {linear_oos_stats['Max Drawdown']:.6f}\")\n",
    "    print(f\"  Neural Network OOS: {nn_oos_stats['Max Drawdown']:.6f}\")\n",
    "    print(f\"  CART OOS: {cart_oos_stats['Max Drawdown']:.6f}\")\n",
    "    \n",
    "    print(\"\\nMarket Alpha:\")\n",
    "    print(f\"  Linear Regression OOS: {linear_oos_stats['Market Alpha']:.6f}\")\n",
    "    print(f\"  Neural Network OOS: {nn_oos_stats['Market Alpha']:.6f}\")\n",
    "    print(f\"  CART OOS: {cart_oos_stats['Market Alpha']:.6f}\")\n",
    "    \n",
    "    print(\"\\nMarket Beta:\")\n",
    "    print(f\"  Linear Regression OOS: {linear_oos_stats['Market Beta']:.6f}\")\n",
    "    print(f\"  Neural Network OOS: {nn_oos_stats['Market Beta']:.6f}\")\n",
    "    print(f\"  CART OOS: {cart_oos_stats['Market Beta']:.6f}\")\n",
    "    \n",
    "    print(\"\\nInformation Ratio (annualized):\")\n",
    "    print(f\"  Linear Regression OOS: {linear_oos_stats['Information Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  Neural Network OOS: {nn_oos_stats['Information Ratio (annualized)']:.6f}\")\n",
    "    print(f\"  CART OOS: {cart_oos_stats['Information Ratio (annualized)']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NN & CART OOS IMPLEMENTATION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNote: Out-of-sample performance is a more realistic assessment of model performance\")\n",
    "print(\"as it avoids look-ahead bias and overfitting issues present in in-sample analysis.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
